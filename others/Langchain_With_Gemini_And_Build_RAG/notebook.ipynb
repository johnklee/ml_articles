{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6826c8a0-ff43-4767-a29d-0120f1bb567b",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([article source](https://github.com/karndeepsingh/ApplicationsBuildWithLLMs/blob/main/Langchain_With_Gemini_And_Build_RAG.ipynb), [YT](https://www.youtube.com/watch?v=8xVmzoP1lks)) <b><font size='3ptx'>Here we are going to demonstrate the usage of LLM Gemini + RAG.</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5260b10-83cd-46b5-be6e-f3192b35caa9",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Setup environment</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697c50b2-cfe3-4cb4-a5e4-4c5344f87636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e9ffa22-6503-4fa6-a216-76d1d0323587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# loads the .env file\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dce194d-77bb-4525-96c6-c4bda097e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3e865-f71d-4cc5-aa82-b43e43f3f67d",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Text Generation</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3563f82f-5904-4ce2-bab5-692a698bc12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genai.GenerativeModel(\n",
       "    model_name='models/gemini-pro',\n",
       "    generation_config={},\n",
       "    safety_settings={},\n",
       "    tools=None,\n",
       "    system_instruction=None,\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name = \"gemini-pro\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7850cc6b-6026-4d5c-85fb-11089d58f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What are the usecases of LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba5f1f7-b2be-4f48-ad59-0482c74cd343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> **Content Creation:**\n",
       "> \n",
       "> * **Text generation:** Creating original stories, articles, marketing copy, and social media posts.\n",
       "> * **Code generation:** Assisting programmers in writing code, debugging, and generating documentation.\n",
       "> * **Translation:** Translating text between different languages.\n",
       "> * **Summarization:** Condensing long pieces of text into concise summaries.\n",
       "> * **Chatbot and conversational AI:** Powering chatbots and virtual assistants to engage in natural language conversations.\n",
       "> \n",
       "> **Data Analysis and Research:**\n",
       "> \n",
       "> * **Text and sentiment analysis:** Identifying emotions, opinions, and themes in text.\n",
       "> * **Data exploration and insights:** Uncovering patterns, insights, and trends from large datasets.\n",
       "> * **Question answering:** Answering questions based on a large repository of knowledge.\n",
       "> * **Fact-checking and bias detection:** Identifying bias and verifying factual claims.\n",
       "> \n",
       "> **Business Operations:**\n",
       "> \n",
       "> * **Customer service:** Assisting customer service representatives with resolving queries and providing support.\n",
       "> * **Sales and marketing:** Generating targeted marketing copy, analyzing customer feedback, and predicting customer behavior.\n",
       "> * **Process automation:** Automating repetitive tasks, such as data entry, email writing, and form processing.\n",
       "> * **Collaboration and knowledge management:** Facilitating collaboration, sharing information, and managing knowledge across teams.\n",
       "> \n",
       "> **Education and Training:**\n",
       "> \n",
       "> * **Personalized learning:** Adapting learning content to individual student's needs and progress.\n",
       "> * **Language learning:** Assisting language learners with grammar, vocabulary acquisition, and pronunciation.\n",
       "> * **Code literacy:** Teaching coding concepts and helping students build projects.\n",
       "> * **Critical thinking and problem-solving:** Engaging students in thought-provoking discussions and problem-solving exercises.\n",
       "> \n",
       "> **Other Usecases:**\n",
       "> \n",
       "> * **Gaming and entertainment:** Generating unique and engaging gameplay experiences, such as procedural levels and interactive stories.\n",
       "> * **Medical research:** Assisting in drug discovery, disease diagnosis, and personalized treatment plans.\n",
       "> * **Financial modeling and forecasting:** Predicting financial trends, analyzing market data, and making investment recommendations.\n",
       "> * **Transportation and logistics:** Optimizing routes, forecasting traffic patterns, and managing inventory.\n",
       "> * **Environmental science:** Modeling climate change, predicting natural disasters, and analyzing data from sensors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ab636-6e75-48bd-870f-b543e6d04797",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Use LangChain to Access Gemini API</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff52c29-c056-4290-b29a-35e74fcb44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46716b9f-5db6-4321-ae41-3d17bbc90aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "356e73ed-ae89-4144-8eb6-54444feb0d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 ms, sys: 1.13 ms, total: 17.8 ms\n",
      "Wall time: 6.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = llm.invoke(\"What are the usecases of LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea756a3-aa10-4cc5-986b-f10649506e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> **Language Generation and Summarization:**\n",
       "> \n",
       "> * Automated content creation, such as news articles, blog posts, and marketing copy\n",
       "> * Text summarization and abstraction\n",
       "> * Chatbot and virtual assistant responses\n",
       "> \n",
       "> **Code Generation and Debugging:**\n",
       "> \n",
       "> * Generating code snippets and functions in various programming languages\n",
       "> * Debugging and fixing errors in code\n",
       "> * Automating software testing\n",
       "> \n",
       "> **Translation and Localization:**\n",
       "> \n",
       "> * Translating text between different languages\n",
       "> * Localizing content for specific regions and cultures\n",
       "> \n",
       "> **Search and Information Retrieval:**\n",
       "> \n",
       "> * Improving search engine results by understanding natural language queries\n",
       "> * Extracting key information from large text corpora\n",
       "> * Question answering and fact verification\n",
       "> \n",
       "> **Content Analysis and Classification:**\n",
       "> \n",
       "> * Sentiment analysis and emotion detection\n",
       "> * Topic modeling and text classification\n",
       "> * Detecting fake news and misinformation\n",
       "> \n",
       "> **Education and Learning:**\n",
       "> \n",
       "> * Personalized learning assistants\n",
       "> * Language learning apps\n",
       "> * Educational content generation\n",
       "> \n",
       "> **Healthcare and Medicine:**\n",
       "> \n",
       "> * Medical diagnosis and treatment recommendations\n",
       "> * Drug discovery and research\n",
       "> * Analyzing medical records and patient data\n",
       "> \n",
       "> **Finance and Business:**\n",
       "> \n",
       "> * Financial analysis and forecasting\n",
       "> * Market research and sentiment analysis\n",
       "> * Contract and legal document review\n",
       "> \n",
       "> **Customer Service and Support:**\n",
       "> \n",
       "> * Chatbots and virtual assistants for customer inquiries\n",
       "> * Complaint and feedback analysis\n",
       "> * Knowledge base creation and maintenance\n",
       "> \n",
       "> **Entertainment and Creative Arts:**\n",
       "> \n",
       "> * Generating story ideas and plot outlines\n",
       "> * Creating music lyrics and melodies\n",
       "> * Developing video game scripts and dialogue\n",
       "> \n",
       "> **Other Use Cases:**\n",
       "> \n",
       "> * Social media monitoring and analysis\n",
       "> * Spam and phishing detection\n",
       "> * Data extraction and cleaning\n",
       "> * Language modeling for natural language processing tasks"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea953d-66eb-42dd-8b72-42d0dd0550b5",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Chat with Documents using RAG (Retreival Augment Generation)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab75543f-ef9e-43e6-9bdf-bc09d1c632fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import warnings\n",
    "from pathlib import Path as p\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# restart python kernal if issues with langchain import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "303c4ff0-77d7-4485-aafb-a2a0e649089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\",google_api_key=GOOGLE_API_KEY,\n",
    "    temperature=0.2,convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560ec73-b97e-4a59-a1bd-d34c12dfc672",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>RAG Pipeline: Embedding + Gemini (LLM)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ef76260-943b-478b-a102-27290d6e24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "CHROMA_PATH = os.getenv('CHROMA_PATH')\n",
    "COLLECTION_NAME = os.getenv('COLLECTION_NAME')\n",
    "EMBEDDING_FUNC_NAME = os.getenv('EMBEDDING_FUNC_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18c6a2e9-41c8-40cc-b7de-8007bd361f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe383bfe-5a4f-4677-b1b5-5cbee3e12618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_collection( \n",
    "    chroma_path: str=CHROMA_PATH, collection_name: str=COLLECTION_NAME):\n",
    "  chroma_client = chromadb.PersistentClient(chroma_path)\n",
    "  for collection in chroma_client.list_collections():\n",
    "    if collection.name == collection_name:\n",
    "      print(f'Found collection with name=\"{collection_name}\"!')\n",
    "      return collection\n",
    "\n",
    "  raise Exception(\n",
    "      'Chroma collection with name=\"{collection_name}\" does not exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c50b07f-c17a-47f7-8086-ecdf69bd685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(CHROMA_PATH)\n",
    "#embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "#      model_name=EMBEDDING_FUNC_NAME)\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=EMBEDDING_FUNC_NAME)\n",
    "\n",
    "langchain_chroma =  Chroma(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b2428e8-c214-4f4a-bd62-617f34a3e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = langchain_chroma.as_retriever(search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12cacdf5-4385-42d9-a574-9d2d6befcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    model,\n",
    "    retriever=vector_index,\n",
    "    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4c79f53-c683-4fc5-a13a-ea937c190bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.2 ms, sys: 2.8 ms, total: 59 ms\n",
      "Wall time: 4.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"Could you give me the sample code in using BDS broker from BTTC?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b70d2aca-f07f-4e48-9f55-f3b34cb29bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We call method `pair` on BDS broker to pair BDS device with DUT device:\\n```python\\n# Triggering pairing between BDS device and DUT device:\\n>>> bds_broker.pair()\\nTrue\\n\\n# The returned `True` indicated that BDS device and DUT device are paired:\\n>>> bds_broker.is_bt_paired()\\nTrue\\n```\\nthanks for asking!'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8aea2745-787c-4b58-8831-2964ad1f9f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show source document(s)\n",
    "# Markdown(result[\"source_documents\"][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d17d622-3ab3-4243-ac06-bca6b3af0db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We call method `pair` on BDS broker to pair BDS device with DUT device:\n",
       "```python\n",
       "# Triggering pairing between BDS device and DUT device:\n",
       ">>> bds_broker.pair()\n",
       "True\n",
       "\n",
       "# The returned `True` indicated that BDS device and DUT device are paired:\n",
       ">>> bds_broker.is_bt_paired()\n",
       "True\n",
       "```\n",
       "thanks for asking!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "258f3cd2-1ccf-4cad-b2da-43a43a90594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a software engineer with excellent experience in using bttc.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
    "Use the following collected information to answer questions:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    model,\n",
    "    retriever=vector_index,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9ebabae-5bb2-4865-a356-4664d7fc80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.7 ms, sys: 41.9 ms, total: 86.5 ms\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"Could you give me the sample code in using Dialer simulator from BTTC?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d166a60a-dcb4-4662-b38f-5ccafaedb2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Gets the DUT device from its serial.\n",
       ">>> import bttc\n",
       ">>> dut = bttc.get('36121FDJG000GR')\n",
       "\n",
       "# Import the module `hfp_devices`\n",
       ">>> from bttc.profiles.hfp import hfp_devices\n",
       "\n",
       "# Create an instance of AndroidPhoneWithDialerSimulator, wrapping the DUT\n",
       ">>> dut_with_dialer_simulator = hfp_devices.AndroidPhoneWithDialerSimulator(dut)\n",
       ">>> dut_with_dialer_simulator.ds\n",
       "<bttc.utils.dialer_simulator.DialerSimulator object at 0x7fdf5bdc7fd0>\n",
       "\n",
       "# Check the initial call state (should be `IDLE`)\n",
       ">>> dut_with_dialer_simulator.get_call_state()\n",
       "<CallStateEnum.IDLE: 'IDLE'>\n",
       "\n",
       "# Simulate an incoming call\n",
       ">>> dut_with_dialer_simulator.incoming_call()\n",
       "CallResult(caller=..., callee=<bttc.profiles.hfp.hfp_devices.AndroidPhoneWithDialerSimulator object at 0x7f79aabe4550>, error=None)\n",
       "\n",
       "# Verify the call state changed to `RINGING`\n",
       ">>> dut_with_dialer_simulator.get_call_state()\n",
       "<CallStateEnum.RINGING: 'RINGING'>\n",
       "\n",
       "# Simulate answering the call\n",
       ">>> dut_with_dialer_simulator.answer_call()\n",
       "True\n",
       "\n",
       "# Verify the call state changed to `ACTIVE`\n",
       ">>> dut_with_dialer_simulator.get_call_state()\n",
       "<CallStateEnum.ACTIVE: 'ACTIVE'>\n",
       "\n",
       "# Ends the call and expects call state to be `IDLE`.\n",
       ">>> dut_with_dialer_simulator.end_call()\n",
       "True\n",
       ">>> dut_with_dialer_simulator.get_call_state()\n",
       "<CallStateEnum.IDLE: 'IDLE'>\n",
       "\n",
       "# Simulates outgoing call and expects call state to be `ACTIVE`.\n",
       ">>> dut_with_dialer_simulator.outgoing_call()\n",
       "CallResult(caller=<bttc.profiles.hfp.hfp_devices.AndroidPhoneWithDialerSimulator object at 0x7f79aabe4550>, callee=..., error=None)\n",
       ">>> dut_with_dialer_simulator.get_call_state()\n",
       "<CallStateEnum.ACTIVE: 'ACTIVE'>\n",
       "\n",
       "# Ends the call and expects call state to be `IDLE`\n",
       ">>> dut_with_dialer_simulator.end_call()\n",
       "True\n",
       ">>> dut_with_dialer_simulator.get_call_state()\n",
       "<CallStateEnum.IDLE: 'IDLE'>\n",
       "```\n",
       "Thanks for asking!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2600c2b-8a0e-4c59-8f42-d936456c3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Describe Random forest?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f8c7254-65fa-459e-b2a8-1a0f5234d2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but the provided context does not mention anything about Random forest, so I cannot answer this question.\n",
       "Thanks for asking!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b99a0-2de7-4b3f-84e8-45add0d3d1c3",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [Stackoverflow - How to connect my ChromaDB collection and using langchain](https://stackoverflow.com/questions/77428241/how-to-connect-my-chromadb-collection-and-using-langchain)\n",
    "* [Stackoverflow - Chromadb + Langchain + SentenceTransformerEmbeddingFunction throwing 'SentenceTransformerEmbeddingFunction' object has no attribute 'embed_documents'](https://stackoverflow.com/questions/77004874/chromadb-langchain-sentencetransformerembeddingfunction-throwing-sentencetr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
