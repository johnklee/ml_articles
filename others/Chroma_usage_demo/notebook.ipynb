{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75715b8-479f-41a0-8628-24bc36d8b58f",
   "metadata": {},
   "source": [
    "<a id='sect0'></a>\n",
    "## <b><font color='darkblue'>Meet ChromaDB for LLM Applications</font><b/>\n",
    "<b><font size='3ptx'>[ChromaDB](https://docs.trychroma.com/) is an open-source vector database designed specifically for LLM applications.</font></b>\n",
    "* <b><font size='3ptx'><a href='#sect0_1'>Store documents</font></b>\n",
    "* <b><font size='3ptx'><a href='#sect0_2'>Query Vectorestore</font></b>\n",
    "* <b><font size='3ptx'><a href='#sect0_3'>Update documents</font></b>\n",
    "* <b><font size='3ptx'><a href='#sect0_4'>Delete documents</font></b>\n",
    "\n",
    "<b>ChromaDB offers you both a user-friendly API and impressive performance, making it a great choice for many embedding applications</b>. To get started, activate your virtual environment and run the following command:\n",
    "```shell\n",
    "(venv) $ python -m pip install chromadb\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "If you have any issues installing ChromaDB, take a look at [the troubleshooting guide](https://docs.trychroma.com/troubleshooting#build-error-when-running-pip-install-chromadb) for help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f44508-1a72-4679-ba43-315ca68ca257",
   "metadata": {},
   "source": [
    "<a id='sect0_1'></a>\n",
    "### <b><font color='darkgreen'>Store documents</font></b> ([back](#sect0))\n",
    "<font size='3ptx'><b>Because you have a grasp on vectors and embeddings, and you understand the motivation behind vector databases, the best way to get started is with an example</b></font>.  \n",
    "\n",
    "<b>For this example, you’ll store ten documents to search over.</b> To illustrate the power of embeddings and semantic search, each document covers a different topic, and you’ll see how well ChromaDB associates your queries with similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3091de82-86e4-4a8b-a7e1-2aa64a047fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "CHROMA_DATA_PATH = \"chroma_data/\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "COLLECTION_NAME = \"demo_docs\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624403f0-cb55-4ef8-9478-d5b6d2d9ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb3f376-f424-4ef9-a54c-b831715d1535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=demo_docs)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6e794-f643-4c1e-a9cc-d17516e0a826",
   "metadata": {},
   "source": [
    "Next, you instantiate your embedding function and the ChromaDB collection to store your documents in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed826331-7d41-4fba-a84c-e909c1dbe1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_registered is True\n"
     ]
    }
   ],
   "source": [
    "has_registered = False\n",
    "func_select_embedding_model = embedding_functions.SentenceTransformerEmbeddingFunction\n",
    "\n",
    "if not collections:\n",
    "    embedding_func = func_select_embedding_model(\n",
    "        model_name=EMBED_MODEL\n",
    "    )\n",
    "\n",
    "    collection = client.create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        embedding_function=embedding_func,\n",
    "        metadata={\"hnsw:space\": \"cosine\"},\n",
    "    )\n",
    "else:\n",
    "    has_registered = True\n",
    "    collection = collections[0]\n",
    "\n",
    "print(f'has_registered is {has_registered}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b6aa4-f361-4f74-8308-a813710ba067",
   "metadata": {},
   "source": [
    "You specify an embedding function from the [**SentenceTransformers**](https://sbert.net/) library. ChromaDB will use this to embed all your documents and queries. In this example, you’ll continue using the \"`all-MiniLM-L6-v2`\" model. You then create your first collection.\n",
    "\n",
    "<b>A collection is the object that stores your embedded documents along with any associated metadata</b>. If you’re familiar with relational databases, then you can think of a collection as a table. In this example, your collection is named demo_docs, it uses the \"`all-MiniLM-L6-v2`\" embedding function that you instantiated, and it uses the cosine similarity distance function as specified by `metadata={\"hnsw:space\": \"cosine\"}`.\n",
    "\n",
    "The last step in setting up your collection is to add documents and metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f12c176-25bd-433b-8317-4b05c0d125ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "     \"The latest iPhone model comes with impressive features and a powerful camera.\",\n",
    "     \"Exploring the beautiful beaches and vibrant culture of Bali is a dream for many travelers.\",\n",
    "     \"Einstein's theory of relativity revolutionized our understanding of space and time.\",\n",
    "     \"Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens.\",\n",
    "     \"The American Revolution had a profound impact on the birth of the United States as a nation.\",\n",
    "     \"Regular exercise and a balanced diet are essential for maintaining good physical health.\",\n",
    "     \"Leonardo da Vinci's Mona Lisa is considered one of the most iconic paintings in art history.\",\n",
    "     \"Climate change poses a significant threat to the planet's ecosystems and biodiversity.\",\n",
    "     \"Startup companies often face challenges in securing funding and scaling their operations.\",\n",
    "     \"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\",\n",
    "]\n",
    "\n",
    "genres = [\n",
    "     \"technology\",\n",
    "     \"travel\",\n",
    "     \"science\",\n",
    "     \"food\",\n",
    "     \"history\",\n",
    "     \"fitness\",\n",
    "     \"art\",\n",
    "     \"climate change\",\n",
    "     \"business\",\n",
    "     \"music\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d6e435-b6ac-4456-82a4-a0689982bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not has_registered:\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "         ids=[f\"id{i}\" for i in range(len(documents))],\n",
    "         metadatas=[{\"genre\": g} for g in genres]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5fd3b-6fb8-4142-b0ef-18713cd6819e",
   "metadata": {},
   "source": [
    "<b>The `metadatas` argument is optional, but most of the time, it’s useful to store metadata with your embeddings. In this case, you define a single metadata field, \"genre\", that records the genre of each document</b>. When you query a document, metadata provides you with additional information that can be helpful to better understand the document’s contents. You can also filter on metadata fields, just like you would in a relational database query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa906c9-a38b-4da4-ad74-f71eddf99254",
   "metadata": {},
   "source": [
    "<a id='sect0_2'></a>\n",
    "### <b><font color='darkgreen'>Query Vectorestore</font></b> ([back](#sect0))\n",
    "<b><font size='3ptx'>With documents embedded and stored in a collection, you’re ready to run some semantic queries.</font></b>\n",
    "\n",
    "Below code snippet will send query `Find me some delicious food!` and request only one doc being returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68422b7a-1e66-4d3d-8f03-539fa4202764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Update of nonexisting embedding ID: id1\n",
      "Update of nonexisting embedding ID: id2\n",
      "Delete of nonexisting embedding ID: id1\n",
      "Delete of nonexisting embedding ID: id2\n",
      "Update of nonexisting embedding ID: id1\n",
      "Update of nonexisting embedding ID: id2\n",
      "Delete of nonexisting embedding ID: id1\n",
      "Delete of nonexisting embedding ID: id2\n"
     ]
    }
   ],
   "source": [
    "query_results = collection.query(\n",
    "    query_texts=[\"Find me some delicious food!\"],\n",
    "    n_results=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d8cfa8-fcab-4544-81d5-f260ccd0bc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'distances', 'metadatas', 'embeddings', 'documents', 'uris', 'data'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581fc6ce-f83d-41f6-a16f-3602ff20c446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51886930-f0af-45a1-acd2-c989e16f1891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id3']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8299a42b-b138-4d6c-b750-a48d7502f43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7638262063498773]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"distances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "880d7c4d-94e7-41e0-9204-40b7478ab6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'genre': 'food'}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d1793d-faf2-4e8d-b965-30c8f2203b37",
   "metadata": {},
   "source": [
    "As you can see, the embedding for `Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens` was most similar to the query `Find me some delicious food`. You probably agree that this document is the closest match. You can also see the ID, metadata, and distance associated with the matching document embedding. Here, you’re using **cosine distance**, which is one minus the cosine similarity between two embeddings.\n",
    "\n",
    "With <font color='blue'>collection.query()</font>, you’re not limited to single queries or single results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f76ef86-1066-45a8-9a5f-e8c2161d4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = collection.query(\n",
    "    query_texts=[\"Teach me about history\",\n",
    "                 \"What's going on in the world?\"],\n",
    "    include=[\"documents\", \"distances\"],\n",
    "    n_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd53517-0cee-4afa-9c90-44f470e17190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The American Revolution had a profound impact on the birth of the United States as a nation.',\n",
       " \"Leonardo da Vinci's Mona Lisa is considered one of the most iconic paintings in art history.\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c969d3d-db21-4363-9fca-7a73b5a9b3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6904192480258038, 0.8771601240607931]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"distances\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a1d54b5-a89a-4184-80e2-4d4393be7980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Climate change poses a significant threat to the planet's ecosystems and biodiversity.\",\n",
       " 'The American Revolution had a profound impact on the birth of the United States as a nation.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"documents\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5858867d-0c78-43be-949e-8c8707a3a20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8002942768712199, 0.9402920899385823]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"distances\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351aa95-881c-4c6c-af1f-e43a01cb7904",
   "metadata": {},
   "source": [
    "For this query, the two most similar documents weren’t as strong of a match as in the first query. Recall that cosine distance is one minus cosine similarity, so a cosine distance of 0.80 corresponds to a cosine similarity of 0.20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758355c-f97c-4411-b11b-0fe97db326ea",
   "metadata": {},
   "source": [
    "<b><font color='darkred'>Note:</font></b>\n",
    "> <b>Keep in mind that so-called similar documents returned from a semantic search over embeddings may not actually be relevant to the task that you’re trying to solve</b>. The success of a semantic search is somewhat subjective, and you or your stakeholders might not agree on the quality of the results.\n",
    "> <br/><br/>\n",
    "> <b>If there are no relevant documents in your collection for a given query, or your embedding algorithm wasn’t trained on the right or enough data, then your results might be poor</b>. It’s up to you to understand your application, your stakeholders’ expectations, and the limitations of your embedding algorithm and document collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa6868-2426-4596-8225-7a4621592bb1",
   "metadata": {},
   "source": [
    "<b>Another awesome feature of ChromaDB is the ability to filter queries on metadata</b>. To motivate this, suppose you want to find the single document that’s most related to music history. You might run this query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7484404-ed6a-4ab0-adcb-8ff7e46dcb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id9']],\n",
       " 'distances': [[0.8186328079302339]],\n",
       " 'metadatas': [[{'genre': 'music'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\"]],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"Teach me about music history\"],\n",
    "    n_results=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d2bf4-8077-40bf-b19f-c036857e8567",
   "metadata": {},
   "source": [
    "our query is `Teach me about music history`, and the most similar document is `Einstein’s theory of relativity revolutionized our understanding of space and time`. While Einstein is a historical figure who was a musician and teacher, this isn’t quite the result that you’re looking for. Because you’re particularly interested in `music` history, you can filter on the \"genre\" metadata field to search over more relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb4769ad-fbf5-425f-bc27-c7664fd25ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id9']],\n",
       " 'distances': [[0.8186328079302339]],\n",
       " 'metadatas': [[{'genre': 'music'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\"]],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"Teach me about music history\"],\n",
    "    where={\"genre\": {\"$eq\": \"music\"}},\n",
    "    n_results=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb5b7e-5cde-4bb2-853d-904db21075dc",
   "metadata": {},
   "source": [
    "As you can see, the document about `Beethoven’s Symphony No. 9` is the most similar document. Of course, for this example, there’s only one document with the `music` genre. To make it slightly more difficult, you could filter on both `history` and `music`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9994a28c-e499-4ad0-9615-2e2f9ef7ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = collection.query(\n",
    "    query_texts=[\"Teach me about music history\"],\n",
    "    where={\"genre\": {\"$in\": [\"music\", \"history\"]}},\n",
    "    n_results=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff7a51b2-7c3b-44a5-a3a7-c4b06aef1c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\",\n",
       "  'The American Revolution had a profound impact on the birth of the United States as a nation.']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "884a8e36-c68d-48dc-b083-3618b7eb6aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8186328079302339, 0.8200413485985653]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"distances\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b926ab-b53f-4c0b-9f8c-24048859f90f",
   "metadata": {},
   "source": [
    "This query filters the collection of documents that have either a music or history genre, as specified by `where={\"genre\": {\"$in\": [\"music\", \"history\"]}}`. As you can see, the `Beethoven document` is still the most similar, while the `American Revolution document` is a close second. These were straightforward filtering examples on a single metadata field, but ChromaDB also supports [**other filtering operations**](https://docs.trychroma.com/usage-guide#:~:text=Filtering%20metadata%20supports%20the%20following%20operators%3A) that you might need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbd6e8-306b-42f0-b137-d6d0cff051e9",
   "metadata": {},
   "source": [
    "<a id='sect0_3'></a>\n",
    "### <b><font color='darkgreen'>Update documents</font></b> ([back](#sect0))\n",
    "<font size='3ptx'><b>If you want to update existing documents, embeddings, or metadata, then you can use <font color='blue'>collection.update()</font>.</b></font>\n",
    "\n",
    "\n",
    "This requires you to know the IDs of the data that you want to update. In this example, you’ll update both the documents and metadata for \"id1\" and \"id2\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "269ba432-ee13-48ff-aedf-3bde5938c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Update of nonexisting embedding ID: id1\n",
      "Update of nonexisting embedding ID: id2\n",
      "Update of nonexisting embedding ID: id1\n",
      "Update of nonexisting embedding ID: id2\n"
     ]
    }
   ],
   "source": [
    "collection.update(\n",
    "    ids=[\"id1\", \"id2\"],\n",
    "    documents=[\n",
    "        \"The new iPhone is awesome!\",\n",
    "        \"Bali has beautiful beaches\"],\n",
    "    metadatas=[{\"genre\": \"tech\"}, {\"genre\": \"beaches\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0485aadf-9cd1-45b8-a2fc-6b379ce5e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = collection.get(ids=[\"id1\", \"id2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a025ae3c-d410-4d7f-9c40-1c90c9cf5676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "031bfd81-c2a0-4a78-b2c6-9349f9b12a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7896a65-f804-40b0-820d-a5aa0689434c",
   "metadata": {},
   "source": [
    "<a id='sect0_4'></a>\n",
    "### <b><font color='darkgreen'>Delete documents</font></b> ([back](#sect0))\n",
    "<font size='3ptx'><b>Lastly, if you want to delete any items in the collection, then you can use <font color='blue'>collection.delete()</font>.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f719a27e-c1a2-46c8-8329-f1ad688585b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deletion, we have 8 document(s)!\n"
     ]
    }
   ],
   "source": [
    "print(f'Before deletion, we have {collection.count()} document(s)!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26810e-13c1-42cb-8e5a-3d692e56f87d",
   "metadata": {},
   "source": [
    "Below code snippet will delete two documents with id `id1` and `id2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "530efb9e-028c-4b62-860a-ca88994894e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: id1\n",
      "Delete of nonexisting embedding ID: id2\n",
      "Delete of nonexisting embedding ID: id1\n",
      "Delete of nonexisting embedding ID: id2\n"
     ]
    }
   ],
   "source": [
    "collection.delete(ids=[\"id1\", \"id2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f7da77c-76bf-4651-bf4f-dd879c349c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get([\"id1\", \"id2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83404ddb-6cd9-4a62-a9b0-a8c749665d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deletion, we have 8 document(s)!\n"
     ]
    }
   ],
   "source": [
    "print(f'After deletion, we have {collection.count()} document(s)!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e5d59-ce64-47a0-b16d-b543f654db8b",
   "metadata": {},
   "source": [
    "You’ve now seen many of ChromaDB’s main features, and you can learn more with the [**getting started guide**](https://docs.trychroma.com/getting-started) or [**API cheat sheet**](https://docs.trychroma.com/api-reference). You used a collection of ten hand-crafted documents that allowed you to get familiar with ChromaDB’s syntax and querying functionality, but this was by no means a realistic use case. <b>In the next section, you’ll see ChromaDB shine while you embed and query over thousands of real-world documents</b>!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ab33f-f2d6-4800-94b8-2c3521328fd2",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "## <b><font color='darkblue'>Practical Example: Add Context for a Large Language Model (LLM)</font></b>\n",
    "<b><font size='3ptx'>Vector databases are capable of storing all types of embeddings, such as text, audio, and images. However, as you’ve learned, ChromaDB was initially designed with text embeddings in mind, and it’s most often used to build LLM applications.</font></b>\n",
    "* <b><font size='3ptx'><a href='#sect1_1'>Prepare and Inspect Your Dataset</a></font></b>\n",
    "* <b><font size='3ptx'><a href='#sect1_2'>Create a Collection and Add Reviews</a></font></b>\n",
    "* <b><font size='3ptx'><a href='#sect1_3'>Connect to an LLM Service</a></font></b>\n",
    "* <b><font size='3ptx'><a href='#sect1_4'>Provide Context to the LLM</a></font></b>\n",
    "\n",
    "<b>In this section, you’ll get hands-on experience using ChromaDB to provide context to OpenAI’s ChatGPT LLM</b>. To set the scene, you’re a software engineer who works on a popular repo **[\"bt_test_common\"](https://github.com/johnklee/bt_test_common)** (Common utilities for BT testing.). You want to help external users to learn more about this repo and how to use the APIs provided by this repo by LLM.\n",
    "\n",
    "You’re responsible for designing and implementing the back-end logic that creates these summaries. You’ll take the following steps:\n",
    "1. <b>Create a ChromaDB collection that stores documents</b> along with associated metadata.\n",
    "2. <b>Create a system that accepts a query, finds semantically similar documents</b>, and uses the similar documents as context to an LLM. The LLM will use the documents to answer the question posed in the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec329e41-339d-4d30-89ef-564f0d0e0e8f",
   "metadata": {},
   "source": [
    "<b>This process of retrieving relevant documents and using them as context for a generative model is known as [retrieval-augmented generation](https://cloud.google.com/use-cases/retrieval-augmented-generation?hl=en) (RAG)</b>. This allows LLMs to make inferences using information that wasn’t included in their training dataset, and this is the most common way to apply ChromaDB in LLM applications.\n",
    "\n",
    "There are lots of factors and variations to consider when implementing a RAG system, but for this example, you’ll only need to know the fundamentals. Here’s what a RAG system might look like with ChromaDB:\n",
    "\n",
    "![RAG](images/rag_diagram.PNG)\n",
    "\n",
    "We first embed and store the documents in a ChromaDB collection. In this example, those documents are coming from the `bttc` repo. We then run a query  through ChromaDB to find semantically relevant documents, and you pass the query and relevant documents to an LLM to generate a context-informed response.\n",
    "\n",
    "<b>The key here is that the LLM takes both the original query and the relevant documents as input, allowing it to generate a meaningful response that it wouldn’t be able to create without the documents.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c5995-add8-4ed1-a44e-5b12f6d85365",
   "metadata": {},
   "source": [
    "In reality, your deliverable for this project would likely be a [**chatbot**](https://realpython.com/build-a-chatbot-python-chatterbot/) that stakeholders use to ask questions about repo `bttc` through a user interface. While building a full-fledged chatbot is beyond the scope of this tutorial, you can check out libraries like [**LangChain**](https://python.langchain.com/docs/get_started/introduction) that are designed specifically to help you assemble LLM applications.\n",
    "\n",
    "**The focus of this example is for you to see how you can use ChromaDB for RAG**. This practical knowledge will help reduce the learning curve for [**LangChain**](https://python.langchain.com/docs/get_started/introduction) if you choose to go that route in the future. With that, you’re ready to get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa929d2-b04a-4336-b55b-c91b8773743a",
   "metadata": {},
   "source": [
    "<a id='sect1_1'></a>\n",
    "### <b><font color='darkgreen'>Prepare and Inspect Your Dataset</font></b> ([back](#sect1))\n",
    "<b><font size='3ptx'>You’ll use the repo of [`bttc`](https://github.com/johnklee/bt_test_common) to create the collection. </font></b>\n",
    "\n",
    "Once you’ve clone the target repo [`bttc`](https://github.com/johnklee/bt_test_common), export the root path of repo as environment variable `BTTC_REPO_ROOT` for future ingestion:\n",
    "```shell\n",
    "$ git clone git@github.com:johnklee/bt_test_common.git\n",
    "$ cd bt_test_common/\n",
    "$ export BTTC_REPO_ROOT=`pwd`\n",
    "$ env | grep BTTC_REPO_ROOT\n",
    "BTTC_REPO_ROOT=/usr/local/google/home/johnkclee/Github/bt_test_common\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba454b27-f791-4e16-8621-ce4da63b52d5",
   "metadata": {},
   "source": [
    "Here’s a function that you can use to create the dataset of target repo `bttc` for ingestion of ChromaDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649d4ad2-5270-43f7-aa55-933c9f0e729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ingest_bttc_repo\n",
    "\n",
    "BTTC_REPO_ROOT='/usr/local/google/home/johnkclee/Github/bt_test_common'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31407f90-db77-40a5-a8f7-a62e6e9e0ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Sample doc:\n",
      "\tmetadata: {'file_path': '/usr/local/google/home/johnkclee/Github/bt_test_common/setup.py', 'file_type': 'py'}\n",
      "\tfrom __future__ impo (1,772 chs)\n"
     ]
    }
   ],
   "source": [
    "for dataset in ingest_bttc_repo.ingestion_of_repo_dataset_gen(BTTC_REPO_ROOT):\n",
    "    ids = dataset['ids']\n",
    "    documents = dataset['documents']\n",
    "    metadatas = dataset['metadatas']\n",
    "    print(f'ids: {ids}')\n",
    "    print(f'Sample doc:')\n",
    "    for doc, metadata in zip(documents, metadatas):\n",
    "        print(f'\\tmetadata: {metadata}')\n",
    "        print(f'\\t{doc[:20]} ({len(doc):,d} chs)')\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d90f2c-624a-46a3-8ccd-46784a570048",
   "metadata": {},
   "source": [
    "Function <font color='blue'><b>ingest_bttc_repo</b>.ingestion_of_repo_dataset_gen</font> will generate dataset for every 10 documents for ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fb3439-dddc-4a94-9bdb-c6b84c08ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: ['2', '3']\n",
      "Sample doc:\n",
      "\tmetadata: {'file_path': '/usr/local/google/home/johnkclee/Github/bt_test_common/setup.py', 'file_type': 'py'}\n",
      "\tfrom __future__ impo (1,518 chs)\n"
     ]
    }
   ],
   "source": [
    "for dataset in ingest_bttc_repo.ingestion_of_repo_dataset_gen_with_split(BTTC_REPO_ROOT):\n",
    "    ids = dataset['ids']\n",
    "    documents = dataset['documents']\n",
    "    metadatas = dataset['metadatas']\n",
    "    print(f'ids: {ids}')\n",
    "    print(f'Sample doc:')\n",
    "    for doc, metadata in zip(documents, metadatas):\n",
    "        print(f'\\tmetadata: {metadata}')\n",
    "        print(f'\\t{doc[:20]} ({len(doc):,d} chs)')\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5bada-b748-4059-96ed-d912e2baacb3",
   "metadata": {},
   "source": [
    "<a id='sect1_2'></a>\n",
    "### <b><font color='darkgreen'>Create a Collection and Add Reviews</font></b> ([back](#sect1))\n",
    "<b><font size='3ptx'>Next, you’ll create a collection and add the reviews.</font></b>\n",
    "\n",
    "Below codesnippet will ingest the documents for further RAG usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6dcdcb-36c2-4d36-b240-5de3859eba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"bttc_repo_embeddings\"\n",
    "EMBEDDING_FUNC_NAME = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "COLLECTION_NAME = \"bttc_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00bcc0c-a481-4bad-9cc7-cbc4f5cfc5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/johnkclee/Github/ml_articles/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 10\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 10\n",
      "Insert of existing embedding ID: 12\n",
      "Insert of existing embedding ID: 13\n",
      "Insert of existing embedding ID: 14\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n",
      "Add of existing embedding ID: 14\n",
      "Insert of existing embedding ID: 12\n",
      "Insert of existing embedding ID: 13\n",
      "Insert of existing embedding ID: 14\n",
      "Insert of existing embedding ID: 15\n",
      "Insert of existing embedding ID: 16\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n",
      "Add of existing embedding ID: 14\n",
      "Add of existing embedding ID: 15\n",
      "Add of existing embedding ID: 16\n",
      "Insert of existing embedding ID: 22\n",
      "Insert of existing embedding ID: 23\n",
      "Add of existing embedding ID: 22\n",
      "Add of existing embedding ID: 23\n",
      "Insert of existing embedding ID: 22\n",
      "Insert of existing embedding ID: 23\n",
      "Insert of existing embedding ID: 24\n",
      "Insert of existing embedding ID: 25\n",
      "Add of existing embedding ID: 22\n",
      "Add of existing embedding ID: 23\n",
      "Add of existing embedding ID: 24\n",
      "Add of existing embedding ID: 25\n",
      "Insert of existing embedding ID: 32\n",
      "Insert of existing embedding ID: 33\n",
      "Insert of existing embedding ID: 34\n",
      "Insert of existing embedding ID: 35\n",
      "Add of existing embedding ID: 32\n",
      "Add of existing embedding ID: 33\n",
      "Add of existing embedding ID: 34\n",
      "Add of existing embedding ID: 35\n",
      "Insert of existing embedding ID: 32\n",
      "Insert of existing embedding ID: 33\n",
      "Insert of existing embedding ID: 34\n",
      "Insert of existing embedding ID: 35\n",
      "Insert of existing embedding ID: 36\n",
      "Insert of existing embedding ID: 37\n",
      "Add of existing embedding ID: 32\n",
      "Add of existing embedding ID: 33\n",
      "Add of existing embedding ID: 34\n",
      "Add of existing embedding ID: 35\n",
      "Add of existing embedding ID: 36\n",
      "Add of existing embedding ID: 37\n",
      "Insert of existing embedding ID: 42\n",
      "Add of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 43\n",
      "Insert of existing embedding ID: 44\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Insert of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 43\n",
      "Insert of existing embedding ID: 44\n",
      "Insert of existing embedding ID: 45\n",
      "Insert of existing embedding ID: 46\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Add of existing embedding ID: 45\n",
      "Add of existing embedding ID: 46\n",
      "Insert of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 43\n",
      "Insert of existing embedding ID: 44\n",
      "Insert of existing embedding ID: 45\n",
      "Insert of existing embedding ID: 46\n",
      "Insert of existing embedding ID: 47\n",
      "Insert of existing embedding ID: 48\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Add of existing embedding ID: 45\n",
      "Add of existing embedding ID: 46\n",
      "Add of existing embedding ID: 47\n",
      "Add of existing embedding ID: 48\n",
      "Insert of existing embedding ID: 72\n",
      "Insert of existing embedding ID: 73\n",
      "Insert of existing embedding ID: 74\n",
      "Add of existing embedding ID: 72\n",
      "Add of existing embedding ID: 73\n",
      "Add of existing embedding ID: 74\n",
      "Insert of existing embedding ID: 72\n",
      "Insert of existing embedding ID: 73\n",
      "Insert of existing embedding ID: 74\n",
      "Insert of existing embedding ID: 75\n",
      "Insert of existing embedding ID: 76\n",
      "Add of existing embedding ID: 72\n",
      "Add of existing embedding ID: 73\n",
      "Add of existing embedding ID: 74\n",
      "Add of existing embedding ID: 75\n",
      "Add of existing embedding ID: 76\n",
      "Insert of existing embedding ID: 82\n",
      "Insert of existing embedding ID: 83\n",
      "Insert of existing embedding ID: 84\n",
      "Insert of existing embedding ID: 85\n",
      "Insert of existing embedding ID: 86\n",
      "Insert of existing embedding ID: 87\n",
      "Add of existing embedding ID: 82\n",
      "Add of existing embedding ID: 83\n",
      "Add of existing embedding ID: 84\n",
      "Add of existing embedding ID: 85\n",
      "Add of existing embedding ID: 86\n",
      "Add of existing embedding ID: 87\n",
      "Insert of existing embedding ID: 82\n",
      "Insert of existing embedding ID: 83\n",
      "Insert of existing embedding ID: 84\n",
      "Insert of existing embedding ID: 85\n",
      "Insert of existing embedding ID: 86\n",
      "Insert of existing embedding ID: 87\n",
      "Insert of existing embedding ID: 88\n",
      "Add of existing embedding ID: 82\n",
      "Add of existing embedding ID: 83\n",
      "Add of existing embedding ID: 84\n",
      "Add of existing embedding ID: 85\n",
      "Add of existing embedding ID: 86\n",
      "Add of existing embedding ID: 87\n",
      "Add of existing embedding ID: 88\n",
      "Insert of existing embedding ID: 92\n",
      "Insert of existing embedding ID: 93\n",
      "Add of existing embedding ID: 92\n",
      "Add of existing embedding ID: 93\n",
      "Insert of existing embedding ID: 92\n",
      "Insert of existing embedding ID: 93\n",
      "Insert of existing embedding ID: 94\n",
      "Insert of existing embedding ID: 95\n",
      "Insert of existing embedding ID: 96\n",
      "Insert of existing embedding ID: 97\n",
      "Add of existing embedding ID: 92\n",
      "Add of existing embedding ID: 93\n",
      "Add of existing embedding ID: 94\n",
      "Add of existing embedding ID: 95\n",
      "Add of existing embedding ID: 96\n",
      "Add of existing embedding ID: 97\n",
      "Insert of existing embedding ID: 102\n",
      "Insert of existing embedding ID: 103\n",
      "Insert of existing embedding ID: 104\n",
      "Insert of existing embedding ID: 105\n",
      "Add of existing embedding ID: 102\n",
      "Add of existing embedding ID: 103\n",
      "Add of existing embedding ID: 104\n",
      "Add of existing embedding ID: 105\n",
      "Insert of existing embedding ID: 102\n",
      "Insert of existing embedding ID: 103\n",
      "Insert of existing embedding ID: 104\n",
      "Insert of existing embedding ID: 105\n",
      "Insert of existing embedding ID: 106\n",
      "Add of existing embedding ID: 102\n",
      "Add of existing embedding ID: 103\n",
      "Add of existing embedding ID: 104\n",
      "Add of existing embedding ID: 105\n",
      "Add of existing embedding ID: 106\n",
      "Insert of existing embedding ID: 102\n",
      "Insert of existing embedding ID: 103\n",
      "Insert of existing embedding ID: 104\n",
      "Insert of existing embedding ID: 105\n",
      "Insert of existing embedding ID: 106\n",
      "Insert of existing embedding ID: 107\n",
      "Insert of existing embedding ID: 108\n",
      "Add of existing embedding ID: 102\n",
      "Add of existing embedding ID: 103\n",
      "Add of existing embedding ID: 104\n",
      "Add of existing embedding ID: 105\n",
      "Add of existing embedding ID: 106\n",
      "Add of existing embedding ID: 107\n",
      "Add of existing embedding ID: 108\n",
      "Insert of existing embedding ID: 112\n",
      "Add of existing embedding ID: 112\n",
      "Insert of existing embedding ID: 112\n",
      "Insert of existing embedding ID: 113\n",
      "Insert of existing embedding ID: 114\n",
      "Insert of existing embedding ID: 115\n",
      "Insert of existing embedding ID: 116\n",
      "Add of existing embedding ID: 112\n",
      "Add of existing embedding ID: 113\n",
      "Add of existing embedding ID: 114\n",
      "Add of existing embedding ID: 115\n",
      "Add of existing embedding ID: 116\n",
      "Insert of existing embedding ID: 112\n",
      "Insert of existing embedding ID: 113\n",
      "Insert of existing embedding ID: 114\n",
      "Insert of existing embedding ID: 115\n",
      "Insert of existing embedding ID: 116\n",
      "Insert of existing embedding ID: 117\n",
      "Insert of existing embedding ID: 118\n",
      "Insert of existing embedding ID: 119\n",
      "Insert of existing embedding ID: 120\n",
      "Add of existing embedding ID: 112\n",
      "Add of existing embedding ID: 113\n",
      "Add of existing embedding ID: 114\n",
      "Add of existing embedding ID: 115\n",
      "Add of existing embedding ID: 116\n",
      "Add of existing embedding ID: 117\n",
      "Add of existing embedding ID: 118\n",
      "Add of existing embedding ID: 119\n",
      "Add of existing embedding ID: 120\n",
      "Insert of existing embedding ID: 122\n",
      "Add of existing embedding ID: 122\n",
      "Insert of existing embedding ID: 122\n",
      "Insert of existing embedding ID: 123\n",
      "Insert of existing embedding ID: 124\n",
      "Add of existing embedding ID: 122\n",
      "Add of existing embedding ID: 123\n",
      "Add of existing embedding ID: 124\n",
      "Insert of existing embedding ID: 122\n",
      "Insert of existing embedding ID: 123\n",
      "Insert of existing embedding ID: 124\n",
      "Insert of existing embedding ID: 125\n",
      "Insert of existing embedding ID: 126\n",
      "Insert of existing embedding ID: 127\n",
      "Insert of existing embedding ID: 128\n",
      "Add of existing embedding ID: 122\n",
      "Add of existing embedding ID: 123\n",
      "Add of existing embedding ID: 124\n",
      "Add of existing embedding ID: 125\n",
      "Add of existing embedding ID: 126\n",
      "Add of existing embedding ID: 127\n",
      "Add of existing embedding ID: 128\n",
      "Insert of existing embedding ID: 122\n",
      "Insert of existing embedding ID: 123\n",
      "Insert of existing embedding ID: 124\n",
      "Insert of existing embedding ID: 125\n",
      "Insert of existing embedding ID: 126\n",
      "Insert of existing embedding ID: 127\n",
      "Insert of existing embedding ID: 128\n",
      "Insert of existing embedding ID: 129\n",
      "Add of existing embedding ID: 122\n",
      "Add of existing embedding ID: 123\n",
      "Add of existing embedding ID: 124\n",
      "Add of existing embedding ID: 125\n",
      "Add of existing embedding ID: 126\n",
      "Add of existing embedding ID: 127\n",
      "Add of existing embedding ID: 128\n",
      "Add of existing embedding ID: 129\n",
      "Insert of existing embedding ID: 142\n",
      "Insert of existing embedding ID: 143\n",
      "Insert of existing embedding ID: 144\n",
      "Add of existing embedding ID: 142\n",
      "Add of existing embedding ID: 143\n",
      "Add of existing embedding ID: 144\n",
      "Insert of existing embedding ID: 142\n",
      "Insert of existing embedding ID: 143\n",
      "Insert of existing embedding ID: 144\n",
      "Insert of existing embedding ID: 145\n",
      "Insert of existing embedding ID: 146\n",
      "Add of existing embedding ID: 142\n",
      "Add of existing embedding ID: 143\n",
      "Add of existing embedding ID: 144\n",
      "Add of existing embedding ID: 145\n",
      "Add of existing embedding ID: 146\n",
      "Insert of existing embedding ID: 142\n",
      "Insert of existing embedding ID: 143\n",
      "Insert of existing embedding ID: 144\n",
      "Insert of existing embedding ID: 145\n",
      "Insert of existing embedding ID: 146\n",
      "Insert of existing embedding ID: 147\n",
      "Add of existing embedding ID: 142\n",
      "Add of existing embedding ID: 143\n",
      "Add of existing embedding ID: 144\n",
      "Add of existing embedding ID: 145\n",
      "Add of existing embedding ID: 146\n",
      "Add of existing embedding ID: 147\n",
      "Insert of existing embedding ID: 152\n",
      "Add of existing embedding ID: 152\n",
      "Insert of existing embedding ID: 162\n",
      "Insert of existing embedding ID: 163\n",
      "Insert of existing embedding ID: 164\n",
      "Insert of existing embedding ID: 165\n",
      "Add of existing embedding ID: 162\n",
      "Add of existing embedding ID: 163\n",
      "Add of existing embedding ID: 164\n",
      "Add of existing embedding ID: 165\n",
      "Insert of existing embedding ID: 162\n",
      "Insert of existing embedding ID: 163\n",
      "Insert of existing embedding ID: 164\n",
      "Insert of existing embedding ID: 165\n",
      "Insert of existing embedding ID: 166\n",
      "Insert of existing embedding ID: 167\n",
      "Add of existing embedding ID: 162\n",
      "Add of existing embedding ID: 163\n",
      "Add of existing embedding ID: 164\n",
      "Add of existing embedding ID: 165\n",
      "Add of existing embedding ID: 166\n",
      "Add of existing embedding ID: 167\n",
      "Insert of existing embedding ID: 162\n",
      "Insert of existing embedding ID: 163\n",
      "Insert of existing embedding ID: 164\n",
      "Insert of existing embedding ID: 165\n",
      "Insert of existing embedding ID: 166\n",
      "Insert of existing embedding ID: 167\n",
      "Insert of existing embedding ID: 168\n",
      "Insert of existing embedding ID: 169\n",
      "Add of existing embedding ID: 162\n",
      "Add of existing embedding ID: 163\n",
      "Add of existing embedding ID: 164\n",
      "Add of existing embedding ID: 165\n",
      "Add of existing embedding ID: 166\n",
      "Add of existing embedding ID: 167\n",
      "Add of existing embedding ID: 168\n",
      "Add of existing embedding ID: 169\n",
      "Insert of existing embedding ID: 172\n",
      "Insert of existing embedding ID: 173\n",
      "Insert of existing embedding ID: 174\n",
      "Add of existing embedding ID: 172\n",
      "Add of existing embedding ID: 173\n",
      "Add of existing embedding ID: 174\n",
      "Insert of existing embedding ID: 172\n",
      "Insert of existing embedding ID: 173\n",
      "Insert of existing embedding ID: 174\n",
      "Insert of existing embedding ID: 175\n",
      "Insert of existing embedding ID: 176\n",
      "Add of existing embedding ID: 172\n",
      "Add of existing embedding ID: 173\n",
      "Add of existing embedding ID: 174\n",
      "Add of existing embedding ID: 175\n",
      "Add of existing embedding ID: 176\n",
      "Insert of existing embedding ID: 182\n",
      "Insert of existing embedding ID: 183\n",
      "Insert of existing embedding ID: 184\n",
      "Add of existing embedding ID: 182\n",
      "Add of existing embedding ID: 183\n",
      "Add of existing embedding ID: 184\n",
      "Insert of existing embedding ID: 182\n",
      "Insert of existing embedding ID: 183\n",
      "Insert of existing embedding ID: 184\n",
      "Insert of existing embedding ID: 185\n",
      "Insert of existing embedding ID: 186\n",
      "Insert of existing embedding ID: 187\n",
      "Add of existing embedding ID: 182\n",
      "Add of existing embedding ID: 183\n",
      "Add of existing embedding ID: 184\n",
      "Add of existing embedding ID: 185\n",
      "Add of existing embedding ID: 186\n",
      "Add of existing embedding ID: 187\n",
      "Insert of existing embedding ID: 192\n",
      "Add of existing embedding ID: 192\n",
      "Insert of existing embedding ID: 192\n",
      "Insert of existing embedding ID: 193\n",
      "Insert of existing embedding ID: 194\n",
      "Add of existing embedding ID: 192\n",
      "Add of existing embedding ID: 193\n",
      "Add of existing embedding ID: 194\n",
      "Insert of existing embedding ID: 212\n",
      "Insert of existing embedding ID: 213\n",
      "Insert of existing embedding ID: 214\n",
      "Insert of existing embedding ID: 215\n",
      "Insert of existing embedding ID: 216\n",
      "Add of existing embedding ID: 212\n",
      "Add of existing embedding ID: 213\n",
      "Add of existing embedding ID: 214\n",
      "Add of existing embedding ID: 215\n",
      "Add of existing embedding ID: 216\n",
      "Insert of existing embedding ID: 212\n",
      "Insert of existing embedding ID: 213\n",
      "Insert of existing embedding ID: 214\n",
      "Insert of existing embedding ID: 215\n",
      "Insert of existing embedding ID: 216\n",
      "Insert of existing embedding ID: 217\n",
      "Insert of existing embedding ID: 218\n",
      "Insert of existing embedding ID: 219\n",
      "Insert of existing embedding ID: 220\n",
      "Add of existing embedding ID: 212\n",
      "Add of existing embedding ID: 213\n",
      "Add of existing embedding ID: 214\n",
      "Add of existing embedding ID: 215\n",
      "Add of existing embedding ID: 216\n",
      "Add of existing embedding ID: 217\n",
      "Add of existing embedding ID: 218\n",
      "Add of existing embedding ID: 219\n",
      "Add of existing embedding ID: 220\n",
      "Insert of existing embedding ID: 222\n",
      "Insert of existing embedding ID: 223\n",
      "Insert of existing embedding ID: 224\n",
      "Insert of existing embedding ID: 225\n",
      "Insert of existing embedding ID: 226\n",
      "Insert of existing embedding ID: 227\n",
      "Add of existing embedding ID: 222\n",
      "Add of existing embedding ID: 223\n",
      "Add of existing embedding ID: 224\n",
      "Add of existing embedding ID: 225\n",
      "Add of existing embedding ID: 226\n",
      "Add of existing embedding ID: 227\n",
      "Insert of existing embedding ID: 222\n",
      "Insert of existing embedding ID: 223\n",
      "Insert of existing embedding ID: 224\n",
      "Insert of existing embedding ID: 225\n",
      "Insert of existing embedding ID: 226\n",
      "Insert of existing embedding ID: 227\n",
      "Insert of existing embedding ID: 228\n",
      "Add of existing embedding ID: 222\n",
      "Add of existing embedding ID: 223\n",
      "Add of existing embedding ID: 224\n",
      "Add of existing embedding ID: 225\n",
      "Add of existing embedding ID: 226\n",
      "Add of existing embedding ID: 227\n",
      "Add of existing embedding ID: 228\n",
      "Insert of existing embedding ID: 232\n",
      "Insert of existing embedding ID: 233\n",
      "Insert of existing embedding ID: 234\n",
      "Insert of existing embedding ID: 235\n",
      "Insert of existing embedding ID: 236\n",
      "Insert of existing embedding ID: 237\n",
      "Insert of existing embedding ID: 238\n",
      "Insert of existing embedding ID: 239\n",
      "Insert of existing embedding ID: 240\n",
      "Add of existing embedding ID: 232\n",
      "Add of existing embedding ID: 233\n",
      "Add of existing embedding ID: 234\n",
      "Add of existing embedding ID: 235\n",
      "Add of existing embedding ID: 236\n",
      "Add of existing embedding ID: 237\n",
      "Add of existing embedding ID: 238\n",
      "Add of existing embedding ID: 239\n",
      "Add of existing embedding ID: 240\n",
      "Insert of existing embedding ID: 242\n",
      "Add of existing embedding ID: 242\n",
      "Insert of existing embedding ID: 242\n",
      "Insert of existing embedding ID: 243\n",
      "Insert of existing embedding ID: 244\n",
      "Insert of existing embedding ID: 245\n",
      "Add of existing embedding ID: 242\n",
      "Add of existing embedding ID: 243\n",
      "Add of existing embedding ID: 244\n",
      "Add of existing embedding ID: 245\n",
      "Insert of existing embedding ID: 252\n",
      "Insert of existing embedding ID: 253\n",
      "Add of existing embedding ID: 252\n",
      "Add of existing embedding ID: 253\n",
      "Insert of existing embedding ID: 252\n",
      "Insert of existing embedding ID: 253\n",
      "Insert of existing embedding ID: 254\n",
      "Add of existing embedding ID: 252\n",
      "Add of existing embedding ID: 253\n",
      "Add of existing embedding ID: 254\n",
      "Insert of existing embedding ID: 252\n",
      "Insert of existing embedding ID: 253\n",
      "Insert of existing embedding ID: 254\n",
      "Insert of existing embedding ID: 255\n",
      "Add of existing embedding ID: 252\n",
      "Add of existing embedding ID: 253\n",
      "Add of existing embedding ID: 254\n",
      "Add of existing embedding ID: 255\n",
      "Insert of existing embedding ID: 262\n",
      "Insert of existing embedding ID: 263\n",
      "Insert of existing embedding ID: 264\n",
      "Insert of existing embedding ID: 265\n",
      "Insert of existing embedding ID: 266\n",
      "Insert of existing embedding ID: 267\n",
      "Add of existing embedding ID: 262\n",
      "Add of existing embedding ID: 263\n",
      "Add of existing embedding ID: 264\n",
      "Add of existing embedding ID: 265\n",
      "Add of existing embedding ID: 266\n",
      "Add of existing embedding ID: 267\n",
      "Insert of existing embedding ID: 262\n",
      "Insert of existing embedding ID: 263\n",
      "Insert of existing embedding ID: 264\n",
      "Insert of existing embedding ID: 265\n",
      "Insert of existing embedding ID: 266\n",
      "Insert of existing embedding ID: 267\n",
      "Insert of existing embedding ID: 268\n",
      "Add of existing embedding ID: 262\n",
      "Add of existing embedding ID: 263\n",
      "Add of existing embedding ID: 264\n",
      "Add of existing embedding ID: 265\n",
      "Add of existing embedding ID: 266\n",
      "Add of existing embedding ID: 267\n",
      "Add of existing embedding ID: 268\n",
      "Insert of existing embedding ID: 262\n",
      "Insert of existing embedding ID: 263\n",
      "Insert of existing embedding ID: 264\n",
      "Insert of existing embedding ID: 265\n",
      "Insert of existing embedding ID: 266\n",
      "Insert of existing embedding ID: 267\n",
      "Insert of existing embedding ID: 268\n",
      "Insert of existing embedding ID: 269\n",
      "Insert of existing embedding ID: 270\n",
      "Add of existing embedding ID: 262\n",
      "Add of existing embedding ID: 263\n",
      "Add of existing embedding ID: 264\n",
      "Add of existing embedding ID: 265\n",
      "Add of existing embedding ID: 266\n",
      "Add of existing embedding ID: 267\n",
      "Add of existing embedding ID: 268\n",
      "Add of existing embedding ID: 269\n",
      "Add of existing embedding ID: 270\n",
      "Insert of existing embedding ID: 272\n",
      "Add of existing embedding ID: 272\n",
      "Insert of existing embedding ID: 272\n",
      "Insert of existing embedding ID: 273\n",
      "Insert of existing embedding ID: 274\n",
      "Insert of existing embedding ID: 275\n",
      "Add of existing embedding ID: 272\n",
      "Add of existing embedding ID: 273\n",
      "Add of existing embedding ID: 274\n",
      "Add of existing embedding ID: 275\n",
      "Insert of existing embedding ID: 272\n",
      "Insert of existing embedding ID: 273\n",
      "Insert of existing embedding ID: 274\n",
      "Insert of existing embedding ID: 275\n",
      "Insert of existing embedding ID: 276\n",
      "Insert of existing embedding ID: 277\n",
      "Add of existing embedding ID: 272\n",
      "Add of existing embedding ID: 273\n",
      "Add of existing embedding ID: 274\n",
      "Add of existing embedding ID: 275\n",
      "Add of existing embedding ID: 276\n",
      "Add of existing embedding ID: 277\n",
      "Insert of existing embedding ID: 282\n",
      "Add of existing embedding ID: 282\n",
      "Insert of existing embedding ID: 282\n",
      "Insert of existing embedding ID: 283\n",
      "Add of existing embedding ID: 282\n",
      "Add of existing embedding ID: 283\n",
      "Insert of existing embedding ID: 282\n",
      "Insert of existing embedding ID: 283\n",
      "Insert of existing embedding ID: 284\n",
      "Add of existing embedding ID: 282\n",
      "Add of existing embedding ID: 283\n",
      "Add of existing embedding ID: 284\n",
      "Insert of existing embedding ID: 282\n",
      "Insert of existing embedding ID: 283\n",
      "Insert of existing embedding ID: 284\n",
      "Insert of existing embedding ID: 285\n",
      "Insert of existing embedding ID: 286\n",
      "Insert of existing embedding ID: 287\n",
      "Insert of existing embedding ID: 288\n",
      "Insert of existing embedding ID: 289\n",
      "Add of existing embedding ID: 282\n",
      "Add of existing embedding ID: 283\n",
      "Add of existing embedding ID: 284\n",
      "Add of existing embedding ID: 285\n",
      "Add of existing embedding ID: 286\n",
      "Add of existing embedding ID: 287\n",
      "Add of existing embedding ID: 288\n",
      "Add of existing embedding ID: 289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 19s, sys: 1min 14s, total: 6min 33s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collection = ingest_bttc_repo.build_chroma_collection(\n",
    "    chroma_path=CHROMA_PATH,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_func_name=EMBEDDING_FUNC_NAME,\n",
    "    default_repo_path=BTTC_REPO_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d849a98-8db3-4e89-b59c-7822bf1eb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 292 document(s) being ingested!\n"
     ]
    }
   ],
   "source": [
    "print(f'Total {collection.count()} document(s) being ingested!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74d113-9fd1-4402-a4c0-b85d4b12ad81",
   "metadata": {},
   "source": [
    "Now we could query the created collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba9f87d9-c44a-45f9-8580-2e82603de481",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = collection.query(\n",
    "    query_texts=[\"Tell me how to turn on the bluetooth.\"],\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"distances\", \"metadatas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfe3fe4-efe6-4878-a33c-eac80f8a2575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "912"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result['documents'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3904cf6-430e-4ce2-8a9f-a036b77c9fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result['documents'][0][0].split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4e237d-896e-40d1-9112-95795198677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l', value='null', err='')\n",
      "\n",
      "# Turn on the Gabeldorsche (GD) verbose log\n",
      ">>> dut.bt.enable_gd_log_verbose()\n",
      "True\n",
      "\n",
      "# Confirm the setting is set successfully (value='true')\n",
      ">>> dut.gm.device_config.bluetooth['INIT_logging_debug_enabled_for_all']\n",
      "DeviceConfig.Namespace.Setting(name='INIT_logging_debug_enabled_for_all', value='true', err='')\n",
      "```\n",
      "\n",
      "Ps. For this setting to work, your `build_version_sdk` should >= 33.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the first querying result for first document\n",
    "print(query_result['documents'][0][0][500:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d0341-7cb9-4eb1-a69a-ad6c81021ad6",
   "metadata": {},
   "source": [
    "<a id='sect1_3'></a>\n",
    "### <b><font color='darkgreen'>Connect to an LLM Service</font></b> ([back](#sect1))\n",
    "<b><font size='3ptx'>As you know, you’re going to use the `bttc` embeddings as context to an LLM.</font></b>\n",
    "\n",
    "This means that you’ll ask the LLM a question like `How to turn off the bluebooth`, and you’ll provide relevant embeddings to help the LLM answer this question. To do this, you’ll first need to install the [**openai**](https://github.com/openai/openai-python) library:\n",
    "```shell\n",
    "(venv) $ python -m pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4440c-f320-4a08-beb2-084d7c11c476",
   "metadata": {},
   "source": [
    "<b>You need an API key to interact with the models in the openai library, and you can check out [this tutorial](https://realpython.com/generate-images-with-dalle-openai-api/#get-your-openai-api-key) to help you get set up</b>. Once you have your API key, you can store it as an environment variable or add it to a configuration file like this [**JSON**](https://realpython.com/python-json/) file that you could name <font color='olive'>config.json</font>:\n",
    "```json\n",
    "{\n",
    "    \"openai-secret-key\": \"<your-api-key>\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cec2f9-cdf9-4d46-8dd3-2fe0c1371ac1",
   "metadata": {},
   "source": [
    "To make sure your API works and everything is running properly, you can run the following code, which will ask the LLM a question without considering any of the documents in your ChromaDB collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b139d5-31c9-45bb-88d7-284617a754e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import llm_utils\n",
    "import openai\n",
    "\n",
    "# 0) Initialize an LLM agent.\n",
    "llm_agent = llm_utils.LLMAgent(\n",
    "    context='You are a software engineer.',  # Context for the role of LLM agent.\n",
    "    model_name='gpt-3.5-turbo'               # Model to use.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e66835-34df-447b-9caf-c4b21ec1ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_answer(answer: str, max_line_width: int=100):\n",
    "    lines = [line.strip() for line in answer.split('\\n')]\n",
    "    for line in lines:\n",
    "        if not line:\n",
    "            print('')\n",
    "            continue\n",
    "\n",
    "        text = ''\n",
    "        text_length = 0\n",
    "        for word in line.split(' '):\n",
    "            word_length = len(word)\n",
    "            if text_length + word_length <= max_line_width:\n",
    "                extra_length = word_length + 1 if line else word_length\n",
    "                text = f'{text} {word}' if text else word\n",
    "                text_length += extra_length\n",
    "            else:\n",
    "                print(text)\n",
    "                text = ''\n",
    "                text_length = 0\n",
    "\n",
    "        if text:\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "760b9d5f-ee42-40e3-b0ac-75841cde7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Input question into LLM agent and obtain response.\n",
    "question = 'Can you explain what BTTC or repo `bt_test_common` is?'\n",
    "resp = llm_agent.answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec30a75-b09a-417d-9e87-db7b65abe484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not familiar with a specific technology or repository called \"BTTC\" or \"bt_test_common.\" It's\n",
      "that it could be a project-specific acronym or a custom repository created by a particular\n",
      "or team. If you can provide more context or details about what BTTC stands for or where you\n",
      "it, I may be able to offer more insights or assistance.\n"
     ]
    }
   ],
   "source": [
    "print_answer(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ccd5f7-24aa-4e59-a845-3744a27ba8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to turn off the bluetooth of device by package `bttc`?\"\n",
    "resp = llm_agent.answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7cbc80e-afa7-4229-9eab-310fd7826dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not familiar with a package called `bttc` for turning off Bluetooth on a device. However, if you\n",
      "looking to programmatically turn off Bluetooth on a device using a software package or library, you\n",
      "need to use platform-specific APIs or libraries.\n",
      "\n",
      "For example, on Android, you can use the BluetoothAdapter class to enable or disable Bluetooth.\n",
      "an example code snippet in Java:\n",
      "\n",
      "```java\n",
      "BluetoothAdapter bluetoothAdapter = BluetoothAdapter.getDefaultAdapter();\n",
      "if (bluetoothAdapter != null) {\n",
      "if (bluetoothAdapter.isEnabled()) {\n",
      "bluetoothAdapter.disable();\n",
      "}\n",
      "}\n",
      "```\n",
      "\n",
      "On iOS, you can use the CoreBluetooth framework to manage Bluetooth functionality. Here's an example\n",
      "snippet in Swift:\n",
      "\n",
      "```swift\n",
      "import CoreBluetooth\n",
      "\n",
      "let centralManager = CBCentralManager()\n",
      "if centralManager.state == .poweredOn {\n",
      "centralManager.stopScan()\n",
      "centralManager.cancelPeripheralConnection(peripheral)\n",
      "}\n",
      "```\n",
      "\n",
      "If you provide more information about the specific platform or programming language you are using, I\n",
      "provide more detailed guidance on how to turn off Bluetooth programmatically.\n"
     ]
    }
   ],
   "source": [
    "print_answer(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41bd7cb-379a-4b05-8501-da66317fcc02",
   "metadata": {},
   "source": [
    "In this block, you import `os`, `json`, and `openai` and set the <b><font color='orange'>TOKENIZERS_PARALLELISM</font></b> environment variable to \"false\". Setting this environment variable to \"false\" will suppress a warning related to [**huggingface tokenizers**](https://huggingface.co/docs/transformers/main_classes/tokenizer). You then load the JSON object that stores your OpenAI API key.\n",
    "\n",
    "The context message, `You are a software engineer.`, helps set the behavior of the LLM so that its responses are more likely to have a desired tone. This type of message is also sometimes called a [**role prompt**](https://realpython.com/practical-prompt-engineering/#add-a-role-prompt-to-set-the-tone). <b>The user message, `How to turn off the bluetooth of device by package `bttc`?`, is the actual question or task that you want the LLM to respond to.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c342e01-96b3-4742-a916-0760fd19bd4d",
   "metadata": {},
   "source": [
    "<a id='sect1_4'></a>\n",
    "### <b><font color='darkgreen'>Provide Context to the LLM</font></b> ([back](#sect1))\n",
    "<b><font size='3ptx'>As you can see, the LLM gives you a fairly generic description of what it takes to promote customer satisfaction. None of this information is particularly useful to you because it isn’t specific to repo `bttc`.</font></b>\n",
    "\n",
    "To make this response more tailored to your business, you need to provide the LLM with some reviews as context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca96811d-628b-413e-b8c7-52d16c41750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_CONTEXT_FORMAT = \"\"\"\n",
    "You are a software engineer with less experience in using bttc.\n",
    "Use the following collected information to answer questions: {}\n",
    "\"\"\"\n",
    "\n",
    "RAG_QUESTION_FORMAT = \"\"\"\n",
    "{}\n",
    "\n",
    "Please give a short description coming after with the bullet point list as summary.\n",
    "\"\"\"\n",
    "\n",
    "# Setup RAG settings.\n",
    "llm_agent.rag_context_format = RAG_CONTEXT_FORMAT\n",
    "llm_agent_rag_question_format = RAG_QUESTION_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2bc0a5e-8357-442b-a5c8-7d0f61e3942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = 'Can you explain what BTTC or repo `bt_test_common` is?'\n",
    "\n",
    "related_docs = collection.query(\n",
    "    query_texts=[question1],\n",
    "    n_results=10,\n",
    "    include=[\"documents\", \"metadatas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf7781d2-a1e2-441a-9f6d-d57fb1e57974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': '/usr/local/google/home/johnkclee/Github/bt_test_common/README.md', 'file_type': 'md'}\n",
      "## Common utilities used in BT testing\n",
      "This package is used to hold common utilities for BT testing.\n",
      "\n",
      "## Installation\n",
      "You can install the released package from pip:\n",
      "\n",
      "```shell\n",
      "$ pip install bttc\n",
      "```\n",
      "\n",
      "or download the source then run command below to use the latest version:\n",
      "\n",
      "```shell\n",
      "$ git clone https://github.com/johnklee/bt_test_common.git\n",
      "$ cd bt_test_common\n",
      "$ pip install .\n",
      "```\n",
      "\n",
      "You may need `sudo` for the above commands if your system has certain permission restrictions.\n",
      "\n",
      "## Basic Usage\n",
      "\n",
      "### Re\n"
     ]
    }
   ],
   "source": [
    "doc_str = related_docs[\"documents\"][0][0]\n",
    "doc_metadata = related_docs[\"metadatas\"][0][0]\n",
    "print(doc_metadata)\n",
    "print(doc_str[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88c45269-6759-40d1-94cd-2ba3bf6c4957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a software '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_str = \",\".join(related_docs[\"documents\"][0])\n",
    "RAG_CONTEXT_FORMAT.format(docs_str)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce69a5-5529-4a39-a1a3-a0c7312ec0f2",
   "metadata": {},
   "source": [
    "We setup `rag_max_doc_count=5` to avoid below exception:\n",
    "```python\n",
    "BadRequestError: Error code: 400 - {\n",
    "  'error': {\n",
    "      'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 16392 tokens....\",\n",
    "      'type': 'invalid_request_error',\n",
    "      'param': 'messages', 'code': 'context_length_exceeded'}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "892f82cd-9542-4464-9587-776c99fe9d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_resp = llm_agent.answer_with_rag(\n",
    "    collection=collection,  # Vectorstore containing BTTC embeddings\n",
    "    question=question1,     # Question to query the RAG-augmented LLM\n",
    "    rag_max_doc_count=5,    # Maximum number of relevant embeddings to consider\n",
    "    return_full=True,       # Returns full information including composed question and context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a04e71da-0420-46fb-8777-d8e83b787549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTTC stands for Bluetooth Test Common (BTTC), which is a package used for testing Bluetooth\n",
      "It provides common utilities and tools for Bluetooth testing purposes. The `bt_test_common`\n",
      "contains modules and functions related to Bluetooth testing, such as `bt_utils`, `ble_utils`, and\n",
      "\n",
      "The `bt_test_common` repository includes unit test cases for these modules to ensure the\n",
      "and correctness of the Bluetooth testing utilities provided by BTTC. The unit tests cover scenarios\n",
      "checking Bluetooth device states, handling device configurations, scanning for devices, and more.\n",
      "\n",
      "Overall, BTTC and the `bt_test_common` repository are resources for software engineers and\n",
      "working on Bluetooth testing to streamline their testing processes and ensure the reliability of\n",
      "functionalities in their applications.\n"
     ]
    }
   ],
   "source": [
    "print_answer(full_resp.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f04ccbed-20c4-4c1a-b190-ede4666b55bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you explain what BTTC or repo `bt_test_common` is?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_resp.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b2176f1-1939-4240-adfb-80e4873bce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a software engineer with less experience in using bttc.\n",
      "Use the following collected information to answer questions: ## Common utilities used in BT testing\n",
      "This package is used to hold common utilities for BT testing.\n",
      "\n",
      "## Installation\n",
      "You can install the released package from pip:\n",
      "\n",
      "```shell\n",
      "$ pip install bttc\n",
      "```\n",
      "\n",
      "or download the source then run command below to use the latest version:\n",
      "\n",
      "```shell\n",
      "$ git clone https://github.com/johnklee/bt_test_common.git\n",
      "$ cd bt_test_common\n",
      "$ pip install\n"
     ]
    }
   ],
   "source": [
    "print(full_resp.context[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2be042-0261-4c6d-8834-eb0582d87e02",
   "metadata": {},
   "source": [
    "Then for the second question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9c401d8-b91e-4b19-acf8-653e1b96d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"How to turn off the bluetooth of device by using package `bttc`?\"\n",
    "resp = llm_agent.answer_with_rag(\n",
    "    collection=collection,  # Vectorstore containing BTTC embeddings\n",
    "    question=question2,     # Question to query the RAG-augmented LLM\n",
    "    rag_max_doc_count=5,    # Maximum number of relevant embeddings to consider\n",
    "    return_full=True,       # Returns full information including composed question and context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "665b2590-4fa1-40e1-9b6e-5e8d0cf0f66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a software engineer with less experience in using bttc.\n",
      "Use the following collected information to answer questions: ## Preface\n",
      "Thei `bt_utils` module provides utility functions for common Bluetooth\n",
      "operations, such as enabling/disabling Bluetooth and retrieving a list of\n",
      "paired devices.\n",
      "\n",
      "## Usage\n",
      "The `bttc.bt_utils.BTModule` class is loaded automatically when you retrieve a\n",
      "device using the `bttc.get()` function.  For example:\n",
      "```python\n",
      "# Import the package `bttc`\n",
      ">>> import bttc\n",
      "\n",
      "# Retrieve your device. Please replace '36121FDJG000GR' with your device's\n",
      "# serial number.\n",
      ">>> dut = bttc.get('36121FDJG000GR')\n",
      "```\n",
      "You can access supported Bluetooth operations through the device's `bt`\n",
      "attribute.\n",
      "\n",
      "### Get Bluetooth status\n",
      "You can call method `dut.bt.is_enabled` or access attribute `dut.bt.enabled` to\n",
      "get the Bluetooth status of device. e.g.:\n",
      "```python\n",
      ">>> dut.bt.is_enabled()   # Checks if Bluetooth is enabled.\n",
      "False\n",
      ">>> dut.bt.enable()       # Enable the Bluetooth of device.\n",
      ">>> dut.bt.is_enabled()   # Checks if Bluetooth is enabled.\n",
      "True\n",
      ">>> dut.bt.enabled        # Access the Bluetooth status.\n",
      "True\n",
      "```\n",
      "\n",
      "### Get Device's Bluetooth MAC address\n",
      "You can retrieve the Bluetooth MAC address of device by method\n",
      "`dut.bt.get_bluetooth_mac_address`. e.g.:\n",
      "```python\n",
      "# Import utility `bt_utils`\n",
      ">>> from bttc import bt_utils\n",
      "\n",
      "# Retrieve your device. Please replace '36121FDJG000GR' with your device's\n",
      "# serial number.\n",
      ">>> dut = bt_utils.bind('36121FDJG000GR')\n",
      "\n",
      "# Get Bluetooth MAC address\n",
      ">>> dut.bt.get_bluetooth_mac_address()\n",
      "'D4:3A:2C:57:D4:21'\n",
      "```\n",
      "\n",
      "### Get Bluetooth MAC address of paired BT device by name\n",
      "You can get the MAC address of paired BT device by method `dut.bt.get_device_mac_by_name`:,  def paired_device_names(self):\n",
      "    return self.list_paired_devices()\n",
      "\n",
      "  def restart(self):\n",
      "    \"\"\"Restarts the Bluetooth.\n",
      "\n",
      "    This method will disable and then enable the Bluetooth to restart it.\n",
      "    \"\"\"\n",
      "    self.disable()\n",
      "    self.enable()\n",
      "\n",
      "\n",
      "def bind(\n",
      "    ad: Union[ANDROID_DEVICE, str],\n",
      "    init_mbs: bool = False,\n",
      "    init_sl4a: bool = False,\n",
      "    init_snippet_uiautomator: bool = False,\n",
      "    init_tl4a: bool = False) -> ANDROID_DEVICE:\n",
      "  \"\"\"Binds the input device with functions defined in module `bt_utils`.\n",
      "\n",
      "  Sample Usage:\n",
      "  ```python\n",
      "  >>> from bttc import bt_utils\n",
      "  >>> ad = bt_utils.bind('35121FDJG0005P', init_mbs=True, init_sl4a=True)\n",
      "  >>> ad.bt.is_bluetooth_enabled()\n",
      "  True\n",
      "  >>> ad.bt.list_paired_devices()\n",
      "  ['Galaxy Buds2 Pro', 'Galaxy Buds2 Pro']\n",
      "  ```\n",
      "\n",
      "  Args:\n",
      "    ad: If string is given, it stands for serial of device. Otherwise, it should\n",
      "        be the Android device object.\n",
      "    init_mbs: True to initialize the MBS service of given device.\n",
      "    init_sl4a: True to initialize the SL4A service of given device.\n",
      "\n",
      "  Returns:\n",
      "    The device with binded functions defined in `bt_utils`.\n",
      "  \"\"\"\n",
      "  device = device_factory.get(\n",
      "      ad, init_mbs=init_mbs,\n",
      "      init_sl4a=init_sl4a,\n",
      "      init_snippet_uiautomator=init_snippet_uiautomator,\n",
      "      init_tl4a=init_tl4a)\n",
      "  device.load_config({BINDING_KEYWORD: BTModule(device)})\n",
      "\n",
      "  return device\n",
      "\n",
      "\n",
      "def crash_since(\n",
      "    device: android_device.AndroidDevice,\n",
      "    start_time: str | None = None) -> common_data.CrashInfo:\n",
      "  \"\"\"Collects crash timestamp.\n",
      "\n",
      "  Usage example:,\n",
      "# Enable the snoop log.\n",
      ">>> dut.bt.enable_snoop_log()\n",
      "True\n",
      "\n",
      "# Confirm the snoop log is enabled.\n",
      ">>> dut.gm.props['persist.bluetooth.btsnooplogmode']\n",
      "'full'\n",
      "```\n",
      "\n",
      "### Enables Bluetooth Gabeldorsche (GD) verbose log\n",
      "You can enable Bluetooth Gabeldorsche (GD) verbose log by method `dut.bt.enable_gd_log_verbose`:\n",
      "```python\n",
      "# By default, GD verbose log is off\n",
      ">>> dut.gm.device_config.bluetooth['INIT_logging_debug_enabled_for_all']\n",
      "DeviceConfig.Namespace.Setting(name='INIT_logging_debug_enabled_for_all', value='null', err='')\n",
      "\n",
      "# Turn on the Gabeldorsche (GD) verbose log\n",
      ">>> dut.bt.enable_gd_log_verbose()\n",
      "True\n",
      "\n",
      "# Confirm the setting is set successfully (value='true')\n",
      ">>> dut.gm.device_config.bluetooth['INIT_logging_debug_enabled_for_all']\n",
      "DeviceConfig.Namespace.Setting(name='INIT_logging_debug_enabled_for_all', value='true', err='')\n",
      "```\n",
      "\n",
      "Ps. For this setting to work, your `build_version_sdk` should >= 33.\n",
      ",# Copyright 2024 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#    https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "\"\"\"Module to hold dataclass or related data used in Bluetooth operations.\"\"\"\n",
      "\n",
      "import dataclasses\n",
      "from bttc import constants\n",
      "from typing import Any\n",
      "\n",
      "\n",
      "@dataclasses.dataclass\n",
      "class BondedDeviceInfo:\n",
      "  \"\"\"Information of a bonded device.\"\"\"\n",
      "\n",
      "  mac_addr: str\n",
      "  bt_type: constants.BluetoothDeviceType\n",
      "  name: str\n",
      "\n",
      "\n",
      "@dataclasses.dataclass\n",
      "class PairedDeviceInfo:\n",
      "  \"\"\"Information of a paired device.\"\"\"\n",
      "\n",
      "  mac_addr: str\n",
      "  bt_type: constants.BluetoothDeviceType\n",
      "  name: str\n",
      "  uuids: list[str]\n",
      "  bond_state: constants.BluetoothBondedState\n",
      "\n",
      "  @classmethod\n",
      "  def from_dict(\n",
      "      cls, dict_data: dict[str, Any]) -> 'PairedDeviceInfo':\n",
      "    name = dict_data['Name']\n",
      "\n",
      "    # 'DEVICE_TYPE_DUAL' -> 'DUAL'\n",
      "    bt_type = constants.BluetoothDeviceType.from_str(\n",
      "        dict_data['DeviceType'].split('_')[-1])\n",
      "\n",
      "    mac_addr = dict_data['Address'],# Pattern to match message of logcat service.\n",
      "_LOGCAT_MSG_PATTERN = constants.LOGTCAT_MSG_PATTERN\n",
      "\n",
      "\n",
      "class BTModule(core.UtilBase):\n",
      "  \"\"\"BT module to hold BT related functions define in this module.\"\"\"\n",
      "\n",
      "  NAME = BINDING_KEYWORD\n",
      "  DESCRIPTION = (\n",
      "      'Utility to support Bluetooth base operations such as turn on/off '\n",
      "      'Bluetooth.')\n",
      "\n",
      "  def __init__(self, ad: ANDROID_DEVICE):\n",
      "    super().__init__(ad)\n",
      "    self._bind(crash_since)\n",
      "    self._bind(dump_bluetooth_manager)\n",
      "    self._bind(enable_snoop_log)\n",
      "    self._bind(enable_gd_log_verbose)\n",
      "    self._bind(get_bluetooth_mac_address)\n",
      "    self._bind(get_bonded_devices)\n",
      "    self._bind(get_device_mac_by_name)\n",
      "    self._bind(get_connected_ble_devices)\n",
      "    self._bind(get_current_le_audio_active_group_id)\n",
      "    self._bind(is_le_audio_device_connected)\n",
      "    self._bind(is_bluetooth_enabled, 'is_enabled')\n",
      "    self._bind(list_paired_devices)\n",
      "    self._bind(unbond_device)\n",
      "    self.shell = safe_adb_shell(ad)\n",
      "    self.enable = partial(toggle_bluetooth, ad=ad, enabled=True)\n",
      "    self.disable = partial(toggle_bluetooth, ad=ad, enabled=False)\n",
      "\n",
      "  @property\n",
      "  def enabled(self):\n",
      "    return self.is_enabled()\n",
      "\n",
      "  @property\n",
      "  def bonded_devices(self):\n",
      "    return {d.name: d for d in self.get_bonded_devices()}\n",
      "\n",
      "  @property\n",
      "  def bonded_device_names(self):\n",
      "    return [device.name for device in self.bonded_devices]\n",
      "\n",
      "  @property\n",
      "  def paired_devices(self):\n",
      "    return {\n",
      "        d.name: d\n",
      "        for d in self.list_paired_devices(only_name=False)}\n",
      "\n",
      "  @property\n",
      "  def paired_device_names(self):\n",
      "    return self.list_paired_devices()\n",
      "\n",
      "  def restart(self):\n",
      "    \"\"\"Restarts the Bluetooth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resp.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd32f580-9f31-43c4-85a8-ac27fa517666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To turn off the Bluetooth of a device using the `bttc` package, you can follow these steps:\n",
      "\n",
      "1. Retrieve your device using the `bttc.get()` function.\n",
      "2. Access the Bluetooth attribute of the device.\n",
      "3. Call the `disable()` method to turn off the Bluetooth.\n",
      "\n",
      "Here is an example code snippet to demonstrate how to turn off the Bluetooth of a device using the\n",
      "package:\n",
      "\n",
      "```python\n",
      "# Import the package `bttc`\n",
      "import bttc\n",
      "\n",
      "# Retrieve your device. Please replace '36121FDJG000GR' with your device's serial number.\n",
      "dut = bttc.get('36121FDJG000GR')\n",
      "\n",
      "# Disable the Bluetooth of the device\n",
      "dut.bt.disable()\n",
      "```\n",
      "\n",
      "By calling `dut.bt.disable()`, you will turn off the Bluetooth of the device.\n"
     ]
    }
   ],
   "source": [
    "print_answer(resp.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311867bd-42c0-4130-96ac-f2950190fcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get the MAC address of a device using the `bttc` package, you can follow these steps:\n",
      "\n",
      "1. Import the necessary modules:\n",
      "```python\n",
      "from bttc import bt_utils\n",
      "```\n",
      "\n",
      "2. Retrieve your device by its serial number:\n",
      "```python\n",
      "dut = bt_utils.bind('36121FDJG000GR')\n",
      "```\n",
      "\n",
      "3. Get the Bluetooth MAC address of the device:\n",
      "```python\n",
      "mac_address = dut.bt.get_bluetooth_mac_address()\n",
      "print(mac_address)\n",
      "```\n",
      "\n",
      "This code snippet will retrieve the Bluetooth MAC address of the device with the serial number\n",
      "using the `bttc` package.\n"
     ]
    }
   ],
   "source": [
    "print_answer(llm_agent.answer_with_rag(\n",
    "    collection=collection,                                  # Vectorstore containing BTTC embeddings\n",
    "    question='How to get the MAC address of device by bttc?',     # Question to query the RAG-augmented LLM\n",
    "    rag_max_doc_count=5,                                    # Maximum number of relevant embeddings to consider\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae102915-2715-4234-a3f0-115cfda93b67",
   "metadata": {},
   "source": [
    "As before, you import dependencies, define configuration variables, set your OpenAI API key, and obtain the collection `bttc_docs`. You then define context and question variables that you’ll feed into an LLM for inference. <b>The key difference in context is the `{}` at the end, which will be replaced with relevant reviews that give the LLM context to base its answers on</b>.\n",
    "\n",
    "You then pass the question into <font color='blue'>collection.query()</font> and request ten documents that are most related to the question. In this query. Lastly, you pass the comma-separated `review_str` into context and request an answer from \"`gpt-3.5-turbo`\".\n",
    "\n",
    "Notice how much more specific and detailed ChatGPT’s response is now that you’ve given it relevant documents as context. For example, if you look through the documents in `related_docs`, then you’ll see source code that mention how to turn off bluetooth which are incorporated into the LLM’s response.\n",
    "\n",
    "<b><font color='darkred'>Note.</font></b>\n",
    "> <b>It’s a common misconception that setting <font color='blue'>temperature=0</font> guarantees deterministic responses from ChatGPT</b>. While responses are closer to deterministic when temperature=0, [there’s no guarantee](https://arxiv.org/pdf/2308.02828#:~:text=We%20study%20the%20influence%20of,contrary%20to%20many%20people%27s%20beliefs.) that you’ll get the same response for identical requests. Because of this, ChatGPT might output slightly different results than what you see in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38dfdf-2619-4229-9ae9-df26d4674479",
   "metadata": {},
   "source": [
    "<b>You’ve now seen why vector databases like ChromaDB are so useful for adding context to LLMs. In this example, you’ve scratched the surface of what you can create with ChromaDB, so just think about all the potential use cases for applications like this</b>. The LLM and vector database landscape will likely continue to evolve at a rapid pace, but you can now feel confident in your understanding of how the two technologies interplay with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843c4db-e878-4b1d-b4c2-71b9e27775d6",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [Medium - Code Generation using Retrieval Augmented Generation + LangChain](https://medium.com/@rubenszimbres/code-generation-using-retrieval-augmented-generation-langchain-861e3c1a1a53)\n",
    "* [Chroma API Cheetsheet](https://docs.trychroma.com/api-reference)\n",
    "* [RealPython - Prompt Engineering: A Practical Example](https://realpython.com/practical-prompt-engineering/#add-a-role-prompt-to-set-the-tone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
