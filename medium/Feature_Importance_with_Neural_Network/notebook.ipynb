{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article source](https://towardsdatascience.com/feature-importance-with-neural-network-346eb6205743)) <font size='3ptx'>**Make Machine Learning easy interpretable providing variable relationships explanation**</font>\n",
    "\n",
    "**One of the best challenges in Machine Learning tends to let the model speak themself**. It not also is important to develop a strong solution with great predicting power, but also in a lot of business applications is interesting to know how the model provides these results: **which variables are engaged the most, the presence of correlations, the possible causation relationships and so on.**\n",
    "\n",
    "These needs made the Tree-based model a good weapon in this field. They are scalable and permits to compute variable explanation very easy. Every software provides this option and each of us has at least once tried to compute the variable importance report with Random Forest or similar. <font color='darkred'>**With Neural Net this kind of benefit is considered taboo. Neural Network is often seen as a black box, from which it is very difficult to extract useful information for another purpose like feature explanations.**</font>\n",
    "\n",
    "**In this post, I try to provide an elegant and clever solution, that with few lines of codes, permits you to squeeze your Machine Learning Model and extract as much information as possible**, in order to provide feature importance, individuate the significant correlations and try to explain causation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>THE DATASET</font>\n",
    "Given a real dataset, we try to investigate which factors influence the final prediction performances. To achieve this aim we took data from [**UCI Machine Learning Repository**](https://archive.ics.uci.edu/ml/index.php). The [privileged dataset was the Combined Cycle Power Plant Dataset](https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant), where were collected 6 years of data when the power plant was set to work with full load. Features consist of hourly average variables: `Ambient Temperature` (AT), `Ambient Pressure` (AP), `Relative Humidity` (RH) and `Exhaust Vacuum` (V) to predict the `net hourly electrical energy output` (PE) of the plant.\n",
    "\n",
    "The variables engaged are related by [Pearson correlation linkages](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) as shown in the matrix below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.34</td>\n",
       "      <td>40.77</td>\n",
       "      <td>1010.84</td>\n",
       "      <td>90.01</td>\n",
       "      <td>480.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.64</td>\n",
       "      <td>58.49</td>\n",
       "      <td>1011.40</td>\n",
       "      <td>74.20</td>\n",
       "      <td>445.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.74</td>\n",
       "      <td>56.90</td>\n",
       "      <td>1007.15</td>\n",
       "      <td>41.91</td>\n",
       "      <td>438.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.07</td>\n",
       "      <td>49.69</td>\n",
       "      <td>1007.22</td>\n",
       "      <td>76.79</td>\n",
       "      <td>453.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.80</td>\n",
       "      <td>40.66</td>\n",
       "      <td>1017.13</td>\n",
       "      <td>97.20</td>\n",
       "      <td>464.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0   8.34  40.77  1010.84  90.01  480.48\n",
       "1  23.64  58.49  1011.40  74.20  445.75\n",
       "2  29.74  56.90  1007.15  41.91  438.76\n",
       "3  19.07  49.69  1007.22  76.79  453.09\n",
       "4  11.80  40.66  1017.13  97.20  464.43"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset from CSV\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"../../datas/CCPP/Folds5x2_pp.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [9, 6]\n",
    "corrMatrix = df.corr()\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>GRADIENT BOOSTING FEATURE IMPORTANCE</font>\n",
    "**We start building a simple Tree-based model in order to provide energy output** (PE) **predictions and compute the standard feature importance estimations**. This final step permits us to say more about the variable relationships than a standard correlation index. These numbers summarized the reduction in impurity index over all trees when a particular feature is pointed during internal space partition (<font color='brown'>in training phase</font>). Sklearn applies normalization in order to provide output summable to one. It is also a free result, obtainable indirectly after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1e00ed0a240>,\n",
       "  <matplotlib.axis.XTick at 0x1e00ed0a518>,\n",
       "  <matplotlib.axis.XTick at 0x1e00ed0ab00>,\n",
       "  <matplotlib.axis.XTick at 0x1e00ed5c0f0>],\n",
       " [Text(0, 0, 'AT'), Text(0, 0, 'V'), Text(0, 0, 'AP'), Text(0, 0, 'RH')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "X = df.loc[:, df.columns != 'PE']\n",
    "y = df['PE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=100)\n",
    "gb.fit(X_train, y_train.values.ravel())\n",
    "plt.bar(range(X_train.shape[1]), gb.feature_importances_)\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns) # ['AT','V','AP','RH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is easily interpretable and seems to replicate the initial assumption made computing correlations with our target variable (<font color='brown'>last row of correlation matrix</font>): **higher the value, higher is the impact of this particular feature predicting our target.**\n",
    "\n",
    "Despite the goods results we achieved with our [**Gradient Boosting**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) we don’t want to completely depend by this kind of approach… **We want to generalize the process of computing feature importance, let us free to develop another kind of Machine Learning model with the same flexibility and explainability power; making also a step further: provide evidence of the presence of significant casualty relationship among variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>PERMUTATION IMPORTANCE</font>\n",
    "The models identified for our experiment are doubtless Neural Networks for their reputation to be a black box algorithm. In order to demystify this stereotype, **we’ll focus on Permutation Importance. Its easy implementation, combined with its tangible understanding and adaptability, making it a consistent candidate to answer the question: What features have the biggest impact on predictions?**\n",
    "\n",
    "Permutation importance is calculated after a model has been fitted. So we have only to squeeze it and get what we want. **This method works on a simple principle: If I randomly shuffle a single feature in the data, leaving the target and all others in place, how would that affect the final prediction performances?**\n",
    "\n",
    "From this random reordering of variables I expect to obtain:\n",
    "* Less accurate predictions, since the resulting data no longer corresponds to anything observed in the real world;\n",
    "* Worst performances, from the shuffle of the most important variables. This is because we are corrupting the natural structure of data. If we, with our shuffle, break a strong relationship we’ll compromise what our model has learned during training, resulting in higher errors (<font color='brown'>high error = high importance</font>).\n",
    "\n",
    "![Image1](images/1.png)\n",
    "<br/>\n",
    "\n",
    "Practically speaking this is what’s happened in our real scenario…\n",
    "\n",
    "We chose an adequate Neural Net structure to model the hourly electrical energy output (EP). Remember to scale also the target variable in a lower range: I classically subtracted mean and divided for standard deviation, this helps the train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 - 0s - loss: 0.1940\n",
      "Epoch 2/100\n",
      "60/60 - 0s - loss: 0.0641\n",
      "Epoch 3/100\n",
      "60/60 - 0s - loss: 0.0616\n",
      "Epoch 4/100\n",
      "60/60 - 0s - loss: 0.0608\n",
      "Epoch 5/100\n",
      "60/60 - 0s - loss: 0.0604\n",
      "Epoch 6/100\n",
      "60/60 - 0s - loss: 0.0603\n",
      "Epoch 7/100\n",
      "60/60 - 0s - loss: 0.0593\n",
      "Epoch 8/100\n",
      "60/60 - 0s - loss: 0.0590\n",
      "Epoch 9/100\n",
      "60/60 - 0s - loss: 0.0591\n",
      "Epoch 10/100\n",
      "60/60 - 0s - loss: 0.0600\n",
      "Epoch 11/100\n",
      "60/60 - 0s - loss: 0.0583\n",
      "Epoch 12/100\n",
      "60/60 - 0s - loss: 0.0585\n",
      "Epoch 13/100\n",
      "60/60 - 0s - loss: 0.0584\n",
      "Epoch 14/100\n",
      "60/60 - 0s - loss: 0.0578\n",
      "Epoch 15/100\n",
      "60/60 - 0s - loss: 0.0581\n",
      "Epoch 16/100\n",
      "60/60 - 0s - loss: 0.0576\n",
      "Epoch 17/100\n",
      "60/60 - 0s - loss: 0.0574\n",
      "Epoch 18/100\n",
      "60/60 - 0s - loss: 0.0570\n",
      "Epoch 19/100\n",
      "60/60 - 0s - loss: 0.0569\n",
      "Epoch 20/100\n",
      "60/60 - 0s - loss: 0.0568\n",
      "Epoch 21/100\n",
      "60/60 - 0s - loss: 0.0571\n",
      "Epoch 22/100\n",
      "60/60 - 0s - loss: 0.0572\n",
      "Epoch 23/100\n",
      "60/60 - 0s - loss: 0.0565\n",
      "Epoch 24/100\n",
      "60/60 - 0s - loss: 0.0564\n",
      "Epoch 25/100\n",
      "60/60 - 0s - loss: 0.0558\n",
      "Epoch 26/100\n",
      "60/60 - 0s - loss: 0.0564\n",
      "Epoch 27/100\n",
      "60/60 - 0s - loss: 0.0556\n",
      "Epoch 28/100\n",
      "60/60 - 0s - loss: 0.0563\n",
      "Epoch 29/100\n",
      "60/60 - 0s - loss: 0.0558\n",
      "Epoch 30/100\n",
      "60/60 - 0s - loss: 0.0554\n",
      "Epoch 31/100\n",
      "60/60 - 0s - loss: 0.0552\n",
      "Epoch 32/100\n",
      "60/60 - 0s - loss: 0.0549\n",
      "Epoch 33/100\n",
      "60/60 - 0s - loss: 0.0546\n",
      "Epoch 34/100\n",
      "60/60 - 0s - loss: 0.0546\n",
      "Epoch 35/100\n",
      "60/60 - 0s - loss: 0.0546\n",
      "Epoch 36/100\n",
      "60/60 - 0s - loss: 0.0555\n",
      "Epoch 37/100\n",
      "60/60 - 0s - loss: 0.0548\n",
      "Epoch 38/100\n",
      "60/60 - 0s - loss: 0.0545\n",
      "Epoch 39/100\n",
      "60/60 - 0s - loss: 0.0539\n",
      "Epoch 40/100\n",
      "60/60 - 0s - loss: 0.0544\n",
      "Epoch 41/100\n",
      "60/60 - 0s - loss: 0.0549\n",
      "Epoch 42/100\n",
      "60/60 - 0s - loss: 0.0540\n",
      "Epoch 43/100\n",
      "60/60 - 0s - loss: 0.0539\n",
      "Epoch 44/100\n",
      "60/60 - 0s - loss: 0.0537\n",
      "Epoch 45/100\n",
      "60/60 - 0s - loss: 0.0533\n",
      "Epoch 46/100\n",
      "60/60 - 0s - loss: 0.0534\n",
      "Epoch 47/100\n",
      "60/60 - 0s - loss: 0.0538\n",
      "Epoch 48/100\n",
      "60/60 - 0s - loss: 0.0539\n",
      "Epoch 49/100\n",
      "60/60 - 0s - loss: 0.0529\n",
      "Epoch 50/100\n",
      "60/60 - 0s - loss: 0.0538\n",
      "Epoch 51/100\n",
      "60/60 - 0s - loss: 0.0531\n",
      "Epoch 52/100\n",
      "60/60 - 0s - loss: 0.0529\n",
      "Epoch 53/100\n",
      "60/60 - 0s - loss: 0.0529\n",
      "Epoch 54/100\n",
      "60/60 - 0s - loss: 0.0529\n",
      "Epoch 55/100\n",
      "60/60 - 0s - loss: 0.0532\n",
      "Epoch 56/100\n",
      "60/60 - 0s - loss: 0.0525\n",
      "Epoch 57/100\n",
      "60/60 - 0s - loss: 0.0529\n",
      "Epoch 58/100\n",
      "60/60 - 0s - loss: 0.0524\n",
      "Epoch 59/100\n",
      "60/60 - 0s - loss: 0.0525\n",
      "Epoch 60/100\n",
      "60/60 - 0s - loss: 0.0518\n",
      "Epoch 61/100\n",
      "60/60 - 0s - loss: 0.0521\n",
      "Epoch 62/100\n",
      "60/60 - 0s - loss: 0.0521\n",
      "Epoch 63/100\n",
      "60/60 - 0s - loss: 0.0518\n",
      "Epoch 64/100\n",
      "60/60 - 0s - loss: 0.0519\n",
      "Epoch 65/100\n",
      "60/60 - 0s - loss: 0.0516\n",
      "Epoch 66/100\n",
      "60/60 - 0s - loss: 0.0516\n",
      "Epoch 67/100\n",
      "60/60 - 0s - loss: 0.0521\n",
      "Epoch 68/100\n",
      "60/60 - 0s - loss: 0.0514\n",
      "Epoch 69/100\n",
      "60/60 - 0s - loss: 0.0520\n",
      "Epoch 70/100\n",
      "60/60 - 0s - loss: 0.0515\n",
      "Epoch 71/100\n",
      "60/60 - 0s - loss: 0.0519\n",
      "Epoch 72/100\n",
      "60/60 - 0s - loss: 0.0516\n",
      "Epoch 73/100\n",
      "60/60 - 0s - loss: 0.0510\n",
      "Epoch 74/100\n",
      "60/60 - 0s - loss: 0.0507\n",
      "Epoch 75/100\n",
      "60/60 - 0s - loss: 0.0508\n",
      "Epoch 76/100\n",
      "60/60 - 0s - loss: 0.0513\n",
      "Epoch 77/100\n",
      "60/60 - 0s - loss: 0.0505\n",
      "Epoch 78/100\n",
      "60/60 - 0s - loss: 0.0509\n",
      "Epoch 79/100\n",
      "60/60 - 0s - loss: 0.0511\n",
      "Epoch 80/100\n",
      "60/60 - 0s - loss: 0.0511\n",
      "Epoch 81/100\n",
      "60/60 - 0s - loss: 0.0506\n",
      "Epoch 82/100\n",
      "60/60 - 0s - loss: 0.0505\n",
      "Epoch 83/100\n",
      "60/60 - 0s - loss: 0.0505\n",
      "Epoch 84/100\n",
      "60/60 - 0s - loss: 0.0508\n",
      "Epoch 85/100\n",
      "60/60 - 0s - loss: 0.0502\n",
      "Epoch 86/100\n",
      "60/60 - 0s - loss: 0.0502\n",
      "Epoch 87/100\n",
      "60/60 - 0s - loss: 0.0509\n",
      "Epoch 88/100\n",
      "60/60 - 0s - loss: 0.0509\n",
      "Epoch 89/100\n",
      "60/60 - 0s - loss: 0.0501\n",
      "Epoch 90/100\n",
      "60/60 - 0s - loss: 0.0496\n",
      "Epoch 91/100\n",
      "60/60 - 0s - loss: 0.0496\n",
      "Epoch 92/100\n",
      "60/60 - 0s - loss: 0.0497\n",
      "Epoch 93/100\n",
      "60/60 - 0s - loss: 0.0503\n",
      "Epoch 94/100\n",
      "60/60 - 0s - loss: 0.0504\n",
      "Epoch 95/100\n",
      "60/60 - 0s - loss: 0.0498\n",
      "Epoch 96/100\n",
      "60/60 - 0s - loss: 0.0500\n",
      "Epoch 97/100\n",
      "60/60 - 0s - loss: 0.0495\n",
      "Epoch 98/100\n",
      "60/60 - 0s - loss: 0.0494\n",
      "Epoch 99/100\n",
      "60/60 - 0s - loss: 0.0493\n",
      "Epoch 100/100\n",
      "60/60 - 0s - loss: 0.0492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e01c1a2c50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "inp = Input(shape=(X_train_scaled.shape[1],))\n",
    "x = Dense(128, activation='relu')(inp)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "out = Dense(1)(x)\n",
    "model = Model(inp, out)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train_scaled, (y_train - y_train.mean())/y_train.std() , epochs=100, batch_size=128 ,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the prediction stage, the Gradient Boosting and the Neural Net achieve the same performance in terms of [**Mean Absolute Error**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html), respectively 2.92 and 0.17 (<font color='brown'>remember to reverse predictions</font>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "gb_y_pred = gb.predict(X_test)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_stdzed = (y_test - y_test.mean())/y_test.std()\n",
    "nn_y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB MAE=2.87\n",
      "NN MAE=0.17\n"
     ]
    }
   ],
   "source": [
    "print(f\"GB MAE={mean_absolute_error(y_test, gb_y_pred):.02f}\")\n",
    "\n",
    "NN_MAE = mean_absolute_error(y_test_stdzed, nn_y_pred)\n",
    "print(f\"NN MAE={NN_MAE:.02f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we ended with training and let’s start to randomly sample.\n",
    "\n",
    "We compute the shuffle of every feature on validation data (<font color='brown'>4 times in total = 4 explicative variables</font>) and provide error estimations at each step; remember to return the data to the original order at every step. Then I plot the MAE we achieved at every shuffle stage as percentage variation from the original MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.344993</td>\n",
       "      <td>0.238693</td>\n",
       "      <td>-1.286581</td>\n",
       "      <td>-1.105325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.810959</td>\n",
       "      <td>1.362691</td>\n",
       "      <td>-0.741407</td>\n",
       "      <td>0.264859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.243724</td>\n",
       "      <td>-0.739004</td>\n",
       "      <td>1.999702</td>\n",
       "      <td>-0.197132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.363990</td>\n",
       "      <td>-1.015874</td>\n",
       "      <td>2.294299</td>\n",
       "      <td>0.969859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.371761</td>\n",
       "      <td>0.823896</td>\n",
       "      <td>0.621529</td>\n",
       "      <td>-1.730695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AT         V        AP        RH\n",
       "0  1.344993  0.238693 -1.286581 -1.105325\n",
       "1  0.810959  1.362691 -0.741407  0.264859\n",
       "2 -0.243724 -0.739004  1.999702 -0.197132\n",
       "3 -1.363990 -1.015874  2.294299  0.969859\n",
       "4  1.371761  0.823896  0.621529 -1.730695"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns = X_test.columns)\n",
    "X_test_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled_df['AT'] = X_test_scaled_df['AT'] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.379972</td>\n",
       "      <td>0.238693</td>\n",
       "      <td>-1.286581</td>\n",
       "      <td>-1.105325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.243836</td>\n",
       "      <td>1.362691</td>\n",
       "      <td>-0.741407</td>\n",
       "      <td>0.264859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.974896</td>\n",
       "      <td>-0.739004</td>\n",
       "      <td>1.999702</td>\n",
       "      <td>-0.197132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.455962</td>\n",
       "      <td>-1.015874</td>\n",
       "      <td>2.294299</td>\n",
       "      <td>0.969859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.487046</td>\n",
       "      <td>0.823896</td>\n",
       "      <td>0.621529</td>\n",
       "      <td>-1.730695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AT         V        AP        RH\n",
       "0  5.379972  0.238693 -1.286581 -1.105325\n",
       "1  3.243836  1.362691 -0.741407  0.264859\n",
       "2 -0.974896 -0.739004  1.999702 -0.197132\n",
       "3 -5.455962 -1.015874  2.294299  0.969859\n",
       "4  5.487046  0.823896  0.621529 -1.730695"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on feature=AT (0)\n",
      "          AT         V        AP        RH\n",
      "0  21.519886  0.238693 -1.286581 -1.105325\n",
      "Working on feature=V (1)\n",
      "         AT         V        AP        RH\n",
      "0  5.379972  0.954772 -1.286581 -1.105325\n",
      "Working on feature=AP (2)\n",
      "         AT         V        AP        RH\n",
      "0  5.379972  0.238693 -5.146323 -1.105325\n",
      "Working on feature=RH (3)\n",
      "         AT         V        AP        RH\n",
      "0  5.379972  0.238693 -1.286581 -4.421302\n"
     ]
    }
   ],
   "source": [
    "mae_diff_dict = {} # key as feature, value as tuple(new_mse, shuffled_pred)\n",
    "for i, f in enumerate(X_test.columns):\n",
    "    print(f\"Working on feature={f} ({i})\")\n",
    "    X_test_scaled_df[f] = X_test_scaled_df[f] * 4    \n",
    "    print(X_test_scaled_df.head(1))\n",
    "    nn_y_pred_shuffled = model.predict(X_test_scaled_df)\n",
    "    new_mae = mean_absolute_error(nn_y_pred_shuffled, nn_y_pred)\n",
    "    mae_diff_dict[f] = (abs(new_mae - NN_MAE) * 100 / NN_MAE, nn_y_pred_shuffled)\n",
    "    X_test_scaled_df[f] = X_test_scaled_df[f] / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AT', 5938.62453985666),\n",
       " ('V', 818.1821894805488),\n",
       " ('AP', 1005.2811980847956),\n",
       " ('RH', 913.602108377995)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda t: (t[0], t[1][0]), mae_diff_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1e02d433470>,\n",
       "  <matplotlib.axis.XTick at 0x1e02d433438>,\n",
       "  <matplotlib.axis.XTick at 0x1e02d433240>,\n",
       "  <matplotlib.axis.XTick at 0x1e0349635c0>],\n",
       " [Text(0, 0, 'AT'), Text(0, 0, 'V'), Text(0, 0, 'AP'), Text(0, 0, 'RH')])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(X_train.shape[1]), list(map(lambda t:t[0], mae_diff_dict.values())))\n",
    "plt.xticks(range(X_train.shape[1]), mae_diff_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above replicates the RF feature importance report and confirms our initial assumption: **the `Ambient Temperature` (AT) is the most important and correlated feature to predict electrical energy output** (PE). Despite `Exhaust Vacuum` (V) and AT showed a similar and high correlation relationship with PE (<font color='brown'>respectively 0.87 and 0.95</font>), they have a different impact at the prediction stage. **This phenomenon is a soft example of how not always a high correlation** (<font color='brown'>in Pearson term</font>) **is synonymous of high explainability power**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>CAUSATION RELATIONSHIPS</font>\n",
    "Prove correlation, in order to avoid [spurious relationships](https://www.tylervigen.com/spurious-correlations), is always an insidious operation. At the same time, it is difficult to show evidence of casualty behaviors. In literature, there are a lot of methods to prove causality. One of the most important is the [**Granger Causality Test**](https://en.wikipedia.org/wiki/Granger_causality). This technique is widely applied in time series domain for determining whether one-time series is useful in forecasting another: i.e. demonstrate (<font color='brown'>according to an F-test on lagged values</font>) that it adds explanatory power to the regression.\n",
    "\n",
    "Indirectly this is what we have already done computing Permutation Importance. Shuffling every variable and looking for performance variations, we are proving how much explicative power has this feature to predict the desired target.\n",
    "\n",
    "**In order to prove causation, what we have to do now is to demonstrate that the data shuffle provides significative evidence in performance variation.** We operate on the final predictions, achieved without and with shuffle, and verify if there is a difference in mean among the two prediction population. It means that the mean predictions with shuffle might as well be observed by any random subgroup of predictions. **So that’s exactly what we’ll do for every feature: we’ll merge prediction with and without permutation, we’ll randomly sample a group of predictions and calculate the difference between their mean value and the mean values of the prediction without shuffle.**\n",
    "```python\n",
    "np.random.seed(33)\n",
    "id_ = 0 #feature index\n",
    "merge_pred = np.hstack([shuff_pred[id_], real_pred])\n",
    "observed_diff = abs(shuff_pred[id_].mean() - merge_pred.mean())\n",
    "extreme_values = []\n",
    "sample_d = []\n",
    "for _ in range(10000):\n",
    "    sample_mean = np.random.choice(merge_pred,\n",
    "                  size=shuff_pred[id_].shape[0]).mean()\n",
    "    sample_diff = abs(sample_mean - merge_pred.mean())\n",
    "    sample_d.append(sample_diff)\n",
    "    extreme_values.append(sample_diff >= observed_diff)\n",
    "    \n",
    "np.sum(extreme_values)/10000 #p-value\n",
    "```\n",
    "\n",
    "In order to have all under control, it’s a good choice to visualize the results of our simulations. We plot the distribution of the simulated mean differences (blue bar) and mark the real observed difference (red line). We can see that for `AT` there is evidence for a difference in mean with the prediction made without shuffle (<font color='brown'>low [**p-value**](https://en.wikipedia.org/wiki/P-value): below 0.1</font>). The other variables don’t bring a significant improvement in the mean.\n",
    "![a](https://miro.medium.com/max/700/1*mHrDvp8RK7o_HF-SeO9R2w.png)\n",
    "\n",
    "**Correlation doesn’t always imply causation! With this in mind, we proved causation in terms of the ability of a selected feature to add explicative power.** We’ve recreated, with our knowledge of statistician and programmer, a way to prove this concept making use of our previous findings made with permutation importance, adding information about the relationships of our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Scikit-learn Permutation Importance</font>\n",
    "You can also leverage [**scikit-learn API**](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html) to calculate feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 7.85754\n",
      "Feature: 1, Score: -0.24419\n",
      "Feature: 2, Score: 0.68341\n",
      "Feature: 3, Score: 0.88903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import plt\n",
    "\n",
    "# perform permutation importance\n",
    "results = permutation_importance(model, X_test_scaled, y_test_stdzed, scoring='neg_mean_squared_error')\n",
    "\n",
    "# get importance\n",
    "importance = results.importances_mean\n",
    "\n",
    "# summarize feature importance\n",
    "for i, v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1e0390ca898>,\n",
       "  <matplotlib.axis.XTick at 0x1e0390cab38>,\n",
       "  <matplotlib.axis.XTick at 0x1e0390ca7f0>,\n",
       "  <matplotlib.axis.XTick at 0x1e0390af5f8>],\n",
       " [Text(0, 0, 'AT'), Text(0, 0, 'V'), Text(0, 0, 'AP'), Text(0, 0, 'RH')])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "plt.bar(range(X_train.shape[1]), importance)\n",
    "plt.xticks(range(X_train.shape[1]), mae_diff_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>SUMMARY</font>\n",
    "In this post, I’ve introduced Permutation Importance, an easy and clever technique to compute feature importance. It’s useful with every kind of model (<font color='brown'>I use Neural Net only as a personal choice</font>) and in every problem (<font color='brown'>an analog procedure is applicable in a classification task: remember to choose an adequate loss measure when computing permutation importance, like cross-entropy, avoiding the ambiguous accuracy</font>). We’ve also used the permutations to present a method that proves casualty among variables hacking the p-value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Supplement</font>\n",
    "* [Using neural network to calculate feature importance](https://www.kaggle.com/anycode/feature-importance-using-nn)\n",
    "* [How to Calculate Feature Importance With Python](https://machinelearningmastery.com/calculate-feature-importance-with-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
