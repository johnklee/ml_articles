{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6968b50a",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article source](https://towardsdatascience.com/explain-machine-learning-models-partial-dependence-ce6b9923034f)) <font size='3ptx'><b>Making black box models a thing of the past</b></font>\n",
    "\n",
    "<b>With all the complexity that comes with developing machine learning models, it comes as no surprise that some of these just don’t translate very well when being explained in plain English</b>. The model inputs go in, the answers come out and no one knows how exactly the model arrived at this conclusion. This can result in some sort of disconnect or lack of transparency between different members working on the same team. As the prevalence of machine learning has increased in recent years, this lack of explainability when using complex models has grown even more. <b>In this article, I’ll discuss a few ways to make your models more explainable to the average person whether they be your non-technical manager or just a curious friend</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582029fe",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Why is explainability important?</font>\n",
    "<font size='3ptx'><b>The responsibility that falls on machine learning models has only increased over time. </b></font>\n",
    "\n",
    "They are responsible for everything from filtering spam in your email to deciding if you qualify for that new job or loan you’ve been looking for. <b>When these models can’t be explained in plain English, a lack of trust ensues and people become reluctant to use your model for any important decisions</b>.\n",
    "\n",
    "It would be a shame if the model you worked so hard to create ended up not being discarded because no one could understand what it was doing. <b>In being able to explain a model and show insights that come from it, people</b> (<font color='brown'>especially those with no background in data science</font>) <b>will be a lot more likely to trust and use the models that you create</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62569c8f",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Interpreting Coefficients</font>\n",
    "<b><font size='3ptx'>On one end of the spectrum, we have simple models like linear regression.</font></b>\n",
    "\n",
    "Models like this are quite simple to explain, with each coefficient representing how much a feature affects our target. e.g.:\n",
    "![linear model](images/1.PNG)\n",
    "\n",
    "<br/>\n",
    "\n",
    "The image above shows the plot for a model represented by the equation $y=2x$. This just means that for an increase of 1 in feature x, the target variable will increase by 2. You can have multiple features like this; each one with its own coefficient representing its effect on the target.\n",
    "\n",
    "On the other end, we have “black box” models like neural networks where all we can see are the inputs and outputs but the meanings and steps taken to get from input to output are effectively blocked by a sea of incomprehensible numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef0a85",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Partial Dependence</font>\n",
    "<font size='3ptx'><b>Partial dependence shows how a particular feature affects a prediction. </b></font>\n",
    "\n",
    "<b>By making all other features constant, we want to find out how the feature in question influences our outcome</b>. This is similar to interpreting coefficients explained in the previous section but partial dependence allows us to generalize this interpretation to models more sophisticated and complex than simple linear regression.\n",
    "\n",
    "As an example, we’ll be using a decision tree on this [**Cardiovascular Disease dataset on Kaggle**](https://www.kaggle.com/sulianova/cardiovascular-disease-dataset). The library we’ll be using to plot partial dependence is [**pdpbox**](https://github.com/SauceCat/PDPbox). Let’s train the model and see how this all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed3743b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdpbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdpbox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdp\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpdp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdpbox'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pdpbox.pdp as pdp\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de290ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
