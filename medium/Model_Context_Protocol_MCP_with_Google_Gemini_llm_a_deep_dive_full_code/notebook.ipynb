{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18244b7-a8e9-4f33-84f2-9cd2fe659b16",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Model Context Protocol(MCP) with Google Gemini 2.5 Pro — A Deep Dive (Full Code)</font></b>\n",
    "([source](https://medium.com/google-cloud/model-context-protocol-mcp-with-google-gemini-llm-a-deep-dive-full-code-ea16e3fac9a3)) <b><font size='3ptx'>A step-by-step guide with code, architecture, and real-world use case</font></b>\n",
    "\n",
    "As Large Language Models (LLMs) like GPT-4, Claude, Gemini and Llama3 evolve , we need standardized ways to connect them to tools, APIs, and systems .However, these models operate in isolation based on pre-trained data and don’t have built-in access to real-time data, databases , external APIs, or local files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34177c-7908-4a7a-9d99-8dcd2756bd83",
   "metadata": {},
   "source": [
    "<b>In this article , we’ll discuss more on Model Context Protocol (MCP) concept before diving into implementation :</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be63d11-ad6f-4de5-90c2-80267e81924b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>1. What is Model Context Protocol (MCP) ?</font></b>\n",
    "<font size='3ptx'><b>The [**Model Context Protocol (MCP)**](https://modelcontextprotocol.io/introduction) is a standardized, open protocol developed by Anthropic that enables AI models to seamlessly interact with external data sources and tools</b>, acting as a universal connector for AI integrations.</font>\n",
    "> Think of MCP as a “USB-C for AI integrations,” providing a universal way for AI models to connect to different devices and data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a9b82-777b-42a8-a2e7-8a0de99c1364",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>How MCP works ?</font></b>\n",
    "<b><font size='3ptx'>MCP follows a client-server architecture, where</font></b>:\n",
    "* <b>Clients</b> (like AI applications or LLMs) connect to\n",
    "* <b>Servers</b> (MCP tool providers) expose tools, APIs, or data sources to clients.\n",
    "\n",
    "This enables dynamic and structured interactions between LLM models and the external API’s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6b26b-e7ac-4998-b16b-d0373decd427",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>Benefits of MCP.</font></b>\n",
    "MCP transforms the API into a model-friendly tool, complete with auto-discovery, a predictable schema, and structured interaction.\n",
    "\n",
    "1. <b><font size='3ptx'>Standardized Integration</font></b>: Connect LLMs to any external system with less custom work.\n",
    "2. <b><font size='3ptx'>Flexibility</font></b>: LLMs can use multiple tools and services — on demand.\n",
    "3. <b><font size='3ptx'>Security</font></b>: Supports secure API interaction without hardcoding credentials.\n",
    "4. <b><font size='3ptx'>Simplified Development</font></b>: Build and expose custom MCP servers easily.\n",
    "5. <b><font size='3ptx'>Easier Maintenance</font></b>: No more repetitive integration logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc5fb4-2895-4eea-af69-5177ad778842",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Examples of MCP Servers</font></b>\n",
    "* <b><font size='3ptx'>File System</font></b>: Accessing local files and directories.\n",
    "* <b><font size='3ptx'>Web Search</font></b>: Run real-time web searches.\n",
    "* <b><font size='3ptx'>Databases</font></b>: Query SQL or NoSQL databases\n",
    "* <b><font size='3ptx'>CRMs</font></b>: Connecting to CRM systems like Salesforce.\n",
    "* <b><font size='3ptx'>Version Control</font></b>: Accessing version control systems like Git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52e2c3-7d5b-4df3-b8dc-3495de04c107",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>When to use Model Context Protocol (MCP) ?</font></b>\n",
    "MCP to be used when:\n",
    "* We’re building <b><font size='3ptx'>agentic systems</font></b>\n",
    "* We want tools to <b><font size='3ptx'>be modular, reusable, discoverable</font></b>\n",
    "* We want use multiple external sources -\n",
    "* We want scaling to <b><font size='3ptx'>multiple tools or toolchains</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808d46e-0c38-4f47-9493-6114c90bfd18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>Architecture</font></b>\n",
    "Below project integrates multiple components to enable natural language flight search using Gemini + MCP:\n",
    "![MCP Architecture](images/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded092f-1f88-4344-9d16-7d6e6c3394d4",
   "metadata": {},
   "source": [
    "#### <b>Component Interactions</b>\n",
    "1. <b><font size='3ptx'>User to Client</font></b>\n",
    "    - User provides natural language query (<font color='brown'>e.g., “Find flights from Atlanta to Las Vegas tomorrow”</font>)\n",
    "    - Client script (`client.py`) processes the input\n",
    "2. <b><font size='3ptx'>Client to MCP Server</font></b>\n",
    "    - Client starts the MCP server process (`mcp-flight-search`)\n",
    "    - Establishes stdio communication channel.\n",
    "    - Retrieves available tools and their descriptions\n",
    "3. <b><font size='3ptx'>Client to Gemini API</font></b>\n",
    "    - Sends the user’s query\n",
    "    - Provides tool descriptions for function calling\n",
    "    - Receives structured function call with extracted parameters\n",
    "4. <b><font size='3ptx'>Client to MCP Tool</font></b>\n",
    "    - Takes function call parameters from Gemini\n",
    "    - Calls appropriate MCP tool with parameters\n",
    "    - Handles response processing\n",
    "5. <b><font size='3ptx'>MCP Server to SerpAPI</font></b>\n",
    "    - MCP server makes requests to SerpAPI\n",
    "    - Queries Google Flights data\n",
    "    - Processes and formats flight information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd86fbd-65ce-428e-8246-fedc2d608c84",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Implementation</font></b>\n",
    "([Github link of codes](https://github.com/arjunprabhulal/mcp-gemini-search)) <b><font size='3ptx'>Let us dive into building this pipeline with Gemini AI by breaking down into key implementation steps</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717a750d-d01b-4fd3-b002-434c5e859723",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>Pre-Requisites</font></b>\n",
    "1. Python 3.8+ installed\n",
    "2. [**Google Gemini**](https://makersuite.google.com/app) Generative AI access via [API key](https://aistudio.google.com/apikey)\n",
    "3. A valid [**SerpAPI key**](https://serpapi.com/) (used to fetch live flight data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38af3b-e968-48e5-87ed-356dd8b85f79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>Step 1 : Setup virtual environment</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edcb219-9ca5-44cb-82b8-c052b7ecb34b",
   "metadata": {},
   "source": [
    "#### <b>Install the dependancies</b>\n",
    "* [**google-genai**](https://ai.google.dev/gemini-api/docs/libraries): The official Python library for interacting with Google's Generative AI models (like Gemini).\n",
    "* [**mcp**](https://github.com/modelcontextprotocol/python-sdk): A Python SDK for interacting with an MCP (Model Context Protocol) server. This SDK likely provides functionalities to communicate with external tools or services.\n",
    "\n",
    "```shell\n",
    "#Setup virtual env\n",
    "$ python -n venv venv \n",
    "\n",
    "#Activate venv\n",
    "$ source venv/bin/activate\n",
    "\n",
    "#Install dependancies\n",
    "$ pip install google-genai mcp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ae58df-39f2-42d0-a344-ceb81b8f5a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastmcp==2.11.2\n",
      "google-genai==1.26.0\n",
      "langchain-google-genai==2.1.6\n",
      "langchain-mcp-adapters==0.0.7\n",
      "mcp==1.12.0\n",
      "mcp-flight-search==0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep -P \"(google-genai|mcp)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae9ee6-c948-43ec-8c35-c3589c4f7459",
   "metadata": {},
   "source": [
    "#### <b>Set Environment variables</b>\n",
    "\n",
    "```shell\n",
    "export GEMINI_API_KEY=\"your-google-api-key\"\n",
    "export SERP_API_KEY=\"your-serpapi-key\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f0b4f-24e9-46e9-8760-929e522c4812",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Step 2: Install the MCP Server — mcp-flight-search</font></b>\n",
    "<b><font size='3ptx'>To enable Gemini to interact with real-world APIs, we’ll use an MCP-compliant server.</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d32fc-f268-4016-9951-52f3beb028f1",
   "metadata": {},
   "source": [
    "For this article, we’ll use [**mcp-flight-search**](https://github.com/arjunprabhulal/mcp-flight-search) — a lightweight MCP Server built using [**FastMCP**](https://github.com/jlowin/fastmcp) which exposes a tool that searches real-time flight data using the SerpAPI. Install MCP server package where I published to PyPi:\n",
    "```shell\n",
    "# Install from PyPI\n",
    "$ pip install mcp-flight-search\n",
    "```\n",
    "\n",
    "Let us verify if MCP server package is installed successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5fd5e3-0799-48e2-aaea-ceef6423acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mcp-flight-search\n",
      "Version: 0.2.1\n",
      "Summary: Flight search service implementing  Model Context Protocol (MCP) tools\n",
      "Home-page: https://github.com/arjunprabhulal/mcp-flight-search\n",
      "Author: \n",
      "Author-email: Arjun Prabhulal <code.aicloudlab@gmail.com>\n",
      "License: \n",
      "Location: /usr/local/google/home/johnkclee/Github/ml_articles/env/lib/python3.12/site-packages\n",
      "Requires: fastmcp, google-search-results, pydantic, python-dotenv, rich\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show 'mcp-flight-search'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd45c5f7-0a83-420a-a61d-441e2804622d",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Step 3 : Understanding MCP Tool Packages</font></b>\n",
    "<b><font size='3ptx'>Import library which initializes both Gemini and MCP SDKs and prepares for async execution...</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2986902-9d22-4298-973f-7b90e6404c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b4ece-7b5e-4757-b606-9dcf198cc48e",
   "metadata": {},
   "source": [
    "Above imports the <b>genai</b> module from the <b>google-generativeai</b> library. It <b><font size='3ptx'>provides access to Google’s powerful LLMs, such as Gemini 1.5 and 2.0,2.5 model and includes client methods to interact with models using natural language</font></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a3ff948-9eeb-4a00-9be1-91df4ade7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d902a55-d70c-42ad-a443-8fb5f422ef05",
   "metadata": {},
   "source": [
    "Above module gives access to the <b>type definitions and configuration structures</b> used by the Gemini API. For example:\n",
    "- <b>Tool</b>: Defines tools (functions) that the model can call.\n",
    "- <b>GenerateContentConfig</b>: Allows us to configure how the model responds (e.g., temperature, tool support, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b55cff-d04a-46b9-ab5c-4b00a94e15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp import ClientSession, StdioServerParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7da6fe-89cc-45cb-a245-35b2b536c66d",
   "metadata": {},
   "source": [
    "Above classes come from the [**mcp-sdk-python**](https://pypi.org/project/mcp-sdk-python/) library and are essential for interacting with <b>MCP servers</b>:\n",
    "- <b><font size='3ptx'>ClientSession</font></b>: Manages the communication session between our client/app and the MCP server.\n",
    "- <b><font size='3ptx'>StdioServerParameters</font></b>: stdio allows the server to be language-neutral and easily embedded in different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2fcac4a-635a-495a-862d-a1da3ad5f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.client.stdio import stdio_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4dd82-0d6f-44f6-8c05-9ed1645fe0a2",
   "metadata": {},
   "source": [
    "This imports the <font size='3ptx'><b>`stdio_client`, an asynchronous context manager used to establish a connection with an MCP server over standard I/O</b></font>. It ensures that the server is correctly launched, and the client is ready to send/receive structured requests.\n",
    "\n",
    "Above 4 key imports together form the backbone of how we <b><font size='3ptx'>bridge Gemini’s LLM interaction with real-world APIs exposed via MCP tools</font></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8e2fe-b0df-4dc9-9535-42007aa27252",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Step 4: Initialize Gemini Client</font></b>\n",
    "<font size='3ptx'><b>`genai.Client()`</b> is the primary interface used to interact with Google’s generative models (<font color='brown'>e.g., Gemini 2.5 Pro, Gemini 2 Flash</font>)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff89eca0-9187-45f6-8cbf-3b120041c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d546ee-8243-4f5b-a7db-bd5466907889",
   "metadata": {},
   "source": [
    "Once GenAI Client is initialized, this client object can:\n",
    "* Send prompts to Gemini models\n",
    "* Pass tool definitions (function calling)\n",
    "* Receive structured responses and function call objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5271a5-57cc-4e2e-9269-7e5a24f43514",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>Step 5 : Configure MCP Tool Server</font></b>\n",
    "<font size='3ptx'>Below block sets up the parameters required to <b>launch and communicate with the MCP server that exposes tools</b> (<font color='brown'>in our case, a flight search function</font>).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b091f5-61c6-4dc3-8d6d-22a6fee0a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_params = StdioServerParameters(\n",
    "    command=\"mcp-flight-search\",\n",
    "    args=[\"--connection_type\", \"stdio\"],\n",
    "    env={\"SERP_API_KEY\": os.getenv(\"SERP_API_KEY\")},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d77cde-f5da-46ef-a546-652ea74b7afa",
   "metadata": {},
   "source": [
    "- <b><font size='3ptx'>mcp-flight-search</font></b> — This is the CLI entry point to run local MCP server,or could be a Python module in our case that implements the MCP protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aede2db8-1331-4c47-86c7-77d2ca38166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: mcp-flight-search [-h] [--connection_type {http,stdio}] [--port PORT]\n",
      "\n",
      "Model Context Protocol Flight Search Service\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --connection_type {http,stdio}\n",
      "                        Connection type (http or stdio)\n",
      "  --port PORT           Port to run the server on (default: 3001)\n"
     ]
    }
   ],
   "source": [
    "!mcp-flight-search -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ef28b-1186-4a3e-83ee-9d72dac2fea0",
   "metadata": {},
   "source": [
    "* <b><font size='3ptx'>--connection_type stdio</font></b>: This tells the server to <b>use standard input/output (stdio) as its communication channel</b>. Stdio is simple, language-agnostic, and great for running tool servers locally or in subprocesses.\n",
    "\n",
    "* <b><font size='3ptx'>SERP_API_KEY</font></b> — This passes an environment variable (`SERP_API_KEY`) to the subprocess running the tool. In our case, the tool needs it to authenticate with SerpAPI, which fetches real-time flight data.\n",
    "\n",
    "\n",
    "Once `server_params` is defined, we can use it to spin up the server using the `stdio_client` async context manager.\n",
    "```python\n",
    ">>> import os\n",
    ">>> from google import genai\n",
    ">>> from google.genai import types\n",
    ">>> from mcp import ClientSession, StdioServerParameters\n",
    ">>> from mcp.client.stdio import stdio_client\n",
    ">>>\n",
    ">>> client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    ">>>\n",
    ">>> server_params = StdioServerParameters(\n",
    "...     command=\"mcp-flight-search\",\n",
    "...     args=[\"--connection_type\", \"stdio\"],\n",
    "...     env={\"SERP_API_KEY\": os.getenv(\"SERP_API_KEY\")},\n",
    "... )\n",
    ">>> server_params\n",
    "StdioServerParameters(command='mcp-flight-search', args=['--connection_type', 'stdio'], env={'SERP_API_KEY':'XXXXXXXXX'}, cwd=None, encoding='utf-8', encoding_error_handler='strict')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bff229-bb11-4519-8053-dabffad10152",
   "metadata": {},
   "source": [
    "The <b>Gemini client</b> handles language understanding, prompt generation, and function calling; The <b>MCP tool server</b> (flight search) listens for tool calls and executes them in real time via SerpAPI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f56690-d14d-4861-8435-00b338190da6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>Step 6 : Connecting to MCP Server and listing tools</font></b>\n",
    "<b><font size='3ptx'>Below block of code does three important steps</font></b>\n",
    "1. Starts connection with the MCP server ,\n",
    "2. Initializes a session for structured tool communication and\n",
    "3. Dynamically discovers and formats available tools for Gemini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d57ca64-1427-4209-b81d-3b3c2ac49406",
   "metadata": {},
   "source": [
    "```python\n",
    "async def run():\n",
    "    # Remove debug prints\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            prompt = f\"Find Flights from Atlanta to Las Vegas 2025-05-05\"\n",
    "            await session.initialize()\n",
    "            # Remove debug prints\n",
    "\n",
    "            mcp_tools = await session.list_tools()\n",
    "            # Remove debug prints\n",
    "            tools = [\n",
    "                types.Tool(\n",
    "                    function_declarations=[\n",
    "                        {\n",
    "                            \"name\": tool.name,\n",
    "                            \"description\": tool.description,\n",
    "                            \"parameters\": {\n",
    "                                k: v\n",
    "                                for k, v in tool.inputSchema.items()\n",
    "                                if k not in [\"additionalProperties\", \"$schema\"]\n",
    "                            },\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "                for tool in mcp_tools.tools\n",
    "            ]\n",
    "            # Remove debug prints\n",
    "\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.5-pro-exp-03-25\",\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=0,\n",
    "                    tools=tools,\n",
    "                ),\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b7551-a5a2-4547-86e7-52c70cfb1b51",
   "metadata": {},
   "source": [
    "Let us breakdown line-by-line to understand how the MCP Client-Server communication is happening under the hood along with Gemini LLM.\n",
    "\n",
    "**`stdio_client`** is an asynchronous context manager that handles:\n",
    "* Launching the MCP server as a subprocess.\n",
    "* Managing the input/output streams for message exchange\n",
    "\n",
    "**`read` and `write`** objects are asynchronous streams:\n",
    "* **`read`**: reads responses or tool registration from the server\n",
    "* **`write`**: sends requests or tool invocations to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a898f11-078b-4b15-b535-b9025064c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Find Flights from Atlanta to Las Vegas 2025-05-05\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d4947-d35c-49d9-afed-3280ec6ac637",
   "metadata": {},
   "source": [
    "Above prompt is <b><font size='3ptx'>natural language query</font></b> we’ll send to the Gemini model. which Gemini will later turn into a structured tool call.\n",
    "\n",
    "Line `await session.initialize()` is the one which <b><font size='3ptx'>triggers the initial MCP handshake between our client and the server</font></b>. server registers its available tools. From this step, it achieves:\n",
    "* Server registers its available tools (in our case: a **flight search tool**).\n",
    "* Session is now ready to list, call, and execute tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b13c7-6e5f-4879-90cf-d0aaa91a6d76",
   "metadata": {},
   "source": [
    "For line `mcp_tools = await session.list_tools()`, it requests the list of all tools (functions) exposed by the server. Each tool in **`mcp_tools.tools`** contains:\n",
    "* A name\n",
    "* A description\n",
    "* An input schema (<font color='brown'>i.e., what parameters it accepts, in JSON Schema format</font>)\n",
    "\n",
    "**`mcp_tools.tools`** makes the MCP server self-describing, so that LLM can automatically understand how to call each tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd61613-85b6-4ba2-b3ab-78ae889c8eaa",
   "metadata": {},
   "source": [
    "Regarding below codesnippet:\n",
    "```python\n",
    "tools = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            {\n",
    "                \"name\": tool.name,\n",
    "                \"description\": tool.description,\n",
    "                \"parameters\": {\n",
    "                    k: v\n",
    "                    for k, v in tool.inputSchema.items()\n",
    "                    if k not in [\"additionalProperties\", \"$schema\"]\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    for tool in mcp_tools.tools\n",
    "]\n",
    "```\n",
    "\n",
    "It converts the MCP tool definitions into [**Gemini’s function_declarations format**](https://ai.google.dev/gemini-api/docs/function-calling?example=weather#function_declarations). Now that our MCP server is running and session is initialized to discover tools from MCP Server for Gemini to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681038d-5ea7-4e76-8bd6-006f620e13bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>Step 7 : Gemini — Interprets Prompt and suggest a Function Call</font></b>\n",
    "<font size='3ptx'>Finally the <b>user’s prompt is sent to the Gemini model, along with a list of available tools discovered from the MCP server</b></font> by below code snippet:\n",
    "```python\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro-exp-03-25\",\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0,\n",
    "        tools=tools,\n",
    "    ),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94295503-e252-439c-a01b-b562147d200a",
   "metadata": {},
   "source": [
    "If Gemini recognizes the prompt as matching a `function’s schema`, it returns a `function_call` object that includes the tool name and the auto-filled parameters. If Gemini determines that the prompt aligns with a function (based on name, description, or parameters), it returns a structured `function_call` object like:\n",
    "```json\n",
    "{\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_flights\",\n",
    "    \"args\": {\n",
    "      \"source\": \"ATL\",\n",
    "      \"destination\": \"LAS\",\n",
    "      \"date\": \"2025-05-05\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Gemini LLM transitions from a passive text model to an active decision-maker that:\n",
    "* Interprets natural input\n",
    "* Selects an appropriate tool\n",
    "* Fills in the function’s arguments automatically\n",
    "* We didn’t write any parsing logic.\n",
    "* Gemini LLM model filled in all the fields by interpreting the user’s natural language.\n",
    "* function call is structured and ready for execution.\n",
    "\n",
    "Below code snippet show how to call the tool:\n",
    "```python\n",
    "result = await session.call_tool(\n",
    "    function_call.name, arguments=dict(function_call.args)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de68ff-9a6e-469f-b8a6-2d73b270252f",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Final Demo: Gemini 2.5 Pro with MCP</font></b>\n",
    "Below debug logs show exactly how Gemini , Model Context Protocol (MCP) work together to interpret user intent, match a tool, and return real-time data.\n",
    "![flow](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D0OHnjompVnvPNGBUdbfmQ.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edc587d-c07c-4c0a-a2dc-7d0e77680a4b",
   "metadata": {},
   "source": [
    "Or you can try local script `client.py`:\n",
    "```shell\n",
    "$ ./client.py \n",
    "...\n",
    "--- Formatted Result ---\n",
    "{\n",
    "  \"airline\": \"Delta\",\n",
    "  \"price\": \"349\",\n",
    "  \"duration\": \"266 min\",\n",
    "  \"stops\": \"Nonstop\",\n",
    "  \"departure\": \"Hartsfield-Jackson Atlanta International Airport (ATL) at 2026-05-05 09:50\",\n",
    "  \"arrival\": \"Harry Reid International Airport (LAS) at 2026-05-05 11:16\",\n",
    "  \"travel_class\": \"Economy\",\n",
    "  \"airline_logo\": \"https://www.gstatic.com/flights/airline_logos/70px/DL.png\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5231e1d7-db84-493c-b70e-20f7f404c17c",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Best Practices for Using Model Context Protocol (MCP) with Gemini LLM</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f134490-5a5b-4959-b3ea-d9a84a080839",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>1. Tool Design</font></b>\n",
    "* <b><font size='3ptx'>Clear Tool Names</font></b>: Use short, meaningful names (<font color='brown'>e.g., `search_flights`, `get_weather`</font>).\n",
    "* <b><font size='3ptx'>Describe Each Tool Well</font></b>: Provide simple, clear descriptions — the model uses this to decide when and how to call the tool.\n",
    "* <b><font size='3ptx'>Use Strong Typing</font></b>: Define input parameters explicitly (<font color='brown'>e.g., string, enum, number</font>) to help the model fill them accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38563633-1d67-4091-85d6-0ab5704f10f3",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>2. Model Interaction</font></b>\n",
    "* <b><font size='3ptx'>Fewer Tools means Better Accuracy</font></b>: Avoid overloading the model — stick to relevant tools only.\n",
    "* <b><font size='3ptx'>Dynamic Tool Loading</font></b>: Load tools based on the user’s query or conversation context.\n",
    "* <b><font size='3ptx'>Prompt the Model Clearly</font></b>: Set the model’s role and explain how and when to use the tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb382110-3d78-422c-97b6-9877345aa8a6",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>3. Server Setup</font></b>\n",
    "* <b><font size='3ptx'>Use stdio for Simplicity</font></b>: Start MCP servers using — connection_type stdio for easy local development.\n",
    "* <b><font size='3ptx'>Pass Environment Variables Safely</font></b>: Use `env` to send keys like `SERP_API_KEY` securely to tool servers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bc7a7-e9f6-417b-9cb1-7980703b8c27",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>4. Request Handling</font></b>\n",
    "* <b><font size='3ptx'>Initialize Session First</font></b>: Always run `session.initialize()` before listing or calling tools.\n",
    "* <b><font size='3ptx'>List Tools Dynamically</font></b>: Use `session.list_tools()` to keep client flexible and tool-agnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f6e97-252c-4118-8c1e-ba101bc468b9",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>5. Error Handling & Security</font></b>\n",
    "* <b><font size='3ptx'>Return Helpful Errors</font></b>: Make sure tool server responds with meaningful messages when something fails.\n",
    "* <b><font size='3ptx'>Secure APIs</font></b>: Never expose secrets like API keys in logs or error messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a61f8-6a13-4271-a3e4-4f0e8a64891a",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Limitations</font></b>\n",
    "As of this writing( March 2025), there are a few limitations when using <b><font size='3ptx'>Model Context Protocol (MCP)</font></b> and function calling with Gemini LLM:\n",
    "1. Partial OpenAPI Support\n",
    "2. Supported parameter types in Python are limited.\n",
    "3. Automatic function calling is a Python SDK feature only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
