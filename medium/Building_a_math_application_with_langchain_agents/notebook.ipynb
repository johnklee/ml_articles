{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064cbf68-cc1c-4ee6-80b7-a2f6615c9519",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([article source](https://towardsdatascience.com/building-a-math-application-with-langchain-agents-23919d09a4d3)) <b><font size='3ptx'>A tutorial on why LLMs struggle with math, and how to resolve these limitations using LangChain Agents, OpenAI and Chainlit</font></b>\n",
    "\n",
    "<b>In this tutorial, I will demonstrate how to use [LangChain](https://www.langchain.com/) agents to create a custom Math application utilising OpenAI’s GPT3.5 model</b>. For the application frontend, I will be using [**Chainlit**](https://chainlit.io/), an easy-to-use open-source Python framework. This generative math application, <b>let’s call it “Math Wiz”, is designed to help users with their math or reasoning/logic questions</b>.\n",
    "![Wiz diagram](images/fig1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17262b77-78b7-4f10-8f13-468cf7f62bd1",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Why do LLMs struggle with Math?</font></b>\n",
    "<b><font size='3ptx'>Large Language Models (LLMs) are known to be quite bad at Math, as well as reasoning tasks, and this is a common trait among many language models.</font></b>\n",
    "\n",
    "There are a few different reasons for this:\n",
    "* **Lack of training data:** One reasons is the limitations of their training data. Language models, trained on vast text datasets, may lack sufficient mathematical problems and solutions. This can lead to misinterpretations of numbers, forgetting important calculation steps, and a lack of quantitative reasoning skills.\n",
    "* **Lack of numeric representations**: Another reason is that LLMs are designed to understand and generate text, operating on tokens instead of numeric values. Most text-based tasks can have multiple reasonable answers. However, math problems typically have only one correct solution.\n",
    "* **Generative nature**: Due to the generative nature of these language models, generating consistently accurate and precise answers to math questions can be challenging for LLMs.\n",
    "\n",
    "This makes the “Math problem” the perfect candidate for utilising LangChain agents. Agents are systems that use a language model to interact with other tools to break down a complex problem (more on this later). The code for this tutorial is available on my [**GitHub**](https://github.com/tahreemrasul/math_app_langchain)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b6ec0-cfa6-419a-8f94-94649158a441",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Application Flow</font></b>\n",
    "<b><font size='3ptx'>The application flow for Math Wiz is outlined in the flowchart below. The agent in our pipeline will have a set of tools at its disposal that it can use to answer a user query. </font></b>\n",
    "\n",
    "<b>The Large Language Model (LLM) serves as the “brain” of the agent, guiding its decisions</b>. When a user submits a question, the agent uses the LLM to select the most appropriate tool or a combination of tools to provide an answer. If the agent determines it needs multiple tools, it will also specify the order in which the tools are used.\n",
    "\n",
    "![App flow](images/fig2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39063f4-6fb5-4c3b-8c92-43dca1a7428d",
   "metadata": {},
   "source": [
    "The agent for our Math Wiz app will be using the following tools:\n",
    "* **Wikipedia Tool**: this tool will be responsible for fetching the latest information from Wikipedia using the Wikipedia API. While there are paid tools and APIs available that can be integrated inside LangChain, I would be using Wikipedia as the app’s online source of information.\n",
    "* **Calculator Tool**: this tool would be responsible for solving a user’s math queries. This includes anything involving numerical calculations. For example, if a user asks what the square root of 4 is, this tool would be appropriate.\n",
    "* **Reasoning Tool**: the final tool in our application setup would be a reasoning tool, responsible for tackling logical/reasoning-based user queries. Any mathematical word problems should also be handled with this tool.\n",
    "\n",
    "Now that we have a rough application design, we can began thinking about building this application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5423da4-1e66-43ac-b49d-73cd62347f5e",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Understanding LangChain Agents</font></b>\n",
    "<b><font size='3ptx'>LangChain agents enhance the interaction with language models by providing an interface for more complex and interactive tasks.</font></b>\n",
    "\n",
    "<b>We can think of an agent as an intermediary between users and a large language model</b>. Agents seek to break down a seemingly complex user query, that our LLM might not be able to tackle on its own, into easier, actionable steps.\n",
    "\n",
    "In our application flow, we defined a few different tools that we would like to use for our math application. <b>Based on the user input, the agent should decide which of these tools to use. If a tool is not required, it should not be used. LangChain agents can simplify this for us</b>. These agents use a language model to choose a sequence of actions to take.\n",
    "\n",
    "<b>Essentially, the LLM acts as the “brain” of the agent, guiding it on which tool to use for a particular query, and in which order.</b> This is different from LangChain chains where the sequence of actions are hardcoded in code. LangChain offers a wide set of tools that can be integrated with an agent. These tools include, and are not limited to, online search tools, API-based tools, chain-based tools etc.\n",
    "\n",
    "For more information on LangChain agents and their types, see [this](https://python.langchain.com/docs/modules/agents/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99586b-6bce-495e-a7bd-4db911f548e4",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Step-by-Step Implementation</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff2f68-0db3-4158-9431-fedddc6b1f4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <b>Step 1</b>\n",
    "Create a <font color='olive'>chatbot.py</font> script and import the necessary dependencies:\n",
    "```python\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7b7b7-462e-44ed-bd3d-5d8d9a81d7bc",
   "metadata": {},
   "source": [
    "#### <b>Step 2</b>\n",
    "Next, we will define our OpenAI-based Language Model. LangChain offers the langchain-openai package which can be used to define an instance of the OpenAI model. We will be using the `gpt-3.5-turbo-instruct` model from OpenAI. The [**dotenv**](https://pypi.org/project/python-dotenv/) package would already be handling the API key so you do not need to explicitly define it here:\n",
    "```python\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct',\n",
    "             temperature=0)\n",
    "```\n",
    "\n",
    "We would be using this LLM both within our math and reasoning chains and as the decision maker for our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521466b-a706-4f81-8b5f-9ce23c83c2fc",
   "metadata": {},
   "source": [
    "#### <b>Step 3</b>\n",
    "<b>When constructing your own agent, you will need to provide it with a list of tools that it can use</b>. Besides the actual function that is called, the Tool consists of a few other parameters:\n",
    "* **name (str)**, is required and must be unique within a set of tools provided to an agent.\n",
    "* **description (str)**, is optional but recommended, as it is used by an agent to determine tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935893ec-7105-4906-8c77-27b23b179e74",
   "metadata": {},
   "source": [
    "We will now create our three tools. The first one will be the online tool using the Wikipedia API wrapper:\n",
    "```python\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "wikipedia_tool = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func=wikipedia.run,\n",
    "\tdescription=\"A useful tool for searching the Internet \n",
    "to    find information on world events, issues, dates, years, etc. Worth \n",
    "using for general topics. Use precise questions.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c7245-c1dd-4b79-b874-c81714ad0f8e",
   "metadata": {},
   "source": [
    "In the code above, we have defined an instance of the Wikipedia API wrapper. Afterwards, we have wrapped it inside a LangChain <font color='blue'><b>Tool</b></font>, with the name, function and description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dca37-d206-4804-9989-ecd747c3542c",
   "metadata": {},
   "source": [
    "<b>Next, let’s define the tool that we will be using for calculating any numerical expressions</b>. LangChain offers the [**LLMMathChain**](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_math.base.LLMMathChain.html#langchain.chains.llm_math.base.LLMMathChain) which uses the [**numexpr**](https://pypi.org/project/numexpr/) Python library to calculate mathematical expressions. It is also important that we clearly define what this tool would be used for. The `description` can be helpful for the agent in deciding which tool to use from a set of tools for a particular user query. For our chain-based tools, we will be using the <font color='blue'><b>Tool</b>.from_function()</font> method:\n",
    "```python\n",
    "problem_chain = LLMMathChain.from_llm(llm=llm)\n",
    "math_tool = Tool.from_function(name=\"Calculator\",\n",
    "                func=problem_chain.run,\n",
    "                 description=\"Useful for when you need to answer questions \n",
    "about math. This tool is only for math questions and nothing else. Only input\n",
    "math expressions.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c6011-74ba-4c52-8524-768f5de15416",
   "metadata": {},
   "source": [
    "<b>Finally, we will be defining the tool for logic/reasoning-based queries</b>. We will first create a prompt to instruct the model with executing the specific task. Then we will create a simple LLMChain for this tool, passing it the LLM and the prompt:\n",
    "```python\n",
    "word_problem_template = \"\"\"You are a reasoning agent tasked with solving \n",
    "the user's logic-based questions. Logically arrive at the solution, and be \n",
    "factual. In your answers, clearly detail the steps involved and give the \n",
    "final answer. Provide the response in bullet points. \n",
    "Question  {question} Answer\"\"\"\n",
    "\n",
    "math_assistant_prompt = PromptTemplate(input_variables=[\"question\"],\n",
    "                                       template=word_problem_template\n",
    "                                       )\n",
    "word_problem_chain = LLMChain(llm=llm,\n",
    "                              prompt=math_assistant_prompt)\n",
    "word_problem_tool = Tool.from_function(name=\"Reasoning Tool\",\n",
    "                                       func=word_problem_chain.run,\n",
    "                                       description=\"Useful for when you need \n",
    "to answer logic-based/reasoning questions.\",\n",
    "                                    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115cf0e-32c6-4780-9335-eb00c0b8a83a",
   "metadata": {},
   "source": [
    "#### <b>Step 4</b>\n",
    "We will now initialize our agent with the tools we have created above. We will also specify the LLM to help it choose which tools to use and in what order:\n",
    "```python\n",
    "agent = initialize_agent(\n",
    "    tools=[wikipedia_tool, math_tool, word_problem_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(agent.invoke(\n",
    "    {\"input\": \"I have 3 apples and 4 oranges. I give half of my oranges \n",
    "               away and buy two dozen new ones, alongwith three packs of \n",
    "               strawberries. Each pack of strawberry has 30 strawberries. \n",
    "               How  many total pieces of fruit do I have at the end?\"}))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc8cc38-8e42-4c6d-afd6-e9e79f265ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 chatbot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec1bad-21e1-407a-aea5-38e2d75d2630",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Creating Chainlit Application</font></b>\n",
    "<b><font size='3ptx'>We will be using [Chainlit](https://chainlit.io/), an open-source Python framework, to build our application. </font></b>\n",
    "\n",
    "With Chainlit, you can build conversational AI applications with a few simple lines of code. To get a deeper understanding of Chainlit functionalities and how the app is set up, you can take a look at my [**article here**](https://medium.com/@tahreemrasul/building-a-chatbot-application-with-chainlit-and-langchain-3e86da0099a6?source=post_page-----23919d09a4d3--------------------------------)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2365280-7413-4146-a12f-af27aa98bf42",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Testing and Validation</font></b>\n",
    "<b><font size='3ptx'>Let’s now validate the performance of our bot.</font></b>\n",
    "\n",
    "We have not integrated any memory into our bot, so each query would have to be its own function call. Let’s ask our app a few math questions. For comparison, I am attaching screenshots of each response for the same query from both Chat GPT 3.5, and our Math Wiz app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67240cb-b1af-4fc1-8f2a-9a8b3fa099aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/johnkclee/Github/ml_articles/env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "/usr/local/google/home/johnkclee/Github/ml_articles/env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import chatbot\n",
    "import os\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f258b2-39f5-43f2-9a51-6827f03d2fb2",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Arithmetic Questions</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd514b5-0c4a-4ef6-8014-811f84f895bd",
   "metadata": {},
   "source": [
    "#### <b>Question 1</b>\n",
    "```\n",
    "Question? What is the cube root of 625?\n",
    "\n",
    "Response:\n",
    "The cube root of 625 is 8.549879733383484.\n",
    "```\n",
    "\n",
    "![fig3](images/fig3.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d69ea9-6515-46f4-9fa8-0a6f384a225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the cube root of 625?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df58c392-395d-4f27-afd2-70b97db044be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cube root of 625 is 5.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By purely LLM\n",
    "chatbot.input_quesiton(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d49c41-b94c-4e38-8e0e-fca158879855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a calculator to solve this math problem.\n",
      "Action: Calculator\n",
      "Action Input: 625^(1/3)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 8.549879733383484\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The cube root of 625 is 8.549879733383484.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The cube root of 625 is 8.549879733383484.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By Math Wiz\n",
    "chatbot.input_quesiton(\"A:\" + question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0650777-8895-4aa0-adf3-15098705f240",
   "metadata": {},
   "source": [
    "<b>Our Math Wiz app was able to correctly answer this question. However, ChatGPT’s response is incorrect</b>. It not only complicated the reasoning steps unnecessarily but also failed to reach the correct answer. However, on a separate occasion, ChatGPT was able to answer this question correctly. This is of course unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760205d7-12ed-4b5c-8f03-a74e11c9413d",
   "metadata": {},
   "source": [
    "#### <b>Question 2</b>\n",
    "```\n",
    "what is cube root of 81? Multiply with 13.27, and subtract 5.\n",
    "\n",
    "# correct answer = 52.4195\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc415ba7-c6f4-4892-a67e-49f73a939283",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_question2 = \"what is cube root of 81? Multiply with 13.27, and subtract 5.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8596e0-23c0-44f4-b9ef-d0a8bf83f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cube root of 81 is 4.\n",
      "\n",
      "4 * 13.27 = 53.08\n",
      "\n",
      "53.08 - 5 = 48.08\n",
      "\n",
      "Therefore, the result of multiplying the cube root of 81 by 13.27 and subtracting 5 is 48.08.\n"
     ]
    }
   ],
   "source": [
    "# By purely LLM\n",
    "print(chatbot.input_quesiton(math_question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03c034c-bed9-458f-85e1-86ab3fb2078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the calculator tool to solve this math problem.\n",
      "Action: Calculator\n",
      "Action Input: (81^(1/3))*13.27-5\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 52.415955393937914\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 52.415955393937914\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "52.415955393937914\n"
     ]
    }
   ],
   "source": [
    "# By Math Wiz\n",
    "print(chatbot.input_quesiton(\"A:\" + math_question2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8a7d4-8cf9-48d2-8e8f-9ceb232292bb",
   "metadata": {},
   "source": [
    "Our Math Wiz app was able to correctly answer this question too. However, once again, ChatGPT’s response isn’t correct. Occasionally, ChatGPT can answer math questions correctly, but this is subject to prompt engineering and multiple inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0e1b2-64a2-46f3-9137-a4f6864799b3",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Reasoning Questions</font></b>\n",
    "Let’s ask our app a few reasoning/logic questions. Some of these questions have an arithmetic component to them. I’d expect the agent to decide which tool to use in each case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ef2c9c-6488-40fb-bdbc-ab9608d622c7",
   "metadata": {},
   "source": [
    "#### <b>Question 1</b>\n",
    "```\n",
    "I have 3 apples and 4 oranges. I give half of my oranges away and buy two \n",
    "dozen new ones, alongwith three packs of strawberries. Each pack of \n",
    "strawberry has 30 strawberries. How  many total pieces of fruit do I have at \n",
    "the end?\n",
    "\n",
    "# correct answer = 3 + 2 + 24 + 90 = 119\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c5c404-7c3a-4a9d-8b8c-90f75327e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_question1 = '''I have 3 apples and 4 oranges. I give half of my oranges away and buy two \n",
    "dozen new ones, along with three packs of strawberries.\n",
    "Each pack of strawberry has 30 strawberries.\n",
    "How many total pieces of fruit do I have at  the end?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063aa86e-0a07-4746-becc-5de8b7c5ab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After giving away half of my oranges, I have 2 oranges left. \n",
      "\n",
      "Then I buy two dozen new oranges, which is 24 oranges. \n",
      "\n",
      "So, I now have a total of 2 + 24 = 26 oranges. \n",
      "\n",
      "I also have 3 packs of strawberries, with each pack having 30 strawberries. \n",
      "\n",
      "So, I have 3 * 30 = 90 strawberries. \n",
      "\n",
      "Adding the apples, oranges, and strawberries together, I have a total of 3 (apples) + 26 (oranges) + 90 (strawberries) = 119 pieces of fruit. \n",
      "\n",
      "Therefore, I have 119 pieces of fruit at the end.\n"
     ]
    }
   ],
   "source": [
    "# By purely LLM\n",
    "print(chatbot.input_quesiton(reason_question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d021385-7270-4215-b1be-aaf48a7bd65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to figure out how many oranges I have left after giving half away and how many strawberries I have in total.\n",
      "Action: Calculator\n",
      "Action Input: 4/2 + (3*24) + (3*30)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 164.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know how many total pieces of fruit I have.\n",
      "Final Answer: 164 pieces of fruit.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "164 pieces of fruit.\n"
     ]
    }
   ],
   "source": [
    "# By Math Wiz\n",
    "print(chatbot.input_quesiton(\"A:\" + reason_question1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992b635-a6b5-4e85-92cb-1d1511bd5994",
   "metadata": {},
   "source": [
    "#### <b>Question 2</b>\n",
    "```\n",
    "Steve's sister is 10 years older than him. Steve was born when the cold war \n",
    "ended. When was Steve's sister born?\n",
    "\n",
    "# correct answer = 1991 - 10 = 1981\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4a2e6b-3be5-43c5-9a76-d5dcf25ac9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_question2 = \"Steve's sister is 10 years older than him. Steve was born when the cold war ended. When was Steve's sister born?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "535c9e6f-6373-456d-aeea-f1a840966383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Steve was born in 1991 when the Cold War ended. Therefore, Steve's sister was born in 1981, which is 10 years before Steve's birth.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By purely LLM\n",
    "chatbot.input_quesiton(reason_question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c003a0c4-2315-4cb0-b193-b5c8ef97c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the year the cold war ended and then calculate 10 years before that.\n",
      "Action: Calculator\n",
      "Action Input: 2021 - 10\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2011\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I know the year Steve's sister was born.\n",
      "Final Answer: Steve's sister was born in 2011.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Steve's sister was born in 2011.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By Math Wiz\n",
    "chatbot.input_quesiton(\"A:\" + reason_question2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86afa98b-0655-4df0-8c26-4543a0aa8154",
   "metadata": {},
   "source": [
    "#### <b>Question 3</b>\n",
    "```\n",
    "give me the year when Tom Cruise's Top Gun released raised to the power 2\n",
    "\n",
    "# correct answer = 1987**2 = 3944196\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d743f01-8a96-45b3-8d7d-651e48ab8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_question3 = \"give me the year when Tom Cruise's Top Gun released raised to the power 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff5957e-90e3-42cd-91cd-85d4bbc4fcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1986^2 = 3,944'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By purely LLM\n",
    "chatbot.input_quesiton(reason_question3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4661e7af-88dd-481a-9b8b-ee8a776bc43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the year when Top Gun was released and then raise it to the power of 2\n",
      "Action: Wikipedia\n",
      "Action Input: \"Top Gun (film)\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Top Gun\n",
      "Summary: Top Gun is a 1986 American action drama film directed by Tony Scott and produced by Don Simpson and Jerry Bruckheimer, with distribution by Paramount Pictures. The screenplay was written by Jim Cash and Jack Epps Jr., and was inspired by an article titled \"Top Guns\", written by Ehud Yonay and published in California magazine three years earlier. It stars Tom Cruise as Lieutenant Pete \"Maverick\" Mitchell, a young naval aviator aboard the aircraft carrier USS Enterprise. He and his radar intercept officer, Lieutenant (junior grade) Nick \"Goose\" Bradshaw (Anthony Edwards), are given the chance to train at the United States Navy's Fighter Weapons School (Top Gun) at Naval Air Station Miramar in San Diego, California. Kelly McGillis, Val Kilmer and Tom Skerritt also appear in supporting roles.\n",
      "Top Gun was released on May 17, 1986. Upon its release, the film received mixed reviews from film critics, but despite this, its visual effects and soundtrack were universally acclaimed. Four weeks after its release, the number of theaters showing it increased by 45 percent. Despite its initial mixed critical reaction, the film was a huge commercial hit, grossing $357 million globally against a production budget of $15 million. Top Gun was the highest-grossing domestic film of 1986, as well as the highest-grossing film of 1986 worldwide. The film maintained its popularity over the years and earned an IMAX 3D re-release in 2013, while the retrospective critical reception became more positive. Additionally, the soundtrack to the film has since become one of the most popular movie soundtracks to date, reaching 9× Platinum certification. The film won both an Academy Award and a Golden Globe for \"Take My Breath Away\" performed by Berlin. In 2015, the United States Library of Congress selected the film for preservation in the National Film Registry, finding it \"culturally, historically, or aesthetically significant\". A sequel, Top Gun: Maverick, in which Cruise and Kilmer reprised their roles, was released 36 years later on May 27, 2022, and surpassed the original film both critically and commercially.\n",
      "\n",
      "Page: Top Gun: Maverick\n",
      "Summary: Top Gun: Maverick is a 2022 American action drama film directed by Joseph Kosinski and written by Ehren Kruger, Eric Warren Singer, and Christopher McQuarrie from stories by Peter Craig and Justin Marks. The film is a sequel to the 1986 film Top Gun. Tom Cruise reprises his starring role as the naval aviator Maverick. It is based on the characters of the original film created by Jim Cash and Jack Epps Jr. It also stars Miles Teller, Jennifer Connelly, Jon Hamm, Glen Powell, Monica Barbaro, Lewis Pullman, Ed Harris and Val Kilmer, who reprises his role as Iceman. The story involves Maverick confronting his past while training a group of younger Top Gun graduates, including the son of his deceased best friend, for a dangerous mission.\n",
      "Development of a Top Gun sequel was announced in 2010 by Paramount Pictures. Tom Cruise, along with producer Jerry Bruckheimer and director Tony Scott, were asked to return. Craig wrote a draft of the screenplay in 2012, but the project stalled when Scott died later that year. Top Gun: Maverick was later dedicated to Scott's memory. Production resumed in 2017, after Kosinski was hired to direct. Principal photography, which involved the use of IMAX-certified 6K full-frame cameras, took place from May 2018 to April 2019 in California, Washington and Maryland. It was initially scheduled to be released July 12, 2019, but it was delayed several times due to its complex action sequences and later the COVID-19 pandemic. During the pandemic, several streaming companies attempted to purchase the streaming rights to the film from Paramount, but all offers were declined on the orders of Cruise, who insisted that it be released exclusively in theaters.\n",
      "Top Gun: Maverick premiered at CinemaCon on April 28, 2022, and was theatrically released by Paramount Pictures in the United \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know that Top Gun was released in 1986\n",
      "Action: Calculator\n",
      "Action Input: 1986^2\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3944196\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know that the year when Tom Cruise's Top Gun was released raised to the power of 2 is 3944196\n",
      "Final Answer: 3944196\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3944196'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By Math Wiz\n",
    "chatbot.input_quesiton(\"A:\" + reason_question3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197bd783-a0e0-46d7-8eef-b247fc791f4b",
   "metadata": {},
   "source": [
    "Our Math Wiz app was able to correctly answer this question. ChatGPT’s response is once again incorrect. Even though it was able to correctly figure out the release date of the film, the final calculation was incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7195b14-705f-49bc-a1c4-cd24a7cdbc62",
   "metadata": {},
   "source": [
    "## <font color='darkblue'><b>Conclusion & Next Steps</b></font>\n",
    "<font size='3ptx'><b>In this tutorial, we used LangChain agents and tools to create a math solver that could also tackle a user’s reasoning/logic questions</b></font>. We saw that our `Math Wiz` app correctly answered all questions, however, most answers given by ChatGPT were incorrect. This is a great first step in building the tool. The **LLMMathChain** can however fail based on the input we are providing, if it contains string-based text. This can be tackled in a few different ways, such as by creating error handling utilities for your code, adding post-processing logic for the **LLMMathChain**, as well as using custom prompts. You could also increase the efficacy of the tool by including a search tool for more sophisticated and accurate results, since Wikipedia might not have updated information sometimes. You can find the code from this tutorial on my [**GitHub**](https://github.com/tahreemrasul/math_app_langchain)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8992703b-8d74-4f94-9807-c62281173e5b",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [LangChain doc - Tool Calling with LangChain](https://blog.langchain.dev/tool-calling-with-langchain/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
