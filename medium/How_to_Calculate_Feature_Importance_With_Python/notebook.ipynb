{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article](https://machinelearningmastery.com/calculate-feature-importance-with-python/)) **<font size='3ptx'>Feature importance refers to techniques that assign a score to input features based on how useful they are at predicting a target variable.</font>** There are many types and sources of feature importance scores, although popular examples include statistical correlation scores, coefficients calculated as part of linear models, decision trees, and permutation importance scores.\n",
    "\n",
    "Feature importance scores play an important role in a predictive modeling project, including providing insight into the data, insight into the model, and the basis for [**dimensionality reduction**](https://machinelearningmastery.com/dimensionality-reduction-for-machine-learning/) and [**feature selection**](https://machinelearningmastery.com/rfe-feature-selection-in-python/) that can improve the efficiency and effectiveness of a predictive model on the problem.\n",
    "\n",
    "In this tutorial, you will discover feature importance scores for machine learning in python\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "* The role of feature importance in a predictive modeling problem.\n",
    "* How to calculate and review feature importance from linear models and decision trees.\n",
    "* How to calculate and review permutation feature importance scores.\n",
    "\n",
    "### <font color='darkgreen'>Tutorial Overview</font>\n",
    "This tutorial is divided into six parts; they are:\n",
    "* [<font size='3ptx'>**Feature Importance**</font>](#sect1)\n",
    "* [<font size='3ptx'>**Preparation**</font>](#sect2)\n",
    "  1. [Check Scikit-Learn Version](#sect2_1)\n",
    "  2. [Test Datasets](#sect2_2)\n",
    "* [<font size='3ptx'>**Coefficients as Feature Importance**</font>](#sect3)\n",
    "  1. [Linear Regression Feature Importance](#sect3_1)\n",
    "  2. [Logistic Regression Feature Importance](#sect3_2)\n",
    "* [<font size='3ptx'>**Decision Tree Feature Importance**</font>](#sect4)\n",
    "  1. [CART Feature Importance](#sect4_1)\n",
    "  2. [Random Forest Feature Importance](#sect4_2)\n",
    "  3. [XGBoost Feature Importance](#sect4_3)\n",
    "* [<font size='3ptx'>**Permutation Feature Importance**</font>](#sect5)\n",
    "  1. [Permutation Feature Importance for Regression](#sect5_1)\n",
    "  2. [Permutation Feature Importance for Classification](#sect5_2)\n",
    "* [<font size='3ptx'>**Feature Selection with Importance**</font>](#sect6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "## <font color='darkblue'>Feature Importance</font>\n",
    "Feature importance refers to a class of techniques for assigning scores to input features to a predictive model that indicates the relative importance of each feature when making a prediction.\n",
    "\n",
    "Feature importance scores can be calculated for problems that involve predicting a numerical value, called regression, and those problems that involve predicting a class label, called classification.\n",
    "\n",
    "The scores are useful and can be used in a range of situations in a predictive modeling problem, such as:\n",
    "* Better understanding the data.\n",
    "* Better understanding a model.\n",
    "* Reducing the number of input features.\n",
    "\n",
    "**Feature importance scores can provide insight into the dataset**. The relative scores can highlight which features may be most relevant to the target, and the converse, which features are the least relevant. This may be interpreted by a domain expert and could be used as the basis for gathering more or different data.\n",
    "\n",
    "**Feature importance scores can provide insight into the model**. Most importance scores are calculated by a predictive model that has been fit on the dataset. Inspecting the importance score provides insight into that specific model and which features are the most important and least important to the model when making a prediction. This is a type of model interpretation that can be performed for those models that support it.\n",
    "\n",
    "**Feature importance can be used to improve a predictive model**. This can be achieved by using the importance scores to select those features to delete (<font color='brown'>lowest scores</font>) or those features to keep (<font color='brown'>highest scores</font>). This is a type of feature selection and can simplify the problem that is being modeled, speed up the modeling process (<font color='brown'>deleting features is called dimensionality reduction</font>), and in some cases, improve the performance of the model.\n",
    "> Often, we desire to quantify the strength of the relationship between the predictors and the outcome. […] Ranking predictors in this manner can be very useful when sifting through large amounts of data.<br/><br/>\n",
    "> [**— Page 463, Applied Predictive Modeling, 2013.**](https://amzn.to/3b2LHTL)\n",
    "\n",
    "Feature importance scores can be fed to a wrapper model, such as the [**SelectFromModel class**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html), to perform feature selection. There are many ways to calculate feature importance scores and many models that can be used for this purpose.\n",
    "\n",
    "Perhaps the simplest way is to calculate simple coefficient statistics between each feature and the target variable. For more on this approach, see the tutorial [\"How to Choose a Feature Selection Method for Machine Learning\"](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/).\n",
    "\n",
    "In this tutorial, we will look at three main types of more advanced feature importance; they are:\n",
    "* Feature importance from model coefficients.\n",
    "* Feature importance from decision trees.\n",
    "* Feature importance from permutation testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "## <font color='darkblue'>Preparation</font>\n",
    "Before we dive in, let’s confirm our environment and prepare some test datasets.\n",
    "\n",
    "<a id='sect2_1'></a>\n",
    "### <font color='darkgreen'>Check Scikit-Learn Version</font>\n",
    "First, confirm that you have a modern version of the scikit-learn library installed. This is important because some of the models we will explore in this tutorial require a modern version of the library.\n",
    "\n",
    "You can check the version of the library you have installed with the following code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example will print the version of the library. At the time of writing, this is about version 0.23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_2'></a>\n",
    "### <font color='darkgreen'>Test Datasets</font>\n",
    "Next, let’s define some test datasets that we can use as the basis for demonstrating and exploring feature importance scores.\n",
    "\n",
    "**Each test problem has five important and five unimportant features**, and it may be interesting to see which methods are consistent at finding or differentiating the features based on their importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Classification Dataset</font>\n",
    "We will use the [make_classification()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function to create a test binary classification dataset.\n",
    "\n",
    "The dataset will have 1,000 examples, with 10 input features, five of which will be informative and the remaining five will be redundant. We will fix the random number seed to ensure we get the same examples each time the code is run.\n",
    "\n",
    "An example of creating and summarizing the dataset is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Regression Dataset</font>\n",
    "We will use the [make_regression()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression) function to create a test regression dataset.\n",
    "\n",
    "Like the classification dataset, the regression dataset will have 1,000 examples, with 10 input features, five of which will be informative and the remaining five that will be redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3'></a>\n",
    "## <font color='darkblue'>Coefficients as Feature Importance</font>\n",
    "Linear machine learning algorithms fit a model where the prediction is the weighted sum of the input values. Examples include linear regression, logistic regression, and extensions that add regularization, such as ridge regression and the elastic net.\n",
    "\n",
    "All of these algorithms find a set of coefficients to use in the weighted sum in order to make a prediction. These coefficients can be used directly as a crude type of feature importance score.\n",
    "\n",
    "**Let’s take a closer look at using coefficients as feature importance for classification and regression**. We will fit a model on the dataset to find the coefficients, then summarize the importance scores for each input feature and finally create a bar chart to get an idea of the relative importance of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3_1'></a>\n",
    "### <font color='darkgreen'>Linear Regression Feature Importance</font>\n",
    "We can fit a [**LinearRegression model**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) on the regression dataset and retrieve the <font color='violet'>coeff_</font> property that contains the coefficients found for each input variable.\n",
    "\n",
    "These coefficients can provide the basis for a crude feature importance score. **This assumes that the input variables have the same scale or have been scaled prior to fitting a model.**\n",
    "\n",
    "The complete example of linear regression coefficients for feature importance is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: -0.00000\n",
      "Feature: 1, Score: 12.44483\n",
      "Feature: 2, Score: 0.00000\n",
      "Feature: 3, Score: -0.00000\n",
      "Feature: 4, Score: 93.32225\n",
      "Feature: 5, Score: 86.50811\n",
      "Feature: 6, Score: 26.74607\n",
      "Feature: 7, Score: 3.28535\n",
      "Feature: 8, Score: 0.00000\n",
      "Feature: 9, Score: -0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear regression feature importance\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# get importance\n",
    "importance = model.coef_\n",
    "\n",
    "# summarize feature importance\n",
    "for i, v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores suggest that the model found the five important features and marked all other features with a zero coefficient, essentially removing them from the model. This approach may also be used with [**Ridge**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) and [**ElasticNet**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3_2'></a>\n",
    "### <font color='darkgreen'>Logistic Regression Feature Importance</font>\n",
    "We can fit a [**LogisticRegression**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model on the regression dataset and retrieve the <font color='violet'>coeff_</font> property that contains the coefficients found for each input variable. These coefficients can provide the basis for a crude feature importance score. This assumes that the input variables have the same scale or have been scaled prior to fitting a model.\n",
    "\n",
    "The complete example of logistic regression coefficients for feature importance is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.16320\n",
      "Feature: 1, Score: -0.64301\n",
      "Feature: 2, Score: 0.48497\n",
      "Feature: 3, Score: -0.46190\n",
      "Feature: 4, Score: 0.18432\n",
      "Feature: 5, Score: -0.11978\n",
      "Feature: 6, Score: -0.40602\n",
      "Feature: 7, Score: 0.03772\n",
      "Feature: 8, Score: -0.51785\n",
      "Feature: 9, Score: 0.26540\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic regression for feature importance\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall this is a classification problem with classes 0 and 1. Notice that the coefficients are both positive and negative. **The positive scores indicate a feature that predicts class 1, whereas the negative scores indicate a feature that predicts class 0.**\n",
    "\n",
    "No clear pattern of important and unimportant features can be identified from these results, at least from what I can tell. Now that we have seen the use of coefficients as importance scores, let’s look at the more common example of decision-tree-based importance scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect4'></a>\n",
    "## <font color='darkblue'>Decision Tree Feature Importance</font>\n",
    "Decision tree algorithms like [**classification and regression trees**](https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/) (<font color='brown'>CART</font>) offer importance scores based on the reduction in the criterion used to select split points, like Gini or entropy. This same approach can be used for ensembles of decision trees, such as the random forest and stochastic gradient boosting algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect4_1'></a>\n",
    "### <font color='darkgreen'>CART Feature Importance</font>\n",
    "We can use the CART algorithm for feature importance implemented in scikit-learn as the [**DecisionTreeRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) and [**DecisionTreeClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) classes. After being fit, the model provides a <font color='violet'>feature_importances_</font> property that can be accessed to retrieve the relative importance scores for each input feature.\n",
    "\n",
    "#### CART Regression Feature Importance\n",
    "The complete example of fitting a [**DecisionTreeRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) and summarizing the calculated feature importance scores is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00283\n",
      "Feature: 1, Score: 0.00441\n",
      "Feature: 2, Score: 0.00235\n",
      "Feature: 3, Score: 0.00188\n",
      "Feature: 4, Score: 0.51686\n",
      "Feature: 5, Score: 0.43843\n",
      "Feature: 6, Score: 0.02682\n",
      "Feature: 7, Score: 0.00260\n",
      "Feature: 8, Score: 0.00288\n",
      "Feature: 9, Score: 0.00093\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decision tree for feature importance on a regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "    # plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CART Classification Feature Importance\n",
    "The complete example of fitting a [**DecisionTreeClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and summarizing the calculated feature importance scores is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.01941\n",
      "Feature: 1, Score: 0.02288\n",
      "Feature: 2, Score: 0.18340\n",
      "Feature: 3, Score: 0.30786\n",
      "Feature: 4, Score: 0.09851\n",
      "Feature: 5, Score: 0.00832\n",
      "Feature: 6, Score: 0.17062\n",
      "Feature: 7, Score: 0.03388\n",
      "Feature: 8, Score: 0.12487\n",
      "Feature: 9, Score: 0.03025\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decision tree for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect4_2'></a>\n",
    "### <font color='darkgreen'>Random Forest Feature Importance</font>\n",
    "We can use the [Random Forest](https://machinelearningmastery.com/implement-random-forest-scratch-python/) algorithm for feature importance implemented in scikit-learn as the [**RandomForestRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) and [**RandomForestClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classes. After being fit, the model provides a <font color='violet'>feature_importances_</font> property that can be accessed to retrieve the relative importance scores for each input feature.\n",
    "\n",
    "This approach can also be used with the bagging and extra trees algorithms.\n",
    "\n",
    "#### Random Forest Regression Feature Importance\n",
    "The complete example of fitting a [**RandomForestRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) and summarizing the calculated feature importance scores is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00294\n",
      "Feature: 1, Score: 0.00559\n",
      "Feature: 2, Score: 0.00297\n",
      "Feature: 3, Score: 0.00305\n",
      "Feature: 4, Score: 0.52893\n",
      "Feature: 5, Score: 0.42141\n",
      "Feature: 6, Score: 0.02639\n",
      "Feature: 7, Score: 0.00276\n",
      "Feature: 8, Score: 0.00312\n",
      "Feature: 9, Score: 0.00284\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random forest for feature importance on a regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classification Feature Importance\n",
    "The complete example of fitting a [**RandomForestClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and summarizing the calculated feature importance scores is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.07047\n",
      "Feature: 1, Score: 0.11288\n",
      "Feature: 2, Score: 0.14955\n",
      "Feature: 3, Score: 0.19332\n",
      "Feature: 4, Score: 0.08140\n",
      "Feature: 5, Score: 0.10700\n",
      "Feature: 6, Score: 0.09635\n",
      "Feature: 7, Score: 0.04981\n",
      "Feature: 8, Score: 0.09283\n",
      "Feature: 9, Score: 0.04639\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random forest for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect4_3'></a>\n",
    "### <font color='darkgreen'>XGBoost Feature Importance</font>\n",
    "[**XGBoost**](https://xgboost.readthedocs.io/en/latest/) is a library that provides an efficient and effective implementation of the stochastic gradient boosting algorithm. This algorithm can be used with scikit-learn via the XGBRegressor and XGBClassifier classes.\n",
    "\n",
    "After being fit, the model provides a <font color='violet'>feature_importances_</font> property that can be accessed to retrieve the relative importance scores for each input feature. This algorithm is also provided via scikit-learn via the [**GradientBoostingClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) and [**GradientBoostingRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor) classes and the same approach to feature selection can be used.\n",
    "\n",
    "First, install the XGBoost library, such as with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\johnlee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\johnlee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\johnlee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from xgboost) (1.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\johnlee\\appdata\\local\\programs\\python\\python36\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then confirm that the library was installed correctly and works by checking the version number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Regression Feature Importance\n",
    "The complete example of fitting a [**XGBRegressor**](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor) and summarizing the calculated feature importance scores is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00039\n",
      "Feature: 1, Score: 0.00583\n",
      "Feature: 2, Score: 0.00112\n",
      "Feature: 3, Score: 0.00129\n",
      "Feature: 4, Score: 0.49502\n",
      "Feature: 5, Score: 0.46443\n",
      "Feature: 6, Score: 0.02951\n",
      "Feature: 7, Score: 0.00086\n",
      "Feature: 8, Score: 0.00075\n",
      "Feature: 9, Score: 0.00079\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# xgboost for feature importance on a regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = XGBRegressor()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classification Feature Importance\n",
    "The complete example of fitting an [**XGBClassifier**](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRFClassifier) and summarizing the calculated feature importance scores is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.03723\n",
      "Feature: 1, Score: 0.07725\n",
      "Feature: 2, Score: 0.12537\n",
      "Feature: 3, Score: 0.29666\n",
      "Feature: 4, Score: 0.10099\n",
      "Feature: 5, Score: 0.05706\n",
      "Feature: 6, Score: 0.13027\n",
      "Feature: 7, Score: 0.03537\n",
      "Feature: 8, Score: 0.11694\n",
      "Feature: 9, Score: 0.02285\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect5'></a>\n",
    "## <font color='darkblue'>Permutation Feature Importance</font>\n",
    "[**Permutation feature importance**](https://scikit-learn.org/stable/modules/permutation_importance.html) is a technique for calculating relative importance scores that is independent of the model used.\n",
    "\n",
    "First, a model is fit on the dataset, such as a model that does not support native feature importance scores. Then the model is used to make predictions on a dataset, although the values of a feature (<font color='brown'>column</font>) in the dataset are scrambled. This is repeated for each feature in the dataset. Then this whole process is repeated 3, 5, 10 or more times. The result is a mean importance score for each input feature (<font color='brown'>and distribution of scores given the repeats</font>).\n",
    "\n",
    "This approach can be used for regression or classification and requires that a performance metric be chosen as the basis of the importance score, such as the mean squared error for regression and accuracy for classification.\n",
    "\n",
    "Permutation feature selection can be used via the [permutation_importance()](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html) function that takes a fit model, a dataset (<font color='brown'>train or test dataset is fine</font>), and a scoring function. Let’s take a look at this approach to feature selection with an algorithm that does not support feature selection natively, specifically [k-nearest neighbors](https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect5_1'></a>\n",
    "### <font color='darkgreen'>Permutation Feature Importance for Regression</font>\n",
    "The complete example of fitting a [**KNeighborsRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) and summarizing the calculated permutation feature importance scores is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 118.37809\n",
      "Feature: 1, Score: 350.19459\n",
      "Feature: 2, Score: 170.61476\n",
      "Feature: 3, Score: 73.29832\n",
      "Feature: 4, Score: 9405.12668\n",
      "Feature: 5, Score: 7992.64430\n",
      "Feature: 6, Score: 933.99287\n",
      "Feature: 7, Score: 174.17950\n",
      "Feature: 8, Score: 151.51481\n",
      "Feature: 9, Score: 117.79557\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# permutation feature importance with knn for regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# perform permutation importance\n",
    "results = permutation_importance(model, X, y, scoring='neg_mean_squared_error')\n",
    "\n",
    "# get importance\n",
    "importance = results.importances_mean\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect5_2'></a>\n",
    "### <font color='darkgreen'>Permutation Feature Importance for Classification</font>\n",
    "The complete example of fitting a [**KNeighborsClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) and summarizing the calculated permutation feature importance scores is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.05160\n",
      "Feature: 1, Score: 0.06240\n",
      "Feature: 2, Score: 0.05040\n",
      "Feature: 3, Score: 0.08520\n",
      "Feature: 4, Score: 0.04980\n",
      "Feature: 5, Score: 0.05620\n",
      "Feature: 6, Score: 0.08320\n",
      "Feature: 7, Score: 0.05080\n",
      "Feature: 8, Score: 0.05980\n",
      "Feature: 9, Score: 0.02960\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# permutation feature importance with knn for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# define the model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# perform permutation importance\n",
    "results = permutation_importance(model, X, y, scoring='accuracy')\n",
    "\n",
    "# get importance\n",
    "importance = results.importances_mean\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect6'></a>\n",
    "## <font color='darkblue'>Feature Selection with Importance</font>\n",
    "**Feature importance scores can be used to help interpret the data, but they can also be used directly to help rank and select features that are most useful to a predictive model.** We can demonstrate this with a small example.\n",
    "\n",
    "Recall, our synthetic dataset has 1,000 examples each with 10 input variables, five of which are redundant and five of which are important to the outcome. We can use feature importance scores to help select the five variables that are relevant and only use them as inputs to a predictive model.\n",
    "\n",
    "First, we can split the training dataset into train and test sets and train a model on the training dataset, make predictions on the test set and evaluate the result using classification accuracy. We will use a logistic regression model as the predictive model.\n",
    "\n",
    "This provides a baseline for comparison when we remove some features using feature importance scores. The complete example of evaluating a logistic regression model using all features as input on our synthetic dataset is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.55\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using all features\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# define the dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we can see that the model achieved the classification accuracy of about 84.55 percent using all features in the dataset. Given that we created the dataset, we would expect better or the same results with half the number of input variables.\n",
    "\n",
    "We could use any of the feature importance scores explored above, but in this case we will use the feature importance scores provided by random forest.\n",
    "\n",
    "We can use the [**SelectFromModel**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html) class to define both the model we wish to calculate importance scores, [**RandomForestClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) in this case, and the number of features to select, 5 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# configure to select a subset of features\n",
    "fs = SelectFromModel(RandomForestClassifier(n_estimators=200), max_features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit the feature selection method on the training dataset.\n",
    "\n",
    "This will calculate the importance scores that can be used to rank all input features. **We can then apply the method as a transform to select a subset of 5 most important features from the dataset**. This transform will be applied to the training dataset and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectFromModel(RandomForestClassifier(n_estimators=1000), max_features=5)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    " \n",
    "# define the dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that the model achieves the same performance on the dataset, although with half the number of input features. As expected, the feature importance scores calculated by random forest allowed us to accurately rank the input features and delete those that were not relevant to the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Further Reading</font>\n",
    "This section provides more resources on the topic if you are looking to go deeper.\n",
    "* [How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)\n",
    "* [How to Perform Feature Selection with Categorical Data](https://machinelearningmastery.com/feature-selection-with-categorical-data/)\n",
    "* [Feature Importance and Feature Selection With XGBoost in Python](https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/)\n",
    "* [Feature Selection For Machine Learning in Python](https://machinelearningmastery.com/feature-selection-machine-learning-python/)\n",
    "* [An Introduction to Feature Selection](https://machinelearningmastery.com/an-introduction-to-feature-selection/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
