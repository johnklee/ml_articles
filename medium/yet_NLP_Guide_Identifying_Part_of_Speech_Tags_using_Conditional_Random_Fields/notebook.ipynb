{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article source](https://medium.com/analytics-vidhya/pos-tagging-using-conditional-random-fields-92077e5eaa31)) <font size='3ptx'>**In the world of Natural Language Processing (NLP), the most basic models are based on Bag of Words. But such models fail to capture the syntactic relations between words.**</font>\n",
    "\n",
    "For example, suppose we build a sentiment analyser based on only Bag of Words. Such a model will not be able to capture the difference between “I like you”, where “like” is a verb with a positive sentiment, and “I am like you”, where “like” is a preposition with a neutral sentiment.\n",
    "\n",
    "So this leaves us with a question — how do we improve on this Bag of Words technique?\n",
    "\n",
    "[**Part of Speech**](https://en.wikipedia.org/wiki/Part_of_speech) (<font color='brown'>hereby referred to as POS</font>) Tags are useful for building parse trees, which are used in building [**NER**](https://en.wikipedia.org/wiki/Named-entity_recognition)s (<font color='brown'>most named entities are Nouns</font>) and extracting relations between words. POS Tagging is also essential for building lemmatizers which are used to reduce a word to its root form.\n",
    "\n",
    "POS tagging is the process of marking up a word in a corpus to a corresponding part of a speech tag, based on its context and definition. This task is not straightforward, as a particular word may have a different part of speech based on the context in which the word is used.\n",
    "\n",
    "For example: In the sentence “Give me your answer”, answer is a Noun, but in the sentence “Answer the question”, answer is a verb.\n",
    "\n",
    "**To understand the meaning of any sentence or to extract relationships and build a knowledge graph, POS Tagging is a very important step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>The Different POS Tagging Techniques</font>\n",
    "There are different techniques for POS Tagging:\n",
    "* **Lexical Based Methods** — Assigns the POS tag the most frequently occurring with a word in the training corpus.\n",
    "* **Rule-Based Methods** — Assigns POS tags based on rules. For example, we can have a rule that says, words ending with “ed” or “ing” must be assigned to a verb. Rule-Based Techniques can be used along with Lexical Based approaches to allow POS Tagging of words that are not present in the training corpus but are there in the testing data.\n",
    "* **Probabilistic Methods** — This method assigns the POS tags based on the probability of a particular tag sequence occurring. Conditional Random Fields (CRFs) and Hidden Markov Models (HMMs) are probabilistic approaches to assign a POS Tag.\n",
    "* **Deep Learning Methods** — Recurrent Neural Networks can also be used for POS tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='crf'></a>\n",
    "## <font color='darkblue'>Conditional Random Fields(CRF)</font>\n",
    "* <font size='3ptx'>[**Dataset**](#dataset)</font>\n",
    "* <font size='3ptx'>[**Creating the Feature Function**](#feature_func)</font>\n",
    "* <font size='3ptx'>[**Fitting a CRF Model**](#crf_fitting)</font>\n",
    "* <font size='3ptx'>[**Evaluating the CRF Model**](#crf_evaluation)</font>\n",
    "\n",
    "**A CRF is a Discriminative Probabilistic Classifiers.** The difference between discriminative and generative models is that while discriminative models try to model conditional probability distribution, i.e., `P(y|x)`, generative models try to model a joint probability distribution, i.e., `P(x,y)`.\n",
    "\n",
    "**Logistic Regression, SVM, CRF are Discriminative Classifiers. Naive Bayes, HMMs are Generative Classifiers**. CRF’s can also be used for sequence labelling tasks like Named Entity Recognisers and POS Taggers.\n",
    "\n",
    "**In CRFs, the input is a set of features** (<font color='brown'>real numbers</font>) **derived from the input sequence using feature functions, the weights associated with the features** (<font color='brown'>that are learned</font>) **and the previous label and the task is to predict the current label.** The weights of different feature functions will be determined such that the likelihood of the labels in the training data will be maximised.\n",
    "\n",
    "**In CRF, a set of feature functions are defined to extract features for each word in a sentence.** Some examples of feature functions are: is the first letter of the word capitalised, what the suffix and prefix of the word, what is the previous word, is it the first or the last word of the sentence, is it a number etc. These set of features are called State Features. In CRF, we also pass the label of the previous word and the label of the current word to learn the weights. CRF will try to determine the weights of different feature functions that will maximise the likelihood of the labels in the training data. **The feature function dependent on the label of the previous word is Transition Feature**.\n",
    "\n",
    "Let’s now jump into how to use CRF for identifying POS Tags in Python. The code can be found [here](https://github.com/AiswaryaSrinivas/DataScienceWithPython/blob/master/CRF%20POS%20Tagging.ipynb). Firstly, let's import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>\n",
    "### <font color='darkgreen'>Dataset</font> ([back](#crf))\n",
    "**We will use the [NLTK](https://www.nltk.org/) Treebank dataset with the Universal Tagset**. The Universal tagset of NLTK comprises of 12 tag classes: Verb, Noun, Pronouns, Adjectives, Adverbs, Adpositions, Conjunctions, Determiners, Cardinal Numbers, Particles, Other/ Foreign words, Punctuations. This dataset has 3,914 tagged sentences and a vocabulary of 12,408 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\john\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\john\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tagged Sentences  3914\n",
      "Total Number of Tagged words 100676\n",
      "Vocabulary of the Corpus 12408\n",
      "Number of Tags in the Corpus  12\n"
     ]
    }
   ],
   "source": [
    "tagged_sentence = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
    "print(\"Number of Tagged Sentences \",len(tagged_sentence))\n",
    "tagged_words=[tup for sent in tagged_sentence for tup in sent]\n",
    "print(\"Total Number of Tagged words\", len(tagged_words))\n",
    "vocab=set([word for word,tag in tagged_words])\n",
    "print(\"Vocabulary of the Corpus\",len(vocab))\n",
    "tags=set([tag for word,tag in tagged_words])\n",
    "print(\"Number of Tags in the Corpus \",len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split the data into Training and Test data in a 80:20 ratio — 3,131 sentences in the training set and 783 sentences in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences in Training Data  3131\n",
      "Number of Sentences in Testing Data  783\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(tagged_sentence,test_size=0.2,random_state=1234)\n",
    "print(\"Number of Sentences in Training Data \",len(train_set))\n",
    "print(\"Number of Sentences in Testing Data \",len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_func'></a>\n",
    "### <font color='darkgreen'>Creating the Feature Function</font> ([back](#crf))\n",
    "For identifying POS tags, we will create a function which returns a dictionary with the following features for each word in a sentence:\n",
    "* Is the first letter of the word capitalised (Generally Proper Nouns have the first letter capitalised)?\n",
    "* Is it the first word of the sentence?\n",
    "* Is it the last word of the sentence\n",
    "* Does the word contain both numbers and alphabets?\n",
    "* Does it have a hyphen (generally, adjectives have hyphens - for example, words like fast-growing, slow-moving)\n",
    "* Is the complete word capitalised?\n",
    "* Is it a number?\n",
    "* What are the first four suffixes and prefixes?(words ending with “ed” are generally verbs, words ending with “ous” like disastrous are adjectives)\n",
    "\n",
    "The feature function is defined as below and the features for train and test data are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    ### sentence is of the form [w1,w2,w3,..], index is the position of the word in the sentence\n",
    "    return {\n",
    "        'is_first_capital':int(sentence[index][0].isupper()),\n",
    "        'is_first_word': int(index==0),\n",
    "        'is_last_word':int(index==len(sentence)-1),\n",
    "        'is_complete_capital': int(sentence[index].upper()==sentence[index]),\n",
    "        'prev_word':'' if index==0 else sentence[index-1],\n",
    "        'next_word':'' if index==len(sentence)-1 else sentence[index+1],\n",
    "        'is_numeric':int(sentence[index].isdigit()),\n",
    "        'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*[a-zA-Z])',sentence[index])))),\n",
    "        'prefix_1':sentence[index][0],\n",
    "        'prefix_2': sentence[index][:2],\n",
    "        'prefix_3':sentence[index][:3],\n",
    "        'prefix_4':sentence[index][:4],\n",
    "        'suffix_1':sentence[index][-1],\n",
    "        'suffix_2':sentence[index][-2:],\n",
    "        'suffix_3':sentence[index][-3:],\n",
    "        'suffix_4':sentence[index][-4:],\n",
    "        'word_has_hyphen': 1 if '-' in sentence[index] else 0  \n",
    "    }\n",
    "\n",
    "\n",
    "def untag(sentence):\n",
    "    return [word for word,tag in sentence]\n",
    "\n",
    "\n",
    "def prepare_data(tagged_sentences):\n",
    "    X, y=[], []\n",
    "    for sentences in tagged_sentences:\n",
    "        X.append([features(untag(sentences), index) for index in range(len(sentences))])\n",
    "        y.append([tag for word, tag in sentences])\n",
    "        \n",
    "    return X,y\n",
    "\n",
    "\n",
    "X_train, y_train=prepare_data(train_set)\n",
    "X_test, y_test=prepare_data(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='crf_fitting'></a>\n",
    "### <font color='darkgreen'>Fitting a CRF Model</font> ([back](#crf))\n",
    "The next step is to use the [**sklearn_crfsuite**](https://sklearn-crfsuite.readthedocs.io/en/latest/) to fit the CRF model. The model is optimised by Gradient Descent using the LBGS method with L1 and L2 regularisation. We will set the CRF to generate all possible label transitions, even those that do not occur in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.01, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='crf_evaluation'></a>\n",
    "### <font color='darkgreen'>Evaluating the CRF Model</font>\n",
    "We use [**F-score**](https://en.wikipedia.org/wiki/F-score) to evaluate the CRF Model. F-score conveys balance between Precision and Recall and is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on Test Data \n",
      "0.9738471726864286\n",
      "F score on Training Data \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADP      0.979     0.985     0.982      1869\n",
      "        NOUN      0.966     0.977     0.972      5606\n",
      "        CONJ      0.994     0.994     0.994       480\n",
      "        VERB      0.964     0.960     0.962      2722\n",
      "         ADJ      0.911     0.874     0.892      1274\n",
      "           .      1.000     1.000     1.000      2354\n",
      "           X      1.000     0.997     0.998      1278\n",
      "         NUM      0.991     0.993     0.992       671\n",
      "         DET      0.994     0.995     0.994      1695\n",
      "         ADV      0.927     0.909     0.918       585\n",
      "        PRON      0.998     0.998     0.998       562\n",
      "         PRT      0.979     0.982     0.980       614\n",
      "\n",
      "    accuracy                          0.974     19710\n",
      "   macro avg      0.975     0.972     0.974     19710\n",
      "weighted avg      0.974     0.974     0.974     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=crf.predict(X_test)\n",
    "print(\"F1 score on Test Data \")\n",
    "print(metrics.flat_f1_score(y_test, y_pred,average='weighted', labels=crf.classes_))\n",
    "print(\"F score on Training Data \")\n",
    "y_pred_train = crf.predict(X_train)\n",
    "metrics.flat_f1_score(\n",
    "    y_train,\n",
    "    y_pred_train,\n",
    "    average='weighted',\n",
    "    labels=crf.classes_\n",
    ")\n",
    "\n",
    "### Look at class wise score\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=crf.classes_, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the class-wise score of the CRF (above), we observe that for <font color='darkred'>**predicting Adjectives, the precision** (0.911)**, recall** (0.874) **and F-score** (0.892) **are lower**</font> — indicating that more features related to adjectives must be added to the CRF feature function.\n",
    "\n",
    "The next step is to look at the top 20 most likely Transition Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Transition Features \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of Transition Features \")\n",
    "len(crf.transition_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ADJ', 'NOUN'), 4.114996),\n",
       " (('NOUN', 'NOUN'), 2.935448),\n",
       " (('NOUN', 'VERB'), 2.891987),\n",
       " (('VERB', 'PRT'), 2.519179),\n",
       " (('X', 'VERB'), 2.271558),\n",
       " (('ADP', 'NOUN'), 2.265833),\n",
       " (('NOUN', 'PRT'), 2.172849),\n",
       " (('PRON', 'VERB'), 2.117186),\n",
       " (('NUM', 'NOUN'), 2.059221),\n",
       " (('DET', 'NOUN'), 2.053832),\n",
       " (('ADV', 'VERB'), 1.994419),\n",
       " (('ADV', 'ADJ'), 1.957063),\n",
       " (('NOUN', 'ADP'), 1.838684),\n",
       " (('VERB', 'NOUN'), 1.763319),\n",
       " (('ADJ', 'ADJ'), 1.660578),\n",
       " (('NOUN', 'CONJ'), 1.591359),\n",
       " (('PRT', 'NOUN'), 1.398473),\n",
       " (('NOUN', '.'), 1.381863),\n",
       " (('NOUN', 'ADV'), 1.380086),\n",
       " (('ADV', 'ADV'), 1.301282)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(crf.transition_features_).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, an Adjective is most likely to be followed by a Noun. A verb is most likely to be followed by a Particle (like TO), a Determinant like “The” is also more likely to be followed a noun.\n",
    "Similarly, we can look at the most common state features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of State Features  32413\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of State Features \",len(crf.state_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('prev_word:will', 'VERB'), 6.751359),\n",
       " (('prev_word:would', 'VERB'), 5.940819),\n",
       " (('prefix_1:*', 'X'), 5.830558),\n",
       " (('suffix_4:rest', 'NOUN'), 5.644523),\n",
       " (('suffix_2:ly', 'ADV'), 5.260228),\n",
       " (('is_first_capital', 'NOUN'), 5.043121),\n",
       " (('prev_word:could', 'VERB'), 5.018842),\n",
       " (('suffix_3:ous', 'ADJ'), 4.870949),\n",
       " (('prev_word:to', 'VERB'), 4.849822),\n",
       " (('suffix_4:will', 'VERB'), 4.677684),\n",
       " (('next_word:appeal', 'ADJ'), 4.386434),\n",
       " (('prev_word:how', 'PRT'), 4.35094),\n",
       " (('suffix_4:pany', 'NOUN'), 4.329975),\n",
       " (('prefix_4:many', 'ADJ'), 4.205028),\n",
       " (('prev_word:lock', 'PRT'), 4.153643),\n",
       " (('word_has_hyphen', 'ADJ'), 4.151036),\n",
       " (('prev_word:tune', 'PRT'), 4.147576),\n",
       " (('next_word:Express', 'NOUN'), 4.137127),\n",
       " (('suffix_4:food', 'NOUN'), 4.116688),\n",
       " (('suffix_2:ed', 'VERB'), 4.070659)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(crf.state_features_).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the previous word is “will” or “would”, it is most likely to be a Verb, or if a word ends in “ed”, it is definitely a verb.** As we discussed during defining features, if the word has a hyphen, as per CRF model the probability of being an Adjective is higher. Similarly if the first letter of a word is capitalised, it is more likely to be a NOUN. Natural language is such a complex yet beautiful thing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
