{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article source](https://towardsdatascience.com/three-common-hypothesis-tests-all-data-scientists-should-know-6204067a9ced)) <font size='3ptx'>**<font color='darkblue'>Hypothesis testing</font> is one of the most fundamental elements of inferential statistics. In modern languages like Python and R, these tests are easy to conduct — often with a single line of code.**</font>\n",
    "\n",
    "ut it never fails to puzzle me how few people use them or understand how they work. **In this article I want to use an example to show three common hypothesis tests and how they work under the hood, as well as showing how to run them in R and Python and to understand the results.**\n",
    "* <font size='3ptx'>[**Example 1 — Welch’s t-test**](#sect1)</font>\n",
    "* <font size='3ptx'>[**Example 2— Correlation test**](#sect2)</font>\n",
    "* <font size='3ptx'>[**Example 3— Chi-square test of difference in proportion**](#sect3)</font>\n",
    "\n",
    "### <font color='darkgreen'>The general principles and process of hypothesis testing</font>\n",
    "**Hypothesis testing exists because it is almost never the case that we can observe an entire population when trying to make a conclusion or inference about it**. Almost always, we are trying to make that inference on the basis of a sample of data from that population.\n",
    "\n",
    "Given that we only ever have a sample, **we can never be 100% certain about the inference we want to make. We can be 90%, 95%, 99%, 99.999% certain, but never 100%.**\n",
    "\n",
    "**Hypothesis testing is essentially about calculating how certain we can be about an inference based on our sample.** The most common process for calculating this has several steps:\n",
    "1. **Assume the inference is not true on the population** — this is called the <font color='darkblue'>**null hypothesis**</font>\n",
    "2. Calculate the **statistic of the inference on the sample**\n",
    "3. **Understand the expected distribution of the sampling error around that statistic**\n",
    "4. Use that distribution to understand the **maximum likelihood of your sample statistic being consistent with the null hypothesis**\n",
    "5. **Use a chosen ‘<font color='darkblue'>likelihood cutoff</font>’ — known as alpha — to make a binary decision on whether to accept the null hypothesis or reject it.** The most commonly used value of alpha is 0.05. That is, we usually reject a null hypothesis if it renders the maximum likelihood of our sample statistic to be less than 1 in 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>The salespeople data set</font>\n",
    "To illustrate some common hypothesis tests in this article I will use the [salespeople dataset which can be obtained here](http://peopleanalytics-regression-book.org/data/salespeople.csv). Let’s download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promoted</th>\n",
       "      <th>sales</th>\n",
       "      <th>customer_rate</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>3.94</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>674.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>657.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   promoted  sales  customer_rate  performance\n",
       "0         0  594.0           3.94          2.0\n",
       "1         0  446.0           4.06          3.0\n",
       "2         1  674.0           3.83          4.0\n",
       "3         0  525.0           3.62          2.0\n",
       "4         1  657.0           4.40          3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salespeople_df = pd.read_csv(\"../../datas/salespeople.csv\")\n",
    "salespeople_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see four columns of data:\n",
    "* **promoted** — a binary value indicating if the salesperson was promoted or not in the recent promotion round\n",
    "* **sales** — the recent sales made by the salesperson in thousands of dollars\n",
    "* **customer_rate** — the recent average rating by customers of the salesperson on a scale of 1 to 5\n",
    "* **performance** — the most recent performance rating of the salesperson where a rating of 1 is the lowest and 4 is the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "## <font color='darkblue'>Example 1 — Welch’s t-test</font>\n",
    "**[Welch’s t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test) is a hypothesis test for determining if two populations have different means**. There are a number of varieties of this test, but we will look at the two sample version and we will ask:\n",
    "> if high performing salespeople generate higher sales than low performing salespeople in the population.\n",
    "<br/>\n",
    "\n",
    "We start by assuming **our null hypothesis which is that the difference in mean sales between high performers and low performers in the population is zero or less**. Now we calculate our difference in means statistic for our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.9742424242424"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sales for top and bottom performers\n",
    "perf1_sales_series = salespeople_df[salespeople_df.performance == 1].sales\n",
    "perf4_sales_series = salespeople_df[salespeople_df.performance == 4].sales\n",
    "\n",
    "# difference\n",
    "sales_mean_diff = perf4_sales_series.mean() - perf1_sales_series.mean()\n",
    "sales_mean_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that in our sample, high performers generate around `$155k` more in sales than low performers.\n",
    "\n",
    "**Now, we are assuming that `sales` is a random variable — that is, that the sales of one salesperson is independent of another**. Therefore we expect the difference in mean sales between the two groups to also be a random variable. So we expect the true population difference to be on a t-distribution centered around our sample statistic, which is an estimate of a normal distribution based on our sample. To get the precise t-distribution, we need the [**degrees of freedom**](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) — which can be determined based on the [**Welch-Satterthwaite equation**](https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation) (<font color='brown'>100.98 in this case</font>). We also need to know the standard deviation of the mean difference, which we call the standard error which we can calculate to be 33.48. See [here](http://peopleanalytics-regression-book.org/found-stats.html) for more details on these calculations.\n",
    "\n",
    "Knowing these parameters, we can create **a graph of the t-distribution around our sample statistic**:\n",
    "![1.png](images/1.png)\n",
    "<br/>\n",
    "\n",
    "We can now see the expected probability distribution for our true population statistic. We can also mark the maximum position on this distribution that represents a difference of zero or less — which is our null hypothesis statement. By taking the area under this distribution to the left of the red line, **we calculate the maximum probability of this sample statistic occurring if the null hypothesis were true.** Usually this is calculated by working out the number of standard errors that are needed to get to the red line — known as the t-statistic. In this case it would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.63"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se = 33.48\n",
    "t_statistic = round((0 - sales_mean_diff)/se, 2)\n",
    "t_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our red line is 4.63 standard errors away from the sample statistic. We can use some built-in functions in R to calculate the **associated area under the curve for this t-statistic on a t-distribution with 100.98 degrees of freedom. This represents the maximum probability of our sample statistic occurring under the null hypothesis, and is known as the <font color='darkblue'>p-value</font> of the hypothesis test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=4.629477606844271, pvalue=5.466221730788519e-06)\n"
     ]
    }
   ],
   "source": [
    "ttest = stats.ttest_ind(perf4_sales_series, perf1_sales_series, equal_var=False, alternative = \"greater\")\n",
    "print(ttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So we determine that the maximum probability of our sample statistic occurring under the null hypothesis is 0.000005 — much less than even a very stringent alpha**. In most cases this would be considered too unlikely to accept the null hypothesis and **we will reject it in favour of the alternative hypothesis — that high performing salespeople generate higher sales than low performing salespeople.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "## <font color='darkblue'>Example 2— Correlation test</font>\n",
    "**Another common hypothesis test is a test that two numeric variables have a non-zero correlation.**\n",
    "\n",
    "Let’s ask if there is a non-zero correlation between `sales` and `customer_rate` in our [**salespeople data set**](https://drive.google.com/file/d/1JF_8jFJRULnI_LWkO6g48C2sMeijTOIP/view?usp=sharing). As usual we assume the null hypothesis: \n",
    "> that there is a zero correlation between variables `sales` and `customer_rate`. \n",
    "\n",
    "We then calculate the sample correlation & p-value by [**scipy.stats.pearsonr**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation=0.3378050448586781; p-value=0.000000000086\n"
     ]
    }
   ],
   "source": [
    "# calculate correlation and p-value \n",
    "sales_series = salespeople_df.sales[~np.isnan(salespeople_df.sales)]\n",
    "cust_rate_series = salespeople_df.customer_rate[\n",
    "  ~np.isnan(salespeople_df.customer_rate)\n",
    "]\n",
    "cor, pv = stats.pearsonr(sales_series, cust_rate_series)\n",
    "print(f\"correlation={cor}; p-value={pv:.012f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we expect the true population correlation to lie in a distribution around this sample statistic. A simple correlation like this is expected to observe a t-distribution with n-2 degrees of freedom (<font color='brown'>348 in this case</font>) and the standard error is approximately 0.05. As before we can graph this and position our null hypothesis red line:\n",
    "![2.png](images/2.png)\n",
    "<br/>\n",
    "\n",
    "We see that the red line lies more than 6 standard errors away from the observed statistic and we have `p-value = 0.00000000008` which is extremely small. Thus we can again reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3'></a>\n",
    "## <font color='darkblue'>Example 3— Chi-square test of difference in proportion</font>\n",
    "Unlike the previous two examples, data scientists often have to deal with categorical variables. **A common question is whether there is a difference in proportion across different categories of a such a variable. A [Chi-square test](https://en.wikipedia.org/wiki/Chi-squared_test) is a hypothesis test designed for this purpose.**\n",
    "\n",
    "Let’s ask the question: is there a difference in the proportion of salespeople who are promoted between the different performance categories? Again, we assume the null hypothesis:\n",
    "> the proportion of salespeople who are `promoted` is the same across all the `performance` categories.\n",
    "\n",
    "Let’s look at the proportion of salespeople who were promoted in each `performance` category by creating a contingency table or cross table for `performance` and `promoted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>performance</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>85</td>\n",
       "      <td>77</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "performance  1.0  2.0  3.0  4.0\n",
       "promoted                       \n",
       "0             50   85   77   25\n",
       "1             10   25   48   30"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency = pd.crosstab(salespeople_df.promoted, salespeople_df.performance)\n",
    "contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let’s assume that there was perfect equality across the categories**. \n",
    "\n",
    "We do this by calculating the overall proportion of promoted salespeople and then applying this proportion to the number of salespeople in each category. This would give us the following expected theoretical contingency table by [**scipy.stats.chi2_contingency**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40.62857143 74.48571429 84.64285714 37.24285714]\n",
      " [19.37142857 35.51428571 40.35714286 17.75714286]]\n"
     ]
    }
   ],
   "source": [
    "# perform chi-square test\n",
    "chi2, pv, dof, expected_contingency_table = stats.chi2_contingency(contingency)\n",
    "print(expected_contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use this formula on each entry of the observed and expected contingency tables and sum up the results to form a statistic known as the chi-square statistic.\n",
    "![3.png](images/3.png)\n",
    "<br/>\n",
    "In this case the chi-square statistic is calculated to be 25.895."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.895405268094862\n"
     ]
    }
   ],
   "source": [
    "print(chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with our t-statistic earlier, the chi-square statistic has an expected distribution which is dependent on the degrees of freedom. **The degrees of freedom are calculated by subtracting one from the number of rows and the number of columns of the contingency table and multiplying them together** — in this case the degrees of freedom is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(dof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as before, we can graph our chi-square distribution with 3 degrees of freedom, mark where our chi-square statistic falls in that distribution and calculate the area under the distribution curve to the right of that point to find the associated p-value.\n",
    "![4.png](images/4.png)\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value=1.0030629464566802e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"p-value={pv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see that this area is extremely small (<font color='brown'>p-value=0.00001</font>) indicating that we are likely to reject the null hypothesis and confirm the alternative hypothesis that **there is a difference in promotion rates between promotion categories.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
