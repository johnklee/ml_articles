{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article source](https://machinelearningmastery.com/autoencoder-for-classification/)) **<font size='3ptx'>Autoencoder is a type of neural network that can be used to learn a compressed representation of raw data.</font>**\n",
    "\n",
    "An autoencoder is composed of an encoder and a decoder sub-models. The encoder compresses the input and the decoder attempts to recreate the input from the compressed version provided by the encoder. After training, the encoder model is saved and the decoder is discarded.\n",
    "\n",
    "The encoder can then be used as a data preparation technique to perform feature extraction on raw data that can be used to train a different machine learning model. **In this tutorial, you will discover how to develop and evaluate an autoencoder for classification predictive modeling.**\n",
    "* An autoencoder is a neural network model that can be used to learn a compressed representation of raw data.\n",
    "* How to train an autoencoder model on a training dataset and save just the encoder part of the model.\n",
    "* How to use the encoder as a data preparation step when training a machine learning model.\n",
    "\n",
    "### <font color='darkgreen'>Tutorial Overview</font>\n",
    "This tutorial is divided into three parts; they are:\n",
    "* <font size='3ptx'>[**Autoencoders for Feature Extraction**](#sect1)</font>\n",
    "* <font size='3ptx'>[**Autoencoder for Classification**](#sect2)</font>\n",
    "* <font size='3ptx'>[**Encoder as Data Preparation for Predictive Model**](#sect3)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "## <font color='darkblue'>Autoencoders for Feature Extraction</font>\n",
    "An [autoencoder](https://en.wikipedia.org/wiki/Autoencoder) is a neural network model that seeks to learn a compressed representation of an input.\n",
    "> An autoencoder is a neural network that is trained to attempt to copy its input to its output. <br/><br/>\n",
    "> [**— Page 502, Deep Learning, 2016.**](https://amzn.to/3kV7gdV)\n",
    "\n",
    "They are an unsupervised learning method, although technically, they are trained using supervised learning methods, referred to as self-supervised. Autoencoders are typically trained as part of a broader model that attempts to recreate the input.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "X = model.predict(X)\n",
    "```\n",
    "The design of the autoencoder model purposefully makes this challenging by restricting the architecture to a bottleneck at the midpoint of the model, from which the reconstruction of the input data is performed.\n",
    "\n",
    "There are many types of autoencoders, and their use varies, but perhaps the more common use is as a learned or automatic feature extraction model.\n",
    "\n",
    "In this case, once the model is fit, the reconstruction aspect of the model can be discarded and the model up to the point of the bottleneck can be used. The output of the model at the bottleneck is a fixed-length vector that provides a compressed representation of the input data.\n",
    "\n",
    "> Usually they are restricted in ways that allow them to copy only approximately, and to copy only input that resembles the training data. Because the model is forced to prioritize which aspects of the input should be copied, it often learns useful properties of the data. <br/><br/>\n",
    "> [— Page 502, Deep Learning, 2016.](https://amzn.to/3kV7gdV)\n",
    "\n",
    "Input data from the domain can then be provided to the model and **the output of the model at the bottleneck can be used as a feature vector in a supervised learning model, for visualization, or more generally for dimensionality reduction.**\n",
    "\n",
    "Next, let’s explore how we might develop an autoencoder for feature extraction on a classification predictive modeling problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "## <font color='darkblue'>Autoencoder for Classification</font>\n",
    "In this section, we will develop an autoencoder to learn a compressed representation of the input features for a classification predictive modeling problem. **First, let’s define a classification predictive modeling problem.**\n",
    "\n",
    "We will use the [make_classification() scikit-learn function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) to define a synthetic binary (2-class) classification task with 100 input features (columns) and 1,000 examples (rows). Importantly, we will define the problem in such a way that most of the input variables are redundant (90 of the 100 or 90 percent), **allowing the autoencoder later to learn a useful compressed representation.**\n",
    "\n",
    "The example below defines the dataset and summarizes its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
    "\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will develop a Multilayer Perceptron (MLP) autoencoder model. The model will take all of the input columns, then output the same values. It will learn to recreate the input pattern exactly.\n",
    "\n",
    "**The autoencoder consists of two parts: the encoder and the decoder.** The encoder learns how to interpret the input and compress it to an internal representation defined by the bottleneck layer. The decoder takes the output of the encoder (the bottleneck layer) and attempts to recreate the input.\n",
    "\n",
    "Once the autoencoder is trained, the decoder is discarded and **we only keep the encoder and use it to compress examples of input to vectors output by the bottleneck layer.**\n",
    "\n",
    "In this first autoencoder, we won’t compress the input at all and will **use a bottleneck layer the same size as the input. This should be an easy problem that the model will learn nearly perfectly and is intended to confirm our model is implemented correctly.**\n",
    "\n",
    "Prior to defining and fitting the model, we will **split the data into train and test sets and scale the input data by normalizing the values to the range 0-1, a good practice with MLPs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the encoder to have two hidden layers, the first with two times the number of inputs (e.g. 200) and the second with the same number of inputs (100), followed by the bottleneck layer with the same number of inputs as the dataset (100).\n",
    "\n",
    "**To ensure the model learns well, we will use batch normalization and leaky [ReLU activation](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define encoder\n",
    "n_inputs = X.shape[1]\n",
    "visible = Input(shape=(n_inputs,))\n",
    "\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# bottleneck\n",
    "n_bottleneck = n_inputs\n",
    "bottleneck = Dense(n_bottleneck)(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder will be defined with a similar structure, although in reverse.\n",
    "\n",
    "It will have two hidden layers, the first with the number of inputs in the dataset (e.g. 100) and the second with double the number of inputs (e.g. 200). The output layer will have the same number of nodes as there are columns in the input data and will use a linear activation function to output numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decoder, level 1\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n",
    "\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be fit using the efficient Adam version of stochastic gradient descent and minimizes the mean squared error, given that reconstruction is a type of multi-output regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the layers in the autoencoder model to get a feeling for how the data flows through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "=================================================================\n",
      "Total params: 103,200\n",
      "Trainable params: 102,000\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can train the model to reproduce the input and keep track of the performance of the model on the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 - 0s - loss: 0.2339 - val_loss: 0.2048\n",
      "Epoch 2/200\n",
      "42/42 - 0s - loss: 0.0352 - val_loss: 0.1121\n",
      "Epoch 3/200\n",
      "42/42 - 0s - loss: 0.0234 - val_loss: 0.0572\n",
      "Epoch 4/200\n",
      "42/42 - 0s - loss: 0.0192 - val_loss: 0.0330\n",
      "Epoch 5/200\n",
      "42/42 - 0s - loss: 0.0165 - val_loss: 0.0214\n",
      "Epoch 6/200\n",
      "42/42 - 0s - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 7/200\n",
      "42/42 - 0s - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 8/200\n",
      "42/42 - 0s - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 9/200\n",
      "42/42 - 0s - loss: 0.0112 - val_loss: 0.0074\n",
      "Epoch 10/200\n",
      "42/42 - 0s - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 11/200\n",
      "42/42 - 0s - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 12/200\n",
      "42/42 - 0s - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 13/200\n",
      "42/42 - 0s - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 14/200\n",
      "42/42 - 0s - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 15/200\n",
      "42/42 - 0s - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 16/200\n",
      "42/42 - 0s - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 17/200\n",
      "42/42 - 0s - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 18/200\n",
      "42/42 - 0s - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 19/200\n",
      "42/42 - 0s - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 20/200\n",
      "42/42 - 0s - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 21/200\n",
      "42/42 - 0s - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 22/200\n",
      "42/42 - 0s - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 23/200\n",
      "42/42 - 0s - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 24/200\n",
      "42/42 - 0s - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 25/200\n",
      "42/42 - 0s - loss: 0.0071 - val_loss: 0.0040\n",
      "Epoch 26/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0032\n",
      "Epoch 27/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 28/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 29/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 30/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 31/200\n",
      "42/42 - 0s - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 32/200\n",
      "42/42 - 0s - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 33/200\n",
      "42/42 - 0s - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 34/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 35/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 36/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0031\n",
      "Epoch 37/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0029\n",
      "Epoch 38/200\n",
      "42/42 - 0s - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 39/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 40/200\n",
      "42/42 - 0s - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 41/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 42/200\n",
      "42/42 - 0s - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 43/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 44/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 45/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 46/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 47/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 48/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 49/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 50/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0026\n",
      "Epoch 51/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 52/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 53/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 54/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 55/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 56/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 57/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 58/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 59/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 60/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 61/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 62/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 63/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 64/200\n",
      "42/42 - 0s - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 65/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 66/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 67/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 68/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 69/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 70/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 71/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 72/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 73/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 74/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 75/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 76/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 77/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 78/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 79/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 80/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 81/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 82/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 83/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 84/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 85/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 86/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 87/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 88/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 89/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 90/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 91/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 92/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 93/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 94/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 95/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 96/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 97/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 98/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 99/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 100/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 101/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 102/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 103/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 104/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 105/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 106/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 107/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 108/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 109/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 110/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 111/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 112/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 113/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 114/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 115/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 116/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 117/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 118/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 119/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 120/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 121/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 122/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 123/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 124/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 125/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 126/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 127/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 128/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 129/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 130/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 131/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 132/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 133/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 134/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 135/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 136/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 137/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 138/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 139/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 140/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 141/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 143/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 144/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 145/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 146/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 147/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 148/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 149/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 150/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 151/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 152/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 9.5503e-04\n",
      "Epoch 153/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 154/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 155/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 156/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 157/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 158/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 159/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 160/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 8.5970e-04\n",
      "Epoch 161/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 162/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 163/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 164/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 165/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 166/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 167/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 168/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 169/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 170/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 171/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 172/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 173/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 174/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 175/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 176/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 177/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 178/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 179/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 180/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 181/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 182/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 183/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 184/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 185/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 186/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 187/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 9.4951e-04\n",
      "Epoch 188/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 189/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 190/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 191/200\n",
      "42/42 - 0s - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 192/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 193/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 194/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 195/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 196/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 8.3030e-04\n",
      "Epoch 197/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 198/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 199/200\n",
      "42/42 - 0s - loss: 0.0028 - val_loss: 9.9817e-04\n",
      "Epoch 200/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 8.4261e-04\n"
     ]
    }
   ],
   "source": [
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we can plot the learning curves for the train and test sets to confirm the model learned the reconstruction problem well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the encoder model for use later, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "# Save the encoder to file\n",
    "encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. We know how to develop an autoencoder without compression. Next, let’s change the configuration of the model so that the bottleneck layer has half the number of nodes (e.g. 50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               20100     \n",
      "=================================================================\n",
      "Total params: 93,150\n",
      "Trainable params: 91,950\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_autoencoder(n_inputs=X.shape[1], n_bottleneck=round(float(X.shape[1])/2.0)):\n",
    "    visible = Input(shape=(n_inputs,))\n",
    "\n",
    "    # encoder level 1\n",
    "    e = Dense(n_inputs*2)(visible)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "\n",
    "    # encoder level 2\n",
    "    e = Dense(n_inputs)(e)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "\n",
    "    # bottleneck\n",
    "    bottleneck = Dense(n_bottleneck)(e)\n",
    "    \n",
    "    # Define decoder, level 1\n",
    "    d = Dense(n_inputs)(bottleneck)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "\n",
    "    # decoder level 2\n",
    "    d = Dense(n_inputs*2)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "\n",
    "    # output layer\n",
    "    output = Dense(n_inputs, activation='linear')(d)\n",
    "\n",
    "    # define autoencoder model\n",
    "    model = Model(inputs=visible, outputs=output)\n",
    "    \n",
    "    # compile autoencoder model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model, visible, bottleneck\n",
    "\n",
    "model, visible, bottleneck = get_autoencoder()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 - 0s - loss: 0.2276 - val_loss: 0.1733\n",
      "Epoch 2/200\n",
      "42/42 - 0s - loss: 0.0371 - val_loss: 0.1089\n",
      "Epoch 3/200\n",
      "42/42 - 0s - loss: 0.0240 - val_loss: 0.0554\n",
      "Epoch 4/200\n",
      "42/42 - 0s - loss: 0.0191 - val_loss: 0.0317\n",
      "Epoch 5/200\n",
      "42/42 - 0s - loss: 0.0156 - val_loss: 0.0206\n",
      "Epoch 6/200\n",
      "42/42 - 0s - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 7/200\n",
      "42/42 - 0s - loss: 0.0128 - val_loss: 0.0109\n",
      "Epoch 8/200\n",
      "42/42 - 0s - loss: 0.0125 - val_loss: 0.0095\n",
      "Epoch 9/200\n",
      "42/42 - 0s - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 10/200\n",
      "42/42 - 0s - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 11/200\n",
      "42/42 - 0s - loss: 0.0112 - val_loss: 0.0062\n",
      "Epoch 12/200\n",
      "42/42 - 0s - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 13/200\n",
      "42/42 - 0s - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 14/200\n",
      "42/42 - 0s - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 15/200\n",
      "42/42 - 0s - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 16/200\n",
      "42/42 - 0s - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 17/200\n",
      "42/42 - 0s - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 18/200\n",
      "42/42 - 0s - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 19/200\n",
      "42/42 - 0s - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 20/200\n",
      "42/42 - 0s - loss: 0.0073 - val_loss: 0.0041\n",
      "Epoch 21/200\n",
      "42/42 - 0s - loss: 0.0070 - val_loss: 0.0037\n",
      "Epoch 22/200\n",
      "42/42 - 0s - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 23/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 24/200\n",
      "42/42 - 0s - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 25/200\n",
      "42/42 - 0s - loss: 0.0072 - val_loss: 0.0037\n",
      "Epoch 26/200\n",
      "42/42 - 0s - loss: 0.0071 - val_loss: 0.0036\n",
      "Epoch 27/200\n",
      "42/42 - 0s - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 28/200\n",
      "42/42 - 0s - loss: 0.0069 - val_loss: 0.0038\n",
      "Epoch 29/200\n",
      "42/42 - 0s - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 30/200\n",
      "42/42 - 0s - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 31/200\n",
      "42/42 - 0s - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 32/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 33/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 34/200\n",
      "42/42 - 0s - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 35/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 36/200\n",
      "42/42 - 0s - loss: 0.0059 - val_loss: 0.0030\n",
      "Epoch 37/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 38/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 39/200\n",
      "42/42 - 0s - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 40/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 41/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 42/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 43/200\n",
      "42/42 - 0s - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 44/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 45/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 46/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 47/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 48/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 49/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 50/200\n",
      "42/42 - 0s - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 51/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 52/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 53/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 54/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 55/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 56/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 57/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 58/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 59/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 60/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 61/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 62/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 63/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 64/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 65/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 66/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 67/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 68/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 69/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 70/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 71/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 72/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 73/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 74/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 75/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 76/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 77/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 78/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 79/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 80/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 81/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 82/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 83/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 84/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 85/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 86/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 87/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 88/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 89/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 90/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 91/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 92/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 93/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 94/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 95/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 96/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 97/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 98/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 99/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 100/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 101/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 102/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 103/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 104/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 105/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 106/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 107/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 108/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 109/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 110/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 111/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 112/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 113/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 114/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 115/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 116/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 117/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 118/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 119/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 120/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 121/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 122/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 123/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 124/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 125/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 126/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 127/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 128/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 129/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 130/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 131/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 132/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 133/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 134/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 135/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 136/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 137/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 138/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 139/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 140/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 141/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 143/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 144/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 145/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 146/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 147/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 148/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 149/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 150/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 151/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 152/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 153/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 154/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 155/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 156/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 157/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 158/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 159/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 160/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 161/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 162/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 163/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 164/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 165/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 166/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 167/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 168/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 169/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 170/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 171/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 172/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 173/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 174/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 175/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 176/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 177/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 178/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 179/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 180/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 181/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 182/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 183/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 184/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 185/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 186/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 187/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 188/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 189/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 190/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 191/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 192/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 193/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 194/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 195/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 196/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 197/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 198/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 199/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 200/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "# save the encoder to file\n",
    "encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained encoder is saved to the file “encoder.h5” that we can load and use later. Next, let’s explore how we might use the trained encoder model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3'></a>\n",
    "## <font color='darkblue'>Encoder as Data Preparation for Predictive Model</font>\n",
    "In this section, we will use the trained encoder from the autoencoder to compress input data and train a different predictive model.\n",
    "\n",
    "**First, let’s establish a baseline in performance on this problem.** This is important as if the performance of a model is not improved by the compressed encoding, then the compressed encoding does not add value to the project and should not be used.\n",
    "\n",
    "We can train a logistic regression model on the training dataset directly and evaluate the performance of the model on the holdout test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
    "\n",
    "# Split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# Scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit model on training set\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939393939393939\n"
     ]
    }
   ],
   "source": [
    "# make prediction on test set\n",
    "yhat = model.predict(X_test)\n",
    "# calculate accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that the model achieves a classification accuracy of about 89.3 percent. **We would hope and expect that a logistic regression model fit on an encoded version of the input to achieve better accuracy for the encoding to be considered useful.**\n",
    "\n",
    "We can update the example to first encode the data using the encoder model trained in the previous section. First, we can load the trained encoder model from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# load the model from file\n",
    "encoder = load_model('encoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the encoder to transform the raw input data (e.g. 100 columns) into bottleneck vectors (e.g. 50 element vectors). This process can be applied to the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 50)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encode.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this encoded data to train and evaluate the logistic regression model, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johnlee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model on the training set\n",
    "model.fit(X_train_encode, y_train)\n",
    "# make predictions on the test set\n",
    "yhat = model.predict(X_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9212121212121213\n"
     ]
    }
   ],
   "source": [
    "# calculate classification accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that the model achieves a classification accuracy of about 92.1 percent. This is a better classification accuracy than the same model evaluated on the raw dataset, suggesting that the encoding is helpful for our chosen model and test harness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
