{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f515a1-0cad-4aa1-bf81-d8d920b32d2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "<font size='3ptx'><b>Large language models generate text, not structured data. Even when you prompt them to return structured data, they’re still generating text that looks like valid JSON.</b> The output may have incorrect field names, missing required fields, wrong data types, or extra text wrapped around the actual data. Without validation, these inconsistencies cause runtime errors that are difficult to debug.</font>\n",
    "\n",
    "<b>[Pydantic](https://docs.pydantic.dev/latest/) helps you validate data at runtime using Python type hints</b>. It checks that LLM outputs match your expected schema, converts types automatically where possible, and provides clear error messages when validation fails. This gives you a reliable contract between the LLM’s output and your application’s requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148b8e4-c724-415d-8d76-c0f1918a5778",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>Agenda</font></b>\n",
    "Topics we will cover include:\n",
    "* Designing robust Pydantic models (including custom validators and nested schemas).\n",
    "* Parsing “messy” LLM outputs safely and surfacing precise validation errors.\n",
    "* Integrating validation with OpenAI, LangChain, and LlamaIndex plus retry strategies.\n",
    "\n",
    "![ui](https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-complete-guide-pydantic-featured-image.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae5c30-a536-4493-af90-aca2b2d8d09e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <b><font color='darkblue'>Getting Started</font></b>\n",
    "<font size='3ptx'><b>Let’s start with a simple example by building a tool that extracts contact information from text.</b> The LLM reads unstructured text and returns structured data that we validate with Pydantic:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8025427a-94d2-4f31-9cea-293e2689e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, EmailStr, field_validator\n",
    "from typing import Optional\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    phone: Optional[str] = None\n",
    "    company: Optional[str] = None\n",
    "    \n",
    "    @field_validator('phone')\n",
    "    @classmethod\n",
    "    def validate_phone(cls, v):\n",
    "        if v is None:\n",
    "            return v\n",
    "        cleaned = ''.join(filter(str.isdigit, v))\n",
    "        if len(cleaned) < 10:\n",
    "            raise ValueError('Phone number must have at least 10 digits')\n",
    "        return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c5f71-eac2-45ff-b858-4a5592fd31bc",
   "metadata": {},
   "source": [
    "<b>All Pydantic models inherit from [**BaseModel**](https://docs.pydantic.dev/latest/api/base_model/#BaseModel), which provides automatic validation</b>. Type hints like `name: str` help Pydantic validate types at runtime. The `EmailStr` type validates email format without needing a custom regex. Fields marked with `Optional[str] = None` can be missing or null. The `@field_validator` decorator lets you add custom validation logic, like cleaning phone numbers and checking their length.\n",
    "\n",
    "Here’s how to use the model to validate sample LLM output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce5b5cd-2cbc-4072-9848-8df74f854266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarah Johnson\n",
      "sarah.johnson@techcorp.com\n",
      "{'name': 'Sarah Johnson', 'email': 'sarah.johnson@techcorp.com', 'phone': '5551234567', 'company': 'TechCorp Industries'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_response = '''\n",
    "{\n",
    "    \"name\": \"Sarah Johnson\",\n",
    "    \"email\": \"sarah.johnson@techcorp.com\",\n",
    "    \"phone\": \"(555) 123-4567\",\n",
    "    \"company\": \"TechCorp Industries\"\n",
    "}\n",
    "'''\n",
    "\n",
    "data = json.loads(llm_response)\n",
    "contact = ContactInfo(**data)\n",
    "\n",
    "print(contact.name) \n",
    "print(contact.email)  \n",
    "print(contact.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd718277-55c2-4e73-a3cf-bbc59edb6f61",
   "metadata": {},
   "source": [
    "When you create a <b><font color='blue'>ContactInfo</font></b> instance, <b>Pydantic validates everything automatically. If validation fails, you get a clear error message telling you exactly what went wrong</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b84c7-18b6-4edb-92b6-8c598dea9875",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Parsing and Validating LLM Outputs</font></b>\n",
    "<font size='3ptx'><b>LLMs don’t always return perfect JSON</b>. Sometimes they add markdown formatting, explanatory text, or mess up the structure. Here’s how to handle these cases:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2588f1ad-26a3-4a7c-8f27-c2a61deceef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError, field_validator\n",
    "import json\n",
    "import re\n",
    "\n",
    "class ProductReview(BaseModel):\n",
    "    product_name: str\n",
    "    rating: int\n",
    "    review_text: str\n",
    "    would_recommend: bool\n",
    "    \n",
    "    @field_validator('rating')\n",
    "    @classmethod\n",
    "    def validate_rating(cls, v):\n",
    "        if not 1 <= v <= 5:\n",
    "            raise ValueError('Rating must be an integer between 1 and 5')\n",
    "        return v\n",
    "\n",
    "\n",
    "def extract_json_from_llm_response(response: str) -> dict:\n",
    "    \"\"\"Extract JSON from LLM response that might contain extra text.\"\"\"\n",
    "    json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json.loads(json_match.group())\n",
    "    raise ValueError(\"No JSON found in response\")\n",
    "\n",
    "\n",
    "def parse_review(llm_output: str) -> ProductReview:\n",
    "    \"\"\"Safely parse and validate LLM output.\"\"\"\n",
    "    try:\n",
    "        data = extract_json_from_llm_response(llm_output)\n",
    "        review = ProductReview(**data)\n",
    "        return review\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        raise\n",
    "    except ValidationError as e:\n",
    "        print(f\"Validation error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f80d1-2662-40d1-b173-cc4476f49d21",
   "metadata": {},
   "source": [
    "This approach uses regex to find JSON within response text, handling cases where the LLM adds explanatory text before or after the data. We catch different exception types separately:\n",
    "- <b><font color='blue'>JSONDecodeError</font></b> for malformed JSON,\n",
    "- <b><font color='blue'>ValidationError</font></b> for data that doesn’t match the schema, and\n",
    "- General exceptions for unexpected issues.\n",
    "\n",
    "The `extract_json_from_llm_response` function handles text cleanup while `parse_review` handles validation, keeping concerns separated. In production, you’d want to log these errors or retry the LLM call with an improved prompt.\n",
    "\n",
    "This example shows an LLM response with extra text that our parser handles correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1909d6-0dee-4272-972b-ab1185777ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Wireless Headphones X100\n",
      "Rating: 4/5\n"
     ]
    }
   ],
   "source": [
    "messy_response = '''\n",
    "Here's the review in JSON format:\n",
    "\n",
    "{\n",
    "    \"product_name\": \"Wireless Headphones X100\",\n",
    "    \"rating\": 4,\n",
    "    \"review_text\": \"Great sound quality, comfortable for long use.\",\n",
    "    \"would_recommend\": true\n",
    "}\n",
    "\n",
    "Hope this helps!\n",
    "'''\n",
    "\n",
    "review = parse_review(messy_response)\n",
    "print(f\"Product: {review.product_name}\")\n",
    "print(f\"Rating: {review.rating}/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb9ccf3-fc2c-4e06-84c0-02ad1da925cc",
   "metadata": {},
   "source": [
    "The parser extracts the JSON block from the surrounding text and validates it against the <b><font color='blue'>ProductReview</font></b> schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c9c15-de19-4fee-bfc2-66d07ebb52ce",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Advanced: Using Pydantic validator (v1/v2)</font></b>\n",
    "If you want the model itself to accept messy text, you can add a `root_validator` (v1) or `model_validator` (v2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4874ab4c-a47b-45d5-b02c-f949f8e214f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4111/952699920.py:8: PydanticDeprecatedSince20: Pydantic V1 style `@root_validator` validators are deprecated. You should migrate to Pydantic V2 style `@model_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  @root_validator(pre=True)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, root_validator\n",
    "\n",
    "class UserModel(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def extract_json(cls, values):\n",
    "        # values could be a dict or raw string\n",
    "        if isinstance(values, str):\n",
    "            import re, json\n",
    "            match = re.search(r'```json(.*?)```', values, re.DOTALL)\n",
    "            if match:\n",
    "                values = json.loads(match.group(1).strip())\n",
    "        print(f'Values: {values}')\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8bc4b75-3b41-4a3e-9fad-80d6f5ec2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: {'name': 'John', 'age': 30}\n",
      "name='John' age=30\n"
     ]
    }
   ],
   "source": [
    "user = UserModel(**{'name': 'John', 'age': 30})\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d6cb5-954f-44ba-8a5b-efc94acdfe39",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Working with Nested Models</font></b>\n",
    "<font size='3ptx'>Real-world data is rarely flat. Here’s how to handle nested structures like a product with multiple reviews and specifications:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea285c7-12b6-4e43-94d5-c2bea9b9184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List\n",
    "\n",
    "class Specification(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "\n",
    "class Review(BaseModel):\n",
    "    reviewer_name: str\n",
    "    rating: int = Field(..., ge=1, le=5)\n",
    "    comment: str\n",
    "    verified_purchase: bool = False\n",
    "    \n",
    "class Product(BaseModel):\n",
    "    id: str\n",
    "    name: str\n",
    "    price: float = Field(..., gt=0)\n",
    "    category: str\n",
    "    specifications: List[Specification]\n",
    "    reviews: List[Review]\n",
    "    average_rating: float = Field(..., ge=1, le=5)\n",
    "    \n",
    "    @field_validator('average_rating')\n",
    "    @classmethod\n",
    "    def check_average_matches_reviews(cls, v, info):\n",
    "        reviews = info.data.get('reviews', [])\n",
    "        if reviews:\n",
    "            calculated_avg = sum(r.rating for r in reviews) / len(reviews)\n",
    "            if abs(calculated_avg - v) > 0.1:\n",
    "                raise ValueError(\n",
    "                    f'Average rating {v} does not match calculated average {calculated_avg:.2f}'\n",
    "                )\n",
    "        return v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
