{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article source](https://machinelearningmastery.com/simple-genetic-algorithm-from-scratch-in-python/)) <font size='3ptx'>**The [genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm) is a stochastic global optimization algorithm.**</font>\n",
    "\n",
    "It may be one of the most popular and widely known biologically inspired algorithms, along with artificial neural networks.\n",
    "\n",
    "The algorithm is a type of evolutionary algorithm and performs an optimization procedure inspired by the biological theory of evolution by means of natural selection with a binary representation and simple operators based on genetic recombination and genetic mutations.\n",
    "\n",
    "**In this tutorial, you will discover the genetic algorithm optimization algorithm.** After completing this tutorial, you will know:\n",
    "* Genetic algorithm is a stochastic optimization algorithm inspired by evolution.\n",
    "* How to implement the genetic algorithm from scratch in Python.\n",
    "* How to apply the genetic algorithm to a continuous objective function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Tutorial Overview</font>\n",
    "This tutorial is divided into four parts; they are:\n",
    "* <font size='3ptx'>[**Genetic Algorithm**](#sect1)</font>\n",
    "* <font size='3ptx'>[**Genetic Algorithm From Scratch**](#sect2)</font>\n",
    "* <font size='3ptx'>[**Genetic Algorithm for OneMax**](#sect3)</font>\n",
    "* <font size='3ptx'>[**Genetic Algorithm for Continuous Function Optimization**](#sect4)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "## <font color='darkblue'>Genetic Algorithm</font>\n",
    "**The [Genetic Algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm) is a stochastic global search optimization algorithm.**\n",
    "\n",
    "**It is inspired by the biological theory of evolution by means of natural selection**. Specifically, the new synthesis that combines an understanding of genetics with the theory.\n",
    "> Genetic algorithms (algorithm 9.4) borrow inspiration from biological evolution, where fitter individuals are more likely to pass on their genes to the next generation.<br/><br/>\n",
    "> [— Page 148, Algorithms for Optimization, 2019.](https://amzn.to/2Traqek)\n",
    "<br/>\n",
    "\n",
    "The algorithm uses analogs of a **genetic representation** (<font color='brown'>bitstrings</font>), **fitness** (<font color='brown'>function evaluations</font>), **genetic recombination** (<font color='brown'>crossover of bitstrings</font>), and **mutation** (<font color='brown'>flipping bits</font>).\n",
    "\n",
    "The algorithm works by first creating a population of a fixed size of random bitstrings. The main loop of the algorithm is repeated for a fixed number of iterations or until no further improvement is seen in the best solution over a given number of iterations.\n",
    "\n",
    "**One iteration of the algorithm is like an evolutionary generation.**\n",
    "\n",
    "First, **the population of bitstrings** (<font color='brown'>candidate solutions</font>) **are evaluated using the <font color='darkblue'>objective function</font>**. The objective function evaluation for each candidate solution is taken as the fitness of the solution, which may be minimized or maximized.\n",
    "\n",
    "Then, parents are selected based on their fitness. A given candidate solution may be used as parent zero or more times. **A simple and effective approach to selection involves drawing `k` candidates from the population randomly and selecting the member from the group with the best fitness. This is called <font color='darkblue'>tournament selection</font> where `k` is a hyperparameter and set to a value such as 3**. This simple approach simulates a more costly fitness-proportionate selection scheme.\n",
    "> In tournament selection, each parent is the fittest out of <i>k</i> randomly chosen chromosomes of the population <br/><br/>\n",
    "> [— Page 151, Algorithms for Optimization, 2019.](https://amzn.to/2Traqek)\n",
    "<br/>\n",
    "\n",
    "**Parents are used as the basis for generating the next generation of candidate points and one parent for each position in the population is required.**\n",
    "\n",
    "Parents are then taken in pairs and used to create two children. <font color='darkblue'>Recombination</font> is performed using a crossover operator. This involves selecting a random split point on the bit string, then creating a child with the bits up to the split point from the first parent and from the split point to the end of the string from the second parent. This process is then inverted for the second child.\n",
    "\n",
    "For example the two parents:\n",
    "* parent1 = 00000\n",
    "* parent2 = 11111\n",
    "\n",
    "May result in two cross-over children:\n",
    "* child1 = 00011\n",
    "* child2 = 11100\n",
    "\n",
    "**This is called <font color='darkblue'>one point crossover</font>, and there are many other variations of the operator.**\n",
    "\n",
    "**Crossover is applied probabilistically for each pair of parents, meaning that in some cases, copies of the parents are taken as the children instead of the recombination operator**. Crossover is controlled by a hyperparameter set to a large value, such as 80 percent or 90 percent.\n",
    "> Crossover is the Genetic Algorithm’s distinguishing feature. It involves mixing and matching parts of two parents to form children. How you do that mixing and matching depends on the representation of the individuals.<br/><br/>\n",
    "> [— Page 36, Essentials of Metaheuristics, 2011.](https://amzn.to/2HxZVn4)\n",
    "<br/>\n",
    "\n",
    "**<font color='darkblue'>Mutation</font> involves flipping bits in created children candidate solutions**. Typically, the mutation rate is set to `1/L`, where `L` is the length of the bitstring.\n",
    "\n",
    "> Each bit in a binary-valued chromosome typically has a small probability of being flipped. For a chromosome with `m` bits, this mutation rate is typically set to `1/m`, yielding an average of one mutation per child chromosome. <br/><br/>\n",
    "> [— Page 155, Algorithms for Optimization, 2019.](https://amzn.to/2Traqek)\n",
    "<br/>\n",
    "\n",
    "For example, if a problem used a bitstring with 20 bits, then a good default mutation rate would be (1/20) = 0.05 or a probability of 5 percent.\n",
    "\n",
    "This defines the simple genetic algorithm procedure. It is a large field of study, and there are many extensions to the algorithm.\n",
    "\n",
    "Now that we are familiar with the simple genetic algorithm procedure, let’s look at how we might implement it from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "## <font color='darkblue'>Genetic Algorithm From Scratch</font>\n",
    "**In this section, we will develop an implementation of the genetic algorithm.**\n",
    "\n",
    "The first step is to create a population of random bitstrings. We could use boolean values True and False, string values ‘0’ and ‘1’, or integer values 0 and 1. In this case, we will use integer values.\n",
    "\n",
    "We can generate an array of integer values in a range using the [randint()](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html) function, and we can specify the range as values starting at 0 and less than 2, e.g. 0 or 1. We will also represent a candidate solution as a list instead of a NumPy array to keep things simple.\n",
    "```python\n",
    "# initial population of random bitstring\n",
    "pop = [randint(0, 2, n_bits).tolist() for _ in range(n_pop)]\n",
    "```\n",
    "\n",
    "An initial population of random bitstring can be created as follows, where **“`n_pop`” is a hyperparameter that controls the population size and “`n_bits`” is a hyperparameter that defines the number of bits in a single candidate solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bits\n",
    "n_bits = 20\n",
    "# define the population size\n",
    "n_pop = 100\n",
    "# Population\n",
    "pop = [randint(0, 2, n_bits).tolist() for _ in range(n_pop)]\n",
    "pop[:10]\n",
    "# Crossover rate\n",
    "r_cross = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can enumerate over a fixed number of algorithm iterations, in this case, controlled by a hyperparameter named “`n_iter`“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the total iterations\n",
    "n_iter = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in the algorithm iteration is to evaluate all candidate solutions. **We will use a function named <font color='blue'>objective()</font> as a generic objective function and call it to get a fitness score, which we will minimize**.\n",
    "```python\n",
    "# evaluate all candidates in the population\n",
    "scores = [objective(c) for c in pop]\n",
    "```\n",
    "\n",
    "We can then select parents that will be used to create children.\n",
    "\n",
    "**The tournament selection procedure can be implemented as a function that takes the population and returns one selected parent.** The `k` value is fixed at 3 with a default argument, but you can experiment with different values if you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tournament selection\n",
    "def selection(pop, scores, k=3):\n",
    "    # first random selection\n",
    "    selection_ix = randint(len(pop))\n",
    "    for ix in randint(0, len(pop), k-1):\n",
    "        # check if better (e.g. perform a tournament)\n",
    "        if scores[ix] < scores[selection_ix]:\n",
    "            selection_ix = ix\n",
    "    return pop[selection_ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then call this function one time for each position in the population to create a list of parents:\n",
    "```python\n",
    "# select parents\n",
    "selected = [selection(pop, scores) for _ in range(n_pop)]\n",
    "```\n",
    "We can then create the next generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first requires a function to perform crossover. This function will take two parents and the crossover rate. The crossover rate is a hyperparameter that determines whether crossover is performed or not, and if not, the parents are copied into the next generation. It is a probability and typically has a large value close to 1.0.\n",
    "\n",
    "The <font color='blue'>crossover()</font> function below implements crossover using a draw of a random number in the range `[0,1]` to determine if crossover is performed, then selecting a valid split point if crossover is to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossover two parents to create two children\n",
    "def crossover(p1, p2, r_cross):\n",
    "    # children are copies of parents by default\n",
    "    c1, c2 = p1.copy(), p2.copy()\n",
    "    # check for recombination\n",
    "    if rand() < r_cross:\n",
    "        # select crossover point that is not on the end of the string\n",
    "        pt = randint(1, len(p1)-2)\n",
    "        # perform crossover\n",
    "        c1 = p1[:pt] + p2[pt:]\n",
    "        c2 = p2[:pt] + p1[pt:]\n",
    "        \n",
    "    return [c1, c2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function to perform mutation.\n",
    "\n",
    "This procedure simply flips bits with a low probability controlled by the “`r_mut`” hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutation rate\n",
    "r_mut = 1.0 / float(n_bits)\n",
    "\n",
    "# mutation operator\n",
    "def mutation(bitstring, r_mut):\n",
    "    for i in range(len(bitstring)):\n",
    "        # check for a mutation\n",
    "        if rand() < r_mut:\n",
    "            # flip the bit\n",
    "            bitstring[i] = 1 - bitstring[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can then loop over the list of parents and create a list of children to be used as the next generation**, calling the <font color='blue'>crossover</font> and <font color='blue'>mutation</font> functions as needed. Below is sample code:\n",
    "```python\n",
    "children = []\n",
    "for i in range(0, n_pop, 2):\n",
    "    # Get selected parent in pairs\n",
    "    p1, p2 = selected[i], selected[i+1]\n",
    "    # Crossover & Mutation operation\n",
    "    for c in crossover(p1, p2, r_cross):       \n",
    "        mutation(c, r_mut)\n",
    "        # Store for next generation\n",
    "        children.append(c)\n",
    "```\n",
    "We can tie all of this together into a function named <font color='blue'>genetic_algorithm()</font> that takes the name of the objective function and the hyperparameters of the search, and returns the best solution found during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic algorithm\n",
    "def genetic_algorithm(objective, n_bits=n_bits, n_pop=n_pop, r_cross=r_cross, r_mut=r_mut):\n",
    "    # Initialize population of random bitstring\n",
    "    pop = [randint(0, 2, n_bits).tolist() for _ in range(n_pop)]\n",
    "    # Keep track of best solution\n",
    "    best, best_eval = 0, objective(pop[0])\n",
    "    # Enumerate generations\n",
    "    for gen in range(n_iter):\n",
    "        # Evaluate all candidates in the population\n",
    "        scores = [objective(c) for c in pop]\n",
    "        # Check for new best solution\n",
    "        for i in range(n_pop):\n",
    "            if scores[i] < best_eval:\n",
    "                best, best_eval = pop[i], scores[i]\n",
    "                print(f\"> {gen}, new best f({pop[i]}) = {scores[i]:.03f}\")\n",
    "                \n",
    "        # Select parents\n",
    "        selected = [selection(pop, scores) for _ in range(n_pop)]\n",
    "        # Create the next generation\n",
    "        children = []\n",
    "        for i in range(0, n_pop, 2):\n",
    "            p1, p2 = selected[i], selected[i+1]\n",
    "            # Crossover and mutation\n",
    "            for c in crossover(p1, p2, r_cross):\n",
    "                # Mutation\n",
    "                mutation(c, r_mut)\n",
    "                # Store for next generation\n",
    "                children.append(c)\n",
    "                    \n",
    "        # Replace population\n",
    "        pop = children\n",
    "            \n",
    "    return [best, best_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have developed an implementation of the genetic algorithm, let’s explore how we might apply it to an objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3'></a>\n",
    "## <font color='darkblue'>Genetic Algorithm for OneMax</font>\n",
    "**In this section, we will apply the genetic algorithm to a binary string-based optimization problem.**\n",
    "\n",
    "The problem is called OneMax and evaluates a binary string based on the number of 1s in the string. For example, a bitstring with a length of 20 bits will have a score of 20 for a string of all 1s.\n",
    "\n",
    "Given we have implemented the genetic algorithm to minimize the objective function, we can add a negative sign to this evaluation so that large positive values become large negative values.\n",
    "\n",
    "The <font color='blue'>onemax()</font> function below implements this and takes a bitstring of integer values as input and returns the negative sum of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "def onemax(x):\n",
    "    return -sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can configure the search.\n",
    "\n",
    "The search will run for `100` iterations and we will use `20` bits in our candidate solutions, meaning the optimal fitness will be `-20.0`. The population size will be 100, and we will use a crossover rate of 90 percent and a mutation rate of 5 percent. This configuration was chosen after a little trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the total iterations\n",
    "n_iter = 100\n",
    "# bits\n",
    "n_bits = 20\n",
    "# define the population size\n",
    "n_pop = 100\n",
    "# crossover rate\n",
    "r_cross = 0.9\n",
    "# mutation rate\n",
    "r_mut = 1.0 / float(n_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search can then be called and the best result reported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0, new best f([1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1]) = -14.000\n",
      "> 0, new best f([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]) = -16.000\n",
      "> 2, new best f([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0]) = -17.000\n",
      "> 3, new best f([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]) = -18.000\n",
      "> 4, new best f([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]) = -19.000\n",
      "> 9, new best f([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) = -20.000\n",
      "Done!\n",
      "f([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) = -20.000\n"
     ]
    }
   ],
   "source": [
    "# Perform the GE search\n",
    "best, score = genetic_algorithm(onemax, n_bits, n_iter, n_pop)\n",
    "print(\"Done!\")\n",
    "print(f\"f({best}) = {score:.03f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example will report the best result as it is found along the way, **then the final best solution at the end of the search, which we would expect to be the optimal solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect4'></a>\n",
    "## <font color='darkblue'>Genetic Algorithm for Continuous Function Optimization</font>\n",
    "**Optimizing the OneMax function is not very interesting; we are more likely to want to optimize a continuous function.**\n",
    "\n",
    "For example, we can define the $x^2$ minimization function that takes input variables and has an optima at $f(0, 0) = 0.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "def objective(x):\n",
    "    return x[0]**2.0 + x[1]**2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can minimize this function with a genetic algorithm.\n",
    "\n",
    "First, we must define the bounds of each input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range for input\n",
    "bounds = [[-5.0, 5.0], [-5.0, 5.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the `n_bits` hyperparameter as a number of bits per input variable to the objective function and set it to 16 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bit per variable\n",
    "n_bits = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means our actual bit string will have `(16*2) = 32` bits, given the two input variables. We must update our mutation rate accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation rate\n",
    "r_mut = 1.0 / (float(n_bits) * len(bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to ensure that the initial population creates random random bitstrings that are large enough:\n",
    "```python\n",
    "pop = [randint(0, 2, n_bits*len(bounds)).tolist() for _ in range(n_pop)]\n",
    "```\n",
    "\n",
    "Finally, we need to decide the bitstrings to numbers prior to evaluating each with the object function.\n",
    "\n",
    "We can achieve this by first decoding each substring to an integer, then scaling the integer to the desired range. This will give a vector of values in the range that can then be provided to the objective function for evaluation.\n",
    "\n",
    "The <font color='blue'>decode()</font> function below implements this, taking the bounds of the function, the number of bits per variable, and a bitstring as input and returns a list of decoded real values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode bitstring to numbers\n",
    "def decode(bounds, n_bits, bitstring):\n",
    "    decoded = []\n",
    "    largest = 2 ** n_bits\n",
    "    for i in range(len(bounds)):\n",
    "        start, end = i * n_bits, (i * n_bits) + n_bits\n",
    "        substring = bitstring[start:end]\n",
    "        # Covert bitstring to a string of chars\n",
    "        chars = ''.join([str(b) for b in substring])\n",
    "        # Covert string to integer\n",
    "        int_value = int(chars, 2)\n",
    "        # Scale integer to desired range\n",
    "        nrm_value = bounds[i][0] + (int_value/largest) * (bounds[i][1] - bounds[i][0])\n",
    "        # Store\n",
    "        decoded.append(nrm_value)\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then call this at the beginning of the algorithm loop to decode the population, then evaluate the decoded version of the population.\n",
    "```python\n",
    "# Eecode population\n",
    "decoded_pop = [decode(bounds, n_bits, p) for p in pop]\n",
    "# Evaluate all candidates in the population\n",
    "scores = [objective(d) for d in decoded_pop]\n",
    "```\n",
    "\n",
    "Trying this together, the complete example of the GE for continuous function optimization is listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_4_cont(objective, bounds=bounds, decode_func=decode, n_bits=n_bits, n_iter=n_iter, n_pop=n_pop, r_cross=r_cross, r_mut=r_mut):\n",
    "    # Initialize population of random bitstring\n",
    "    pop = [randint(0, 2, n_bits*len(bounds)).tolist() for _ in range(n_pop)]\n",
    "    decoded_pop = [decode_func(bounds, n_bits, p) for p in pop]\n",
    "    # Keep track of best solution\n",
    "    best, best_eval = 0, objective(decoded_pop[0])\n",
    "    # Enumerate generations\n",
    "    for gen in range(n_iter):\n",
    "        # Evaluate all candidates in the population\n",
    "        scores = [objective(c) for c in decoded_pop]\n",
    "        # Check for new best solution\n",
    "        for i in range(n_pop):\n",
    "            if scores[i] < best_eval:\n",
    "                best, best_eval = pop[i], scores[i]\n",
    "                print(f\"> {gen}, new best f({pop[i]}) = {scores[i]:.03f}\")\n",
    "                \n",
    "        # Select parents\n",
    "        selected = [selection(pop, scores) for _ in range(n_pop)]\n",
    "        # Create the next generation\n",
    "        children = []\n",
    "        for i in range(0, n_pop, 2):\n",
    "            p1, p2 = selected[i], selected[i+1]\n",
    "            # Crossover and mutation\n",
    "            for c in crossover(p1, p2, r_cross):\n",
    "                # Mutation\n",
    "                mutation(c, r_mut)\n",
    "                # Store for next generation\n",
    "                children.append(c)\n",
    "                    \n",
    "        # Replace population\n",
    "        pop = children\n",
    "        decoded_pop = [decode_func(bounds, n_bits, p) for p in pop]\n",
    "            \n",
    "    return [best, best_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0, new best f([1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0]) = 0.659\n",
      "> 0, new best f([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1]) = 0.475\n",
      "> 0, new best f([0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]) = 0.359\n",
      "> 1, new best f([0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]) = 0.307\n",
      "> 1, new best f([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]) = 0.143\n",
      "> 1, new best f([0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1]) = 0.109\n",
      "> 1, new best f([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]) = 0.031\n",
      "> 2, new best f([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]) = 0.027\n",
      "> 3, new best f([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]) = 0.027\n",
      "> 4, new best f([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1]) = 0.009\n",
      "> 5, new best f([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]) = 0.008\n",
      "> 6, new best f([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]) = 0.008\n",
      "> 6, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]) = 0.002\n",
      "> 7, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0]) = 0.001\n",
      "> 7, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]) = 0.000\n",
      "> 10, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]) = 0.000\n",
      "> 12, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]) = 0.000\n",
      "> 13, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]) = 0.000\n",
      "> 15, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]) = 0.000\n",
      "> 17, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1]) = 0.000\n",
      "> 17, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1]) = 0.000\n",
      "> 18, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0]) = 0.000\n",
      "> 19, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]) = 0.000\n",
      "> 20, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]) = 0.000\n",
      "> 24, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]) = 0.000\n",
      "> 33, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) = 0.000\n",
      "> 39, new best f([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) = 0.000\n",
      "Done!\n",
      "([-0.000152587890625, -0.000152587890625]) = 0.000\n"
     ]
    }
   ],
   "source": [
    "best, score = genetic_algorithm_4_cont(objective)\n",
    "print(\"Done!\")\n",
    "decoded = decode(bounds, n_bits, best)\n",
    "print(f\"({decoded}) = {score:.03f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports the best decoded results along the way and the best decoded solution at the end of the run. n this case, we can see that the algorithm discovers an input very close to $f(0.0, 0.0) = 0.0$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
