{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae7742d-c790-47a6-a0f7-9bb22ee9bfbb",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([source](https://realpython.com/practical-prompt-engineering/)) <font size='3ptx'><b>You‚Äôve used [ChatGPT](https://realpython.com/chatgpt-coding-mentor-python/), and you understand the potential of using a large language model (LLM) to assist you in your tasks.</b> Maybe you‚Äôre already working on an LLM-supported application and have read about <b><font color='darkblue'>prompt engineering</font></b>, but you‚Äôre unsure how to translate the theoretical concepts into a practical example.</font>\n",
    "\n",
    "<b>Your text prompt instructs the LLM‚Äôs responses, so tweaking it can get you vastly different output. In this tutorial, you‚Äôll apply multiple prompt engineering techniques to a real-world example</b>. You‚Äôll experience prompt engineering as an iterative process, see the effects of applying various techniques, and learn about related concepts from machine learning and data engineering.\n",
    "\n",
    "In this tutorial, you‚Äôll learn how to:\n",
    "* Work with OpenAI‚Äôs **GPT-3.5**, **GPT-4** and **Gemini** models through their API\n",
    "* Apply prompt engineering techniques to a **practical, real-world example**.\n",
    "* Use **numbered steps, delimiters**, and **few-shot prompting** to improve your results\n",
    "* Understand and use **chain-of-thought prompting** to add more context\n",
    "* Tap into the power of **roles** in messages to go beyond using singular **role prompts**.\n",
    "\n",
    "You‚Äôll work with a Python script that you can repurpose to fit your own LLM-assisted task. So if you‚Äôd like to use practical examples to discover how you can use prompt engineering to get better results from an LLM, then you‚Äôve found the right tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaaeaa9-00ba-40fa-bcdc-3fc35881dc5a",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Understand the Purpose of Prompt Engineering</font></b>\n",
    "<b><font size='3ptx'>Prompt engineering is more than a buzzword. You can get vastly different output from an LLM when using different prompts.</font></b>\n",
    "\n",
    "That may seem obvious when you consider that you get different output when you ask different questions‚Äîbut it also applies to phrasing the same conceptual question differently. <b><font color='darkblue'>Prompt engineering</font> means constructing your text input to the LLM using specific approaches</b>.\n",
    "\n",
    "You can think of prompts as arguments and the LLM as the function to which you pass these arguments. Different input means different output:\n",
    "```python\n",
    ">>> def hello(name):\n",
    "...     print(f\"Hello, {name}!\")\n",
    "...\n",
    ">>> hello(\"World\")\n",
    "Hello, World!\n",
    ">>> hello(\"Engineer\")\n",
    "Hello, Engineer!\n",
    "```\n",
    "\n",
    "While an LLM is much more complex than the toy function above, the fundamental idea holds true. For a successful function call, you‚Äôll need to know exactly which argument will produce the desired output. In the case of an LLM, that argument is text that consists of many different tokens, or pieces of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486cfe11-b050-413c-8dfb-3ee93c8ac687",
   "metadata": {},
   "source": [
    "<b>The field of prompt engineering is still changing rapidly, and there‚Äôs a lot of active research happening in this area.</b> As LLMs continue to evolve, so will the prompting approaches that will help you achieve the best results.\n",
    "\n",
    "<b>In this tutorial, you‚Äôll cover some prompt engineering techniques, along with approaches to iteratively developing prompts</b>, that you can use to get better text completions for your own LLM-assisted projects:\n",
    "* Zero-Shot Prompting\n",
    "* Few-Shot Prompting\n",
    "* Delimiters\n",
    "* Numbered Steps\n",
    "* Role Prompts\n",
    "* Chain-of-Thought (CoT) Prompting\n",
    "* Structured Output\n",
    "* Labeled Conversations\n",
    "\n",
    "<b>There are more techniques to uncover, and you‚Äôll also find links to additional resources in the tutorial</b>. Applying the mentioned techniques in a practical example will give you a great starting point for improving your LLM-supported programs. If you‚Äôve never worked with an LLM before, then you may want to peruse [**OpenAI‚Äôs GPT documentation**](https://platform.openai.com/docs/guides/gpt) before diving in, but you should be able to follow along either way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476024e-09fc-4bae-ac32-79a956a51b18",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Get to Know the Practical Prompt Engineering Project</font></b>\n",
    "<font size='3ptx'><b>You‚Äôll explore various prompt engineering techniques in service of a practical example: sanitizing customer chat conversations</b>. By practicing different prompt engineering techniques on a single real-world project, you‚Äôll get a good idea of why you might want to use one technique over another and how you can apply them in practice.</font>\n",
    "\n",
    "Imagine that you‚Äôre the resident Python developer at a company that handles thousands of customer support chats on a daily basis. <b>Your job is to format and sanitize these conversations. You also help with deciding which of them require additional attention</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21fea1c-528e-4315-ab23-0f028f9e25f8",
   "metadata": {},
   "source": [
    "#### <b><font size='3ptx'>Collect Your Tasks</font></b>\n",
    "Your big-picture assignment is to help your company stay on top of handling customer chat conversations. The conversations that you work with may look like the one shown below:\n",
    "```text\n",
    "[support_tom] 2023-07-24T10:02:23+00:00 : What can I help you with?\n",
    "[johndoe] 2023-07-24T10:03:15+00:00 : I CAN'T CONNECT TO MY BLASTED ACCOUNT\n",
    "[support_tom] 2023-07-24T10:03:30+00:00 : Are you sure it's not your caps lock?\n",
    "[johndoe] 2023-07-24T10:04:03+00:00 : Blast! You're right!\n",
    "```\n",
    "\n",
    "You‚Äôre supposed to make these text conversations more accessible for further processing by the customer support department in a few different ways:\n",
    "* Remove personally identifiable information.\n",
    "* Remove swear words.\n",
    "* Clean the date-time information to only show the date.\n",
    "\n",
    "The swear words that you‚Äôll encounter in this tutorial won‚Äôt be spicy at all, but you can consider them stand-ins for more explicit phrasing that you might find out in the wild. After sanitizing the chat conversation, you‚Äôd expect it to look like this:\n",
    "```text\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : üò§! You're right!\n",
    "```\n",
    "\n",
    "Sure‚Äîyou could handle it [using Python‚Äôs `str.replace()`](https://realpython.com/replace-string-python/) or show off your [regular expression skills](https://realpython.com/regex-python/). But there‚Äôs more to the task than immediately meets the eye.\n",
    "\n",
    "<b>Your project manager isn‚Äôt a technical person, and they stuck another task at the end of this list.</b> They may think of the task as a normal continuation of the previous tasks. But you know that it requires an entirely different approach and technology stack:\n",
    "> Mark the conversations as ‚Äúpositive‚Äù or ‚Äúnegative.‚Äù\n",
    "\n",
    "That task lies in the realm of [**machine learning**](https://realpython.com/learning-paths/machine-learning-python/), namely [**text classification**](https://realpython.com/python-keras-text-classification/), and more specifically [**sentiment analysis**](https://realpython.com/python-nltk-sentiment-analysis/). Even [**advanced regex skills**](https://realpython.com/regex-python-part-2/) won‚Äôt get you far in this challenge.\n",
    "\n",
    "Additionally, you know that the customer support team that you‚Äôre preparing the data for will want to continue working on it programmatically. Plain text isn‚Äôt necessarily the best format for doing that. **You want to do work that‚Äôs useful for others, so you add yet another stretch goal to your growing list of tasks**:\n",
    "> Format the output as JSON.\n",
    "\n",
    "This task list is quickly growing out of proportion! Fortunately, **you‚Äôve got access to the [**OpenAI API**](https://platform.openai.com/docs/api-reference/), and you‚Äôll employ the help of their LLM to solve all of these challenges**.\n",
    "\n",
    "One of the impressive features of LLMs is the breadth of tasks that you can use them for. So **you‚Äôll cover a lot of ground and different areas of use. And you‚Äôll learn how to tackle them all with prompt engineering techniques.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad3e5b-aa68-4b5a-b853-f685a9659b80",
   "metadata": {},
   "source": [
    "#### <b><font size='3ptx'>Prepare Your Tools</font></b>\n",
    "<b><font size='3ptx'>To follow along with this tutorial, you‚Äôll need to know [how to run a Python script](https://realpython.com/run-python-scripts/) from your command-line interface (CLI), and you‚Äôll [need an API key from OpenAI](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key).</font></b>\n",
    "\n",
    "To get started, go ahead and download the example Python script that you‚Äôll work with throughout the tutorial:\n",
    "> Get Sample Code: Click here to download the sample code that you‚Äôll use to get the most out of large language models through prompt engineering.\n",
    "\n",
    "The codebase represents a light abstraction layer on top of the OpenAI API and exposes one function called get_chat_completion() that‚Äôll be of primary interest for the tutorial. The function interacts with OpenAI‚Äôs /chat/completions endpoint to generate responses using different models, such as GPT-3.5-Turbo and GPT-4. You‚Äôll explore both models, starting with GPT-3.5-Turbo, and eventually you‚Äôll move on to the more powerful GPT-4 model.\n",
    "\n",
    "Most of the code in `app.py` revolves around setting up and fetching the settings from `settings.toml`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b3914-d44e-4d0a-b4e1-412984539389",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Start Engineering Your Prompts</font></b>\n",
    "<b><font size='3ptx'>Now that you have an understanding of prompt engineering and the practical project that you‚Äôll be working with, it‚Äôs time to dive into some prompt engineering techniques.</font></b>\n",
    "\n",
    "In this section, you‚Äôll learn how to apply the following techniques to your prompts to get the desired output from the language model:\n",
    "* **Zero-shot prompting**: Giving the language model normal instructions without any additional context\n",
    "* **Few-shot prompting**: Conditioning the model on a few examples to boost its performance\n",
    "* **Using delimiters**: Adding special tokens or phrases to provide structure and instructions to the model\n",
    "* **Detailed, numbered steps**: Breaking down a complex prompt into a series of small, specific steps.\n",
    "\n",
    "By practicing these techniques with the customer chat conversation example, you‚Äôll gain a deeper understanding of how prompt engineering can enhance the capabilities of language models and improve their usefulness in real-world applications.\n",
    "\n",
    "* <b><font size='3ptx'><a href='#Describe-Your-Task'>Describe Your Task</font></b>\n",
    "* <b><font size='3ptx'><a href='#Switch-to-a-Different-Model'>Switch to a Different Model</font></b>\n",
    "* <b><font size='3ptx'><a href='#Add-a-Role-Prompt-to-Set-the-Tone'>Add a Role Prompt to Set the Tone</font></b>\n",
    "* <b><font size='3ptx'><a href='#Classify-the-Sentiment-of-Chat-Conversations'>Classify the Sentiment of Chat Conversations</font></b>\n",
    "* <b><font size='3ptx'><a href='#Walk-the-Model-Through-Chain-of-Thought-Prompting'>Walk the Model Through Chain-of-Thought Prompting</font></b>\n",
    "* <b><font size='3ptx'><a href='#Structure-Your-Output-Format-as-JSON'>Structure Your Output Format as JSON</font></b>\n",
    "* <b><font size='3ptx'><a href='#Improve-Your-Output-With-the-Power-of-Conversation-(back)'>Improve Your Output With the Power of Conversation</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf15e3-dbed-4fda-808a-151fe39761d7",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "### <b><font color='darkgreen'>Describe Your Task</font></b>\n",
    "You‚Äôll start your prompt engineering journey with a concept called <b><font color='darkblue'>zero-shot prompting</font></b>, which is just a fancy way of saying that you‚Äôre asking a question or describing a task:\n",
    "> Remove personally identifiable information, only show the date, and replace all swear words with ‚Äúüò§‚Äù\n",
    "\n",
    "This task description focuses on the requested steps for sanitizing the customer chat conversation and literally spells them out. This is the prompt that‚Äôs currently saved as `instruction_prompt` in the <font color='olive'>settings.toml</font> file:\n",
    "- <font color='olive'>settings.toml</font>\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Remove personally identifiable information, only show the date,\n",
    "and replace all swear words with \"üò§\"\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1d5234ed-8270-429e-abe1-1ba3a61bb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import tomli\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "_ = load_dotenv(find_dotenv(os.path.expanduser('~/.env')))\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "config = tomli.load(open('settings.toml', 'rb'))\n",
    "CHAT_MESSAGE = open('chats.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15fe1cbb-4201-43bb-9e39-c28a17d73e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file: str = 'settings.toml'):\n",
    "    return tomli.load(open(config_file, 'rb'))\n",
    "\n",
    "def load_chat_messages(chat_file: str = 'chats.txt'):\n",
    "    return open(chat_file).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61463022-1e08-49d1-8e24-ef82171f51a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[support_tom] 2023-07-24T10:02:23+00:00 : What can I help you with?\n",
      "[johndoe] 2023-07-24T10:03:15+00:00 : I CAN'T CONNECT TO MY BLASTED ACCOUNT\n",
      "[support_tom] 2023-07-24T10:03:30+00:00 : Are you sure it's not your caps lock?\n",
      "[johndoe] 2023-07-24T10:04:03+00:00 : Blast! You're right!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CHAT_MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef777a6-e651-4ced-88d3-282e11c94114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction_prompt': 'Remove personally identifiable information, only show the date,\\nand replace all swear words with \"üò§\"\\n'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55fbf6a-fc84-407e-a17a-7c4cc00a7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please work on below chat messages:\n",
    "```\n",
    "{chat_messages}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a159c0a-e9e0-4371-9e2c-39e4366b75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': CHAT_MESSAGE,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54b0d7c6-3acd-4587-a7f6-5f276f0140b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "2023-07-24: What can I help you with?\n",
      "2023-07-24: I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
      "2023-07-24: Are you sure it's not your caps lock?\n",
      "2023-07-24: üò§! You're right!\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafaeda-e123-4fc9-ab6e-93778a40cf20",
   "metadata": {},
   "source": [
    "<b>The user (`[johndoe]`) and suppport team `[support_tom]` are removed which is not expected!</b>\n",
    "\n",
    "<b>One way to do that is by increasing the number of shots, or examples, that you give to the model</b>. When you‚Äôve given the model zero shots, the only way to go is up! That‚Äôs why <b>you‚Äôll improve your results through few-shot prompting in the next section</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a82fc-3e85-422f-b456-032a4ffa1233",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Use Few-Shot Prompting to Improve Output</font></b>\n",
    "<font size='3ptx'><b>Few-shot prompting is a prompt engineering technique where you provide example tasks and their expected solutions in your prompt</b>. So, instead of just describing the task like you did before, you‚Äôll now add an example of a chat conversation and its sanitized version.</font>\n",
    "\n",
    "Open up <font color='olive'>settings_v2.toml</font> which changed the `instruction_prompt` by adding such an example:\n",
    "- <font color='olive'>settings_v2.toml</font>\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Remove personally identifiable information, only show the date,\n",
    "and replace all swear words with \"üò§\"\n",
    "\n",
    "Example Input:\n",
    "[support_tom] 2023-07-24T10:02:23+00:00 : What can I help you with?\n",
    "[johndoe] 2023-07-24T10:03:15+00:00 : I CAN'T CONNECT TO MY BLASTED ACCOUNT\n",
    "[support_tom] 2023-07-24T10:03:30+00:00 : Are you sure it's not your caps lock?\n",
    "[johndoe] 2023-07-24T10:04:03+00:00 : Blast! You're right!\n",
    "\n",
    "Example Output:\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : üò§! You're right!\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4dc282c-b5f0-4104-a078-843378289670",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v2.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6ab0ede-0a48-475b-a4f5-f0a4a44ac905",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': CHAT_MESSAGE,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5202b5-c195-4361-8ff4-188cb986bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : üò§! You're right!\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76283e-5e0b-43eb-999a-b7dc98265676",
   "metadata": {},
   "source": [
    "Okay, great! This time at least the LLM didn‚Äôt eat up all the personal information that you passed to it without giving anything useful back!\n",
    "\n",
    "Let's try one more example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ba39989-4da1-4582-b740-fd358f9f4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat1_messages = load_chat_messages('chat_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a63b841-aff4-4d41-b4a9-1f183aab881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': chat1_messages,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3054c54a-bec4-4e9f-8187-1611618b036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[support_anna] 2023-08-12T08:45:00+00:00 : Hello! How can I assist you today?\n",
      "[melvin_r] 2023-08-12T08:45:27+00:00 : I can't download the monthly report!\n",
      "[support_anna] 2023-08-12T08:46:10+00:00 : Can you try clearing your browser cache and refreshing the page?\n",
      "[melvin_r] 2023-08-12T08:47:21+00:00 : That did the trick. Thanks!\n",
      "[support_anna] 2023-08-12T08:47:23+00:00 : It is my pleasure to help, Melvin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat1_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abc29e2c-f9aa-40e0-a863-b5d03476b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "[Agent] 2023-08-12 : Hello! How can I assist you today?\n",
      "[Customer] 2023-08-12 : I can't download the monthly report!\n",
      "[Agent] 2023-08-12 : Can you try clearing your browser cache and refreshing the page?\n",
      "[Customer] 2023-08-12 : That did the trick. Thanks!\n",
      "[Agent] 2023-08-12 : It is my pleasure to help.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f5a4c-1ca6-4a7a-b869-07e33b0d06b8",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "### <b><font color='darkgreen'>Switch to a Different Model</font></b>\n",
    "<b><font size='3ptx'>Generally, latest larger models will give you better results, especially for prompts that you didn‚Äôt heavily engineer.</font></b>\n",
    "\n",
    "<b>Additionally, it‚Äôs also helpful to keep in mind that API calls to larger, latest models will generally cost more money per request</b>. While it can be fun to always use the latest and greatest LLM, it may be worthwhile to consider whether you really need to upgrade to tackle the task that you‚Äôre trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb9fb669-885d-4eec-bd48-ab9e674d6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro-exp-03-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0bb0710-0843-417e-8af1-8b360303f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat2_messages = load_chat_messages('chat_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93b625df-d86b-4238-9765-def7a67002ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[support_joe] 2023-09-01T14:12:11+00:00 : Welcome to support. What seems to be the issue?\n",
      "[karen_b] 2023-09-01T14:13:02+00:00 : My promo code isn't working at checkout.\n",
      "[support_joe] 2023-09-01T14:14:35+00:00 : That code expired last week.\n",
      "[karen_b] 2023-09-01T14:15:00+00:00 : What the hell?! You guys just sent me that damn promo this morning! This is a total scam. I'm beyond pissed off right now.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat2_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38fed665-360c-4ff3-849b-be79ed1d7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': chat2_messages,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33b3525e-5315-4c77-bd38-70c6b720744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn‚Äôt arrived and it‚Äôs been 3 üò§ weeks.\n",
      "[Agent] 2023-10-05 : I‚Äôm really sorry about that. Let me check‚Ä¶ Okay, it looks like it was lost in transit. I‚Äôll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d45fad-5e91-4c4a-a63b-227c60b63695",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Add a Role Prompt to Set the Tone</font></b>\n",
    "<font size='3ptx'>There are some additional possibilities when interacting with the API endpoint that you‚Äôve only used implicitly, but haven‚Äôt explored yet, such as <b>adding role labels to a part of the prompt</b>.</font>\n",
    "\n",
    "In this section, you‚Äôll use the \"system\" role to create a system message, and you‚Äôll revisit the concept later on when you [**add more roles**](https://realpython.com/practical-prompt-engineering/#improve-your-output-with-the-power-of-conversation) to improve the output.\n",
    "\n",
    "<b>Role prompting usually refers to adding system messages, which represent information that helps to set the context for upcoming completions that the model will produce.</b> System messages usually aren‚Äôt visible to the end user. Keep in mind that the `/chat/completions` endpoint models were initially designed for conversational interactions.\n",
    "\n",
    "You can also use system messages to set a context for your completion task. You‚Äôll craft a bespoke role prompt in a moment. However, for this specific task, the role prompt is likely less important than it might be for some other tasks. To explore the possible influence of a role prompt, you‚Äôll take a little detour and ask your model to play a role:\n",
    "- **<font color='olive'>settings_v3.toml</font>**\n",
    "```toml\n",
    "role_prompt = \"\"\"You are a 16th century villain poet who treats\n",
    "customers with nothing but contempt.\n",
    "Rephrase every line spoken by an Agent with your unique voice.\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "Unleash, thou shall, the parchment‚Äôs code and behold the marvels unexpected, as the results may stir wonderment and awe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98b85e97-7282-4a46-8034-974a7513e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "config = tomli.load(open('settings_v3.toml', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b651fdf-0366-4f9b-9476-0ac483b18de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat3_messages = load_chat_messages('chat_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "665e0dfc-4667-4422-8c63-7b646b5f1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please work on below chat messages:\n",
    "```\n",
    "{chat_messages}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", config['role_prompt']),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "962fc89c-5f8c-4bb2-8353-d1a27b4b3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[support_lee] 2023-10-05T16:01:09+00:00 : Hi there! Need help with something?\n",
      "[mrfixit99] 2023-10-05T16:01:44+00:00 : My order hasn‚Äôt arrived and it‚Äôs been 3 f***ing weeks.\n",
      "[support_lee] 2023-10-05T16:02:30+00:00 : I‚Äôm really sorry about that. Let me check‚Ä¶ Okay, it looks like it was lost in transit. I‚Äôll send a replacement with express shipping right now.\n",
      "[mrfixit99] 2023-10-05T16:03:17+00:00 : Damn, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat3_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fbb8e38-7e2c-42e3-adc5-1ca081c24cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': chat3_messages,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9793659c-460b-4e60-bc89-864e77d7f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] 2023-10-05 : Hmph, what paltry trifle vexes thee today, good sir?\n",
      "[Customer] 2023-10-05 : My order hasn‚Äôt arrived and it‚Äôs been 3 üò§ weeks.\n",
      "[Agent] 2023-10-05 : My profoundest apologies, you blithering buffoon. Let mine eyes assess this... Ah, lost to the ether, it seems. Fear not, for I shall dispatch a replacement with the swiftness of a poisoned dart.\n",
      "[Customer] 2023-10-05 : üò§, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257b692-75b6-4352-bc9f-a2d9049aba10",
   "metadata": {},
   "source": [
    "To practice writing a role prompt‚Äîand to see whether you can release your customer chat conversations from the reign of that 16th century villain poet‚Äîyou‚Äôll craft a more appropriate role prompt:\n",
    "- **<font color='olive'>settings_v4.toml</font>**\n",
    "```toml\n",
    "role_prompt = \"\"\"You are a helpful assistant with a vast knowledge\n",
    "of customer chat conversations.\n",
    "You diligently complete tasks as instructed.\n",
    "You never make up any information that isn't there.\"\"\"\n",
    "```\n",
    "\n",
    "This role prompt is more appropriate to your use case. You don‚Äôt want the model to introduce randomness or to change any of the language that‚Äôs used in the conversations. Instead, you just want it to execute the tasks that you describe. Run the script another time and take a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "837408ef-e6ab-4c1e-ad00-724efac6838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v4.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94e4ba0d-05a0-4bb8-b22c-9879fcdee887",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please work on below chat messages:\n",
    "```\n",
    "{chat_messages}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", config['role_prompt']),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2917cb1-91bf-4e10-a6e6-8104f682a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': chat3_messages,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "114c75fa-2fe8-4677-9afc-c20e0208b78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn‚Äôt arrived and it‚Äôs been 3 üò§ weeks.\n",
      "[Agent] 2023-10-05 : I‚Äôm really sorry about that. Let me check‚Ä¶ Okay, it looks like it was lost in transit. I‚Äôll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0999a-16fa-476e-9a33-2962770bae8d",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Classify the Sentiment of Chat Conversations</font></b>\n",
    "<font size='3ptx'><b>At this point, you‚Äôve engineered a decent prompt that seems to perform quite well in sanitizing and reformatting the provided customer chat conversations</b>. To fully grasp the power of LLM-assisted workflows, <b>you‚Äôll next tackle the tacked-on request by your manager to also classify the conversations as positive or negative.</b></font>\n",
    "\n",
    "Again, you want the model to do the work for you. All you need to do is craft a prompt that spells out the task at hand, and provide examples. You can also edit the role prompt to set the context for this new task that the model should perform:\n",
    "- **<font color='olive'>settings_v5.toml</font>**\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "with \"üî•\" for negative and \"‚úÖ\" for positive:\n",
    "\n",
    "#### START EXAMPLES\n",
    "\n",
    "------ Example Inputs ------\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : üò§! You're right!\n",
    "\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "\n",
    "------ Example Outputs ------\n",
    "üî•\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : üò§! You're right!\n",
    "\n",
    "‚úÖ\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "\n",
    "#### END EXAMPLES\n",
    "\"\"\"\n",
    "role_prompt = \"\"\"You are a thoroughly trained machine learning\n",
    "model that is an expert at sentiment classification.\n",
    "You diligently complete tasks as instructed.\n",
    "You never make up any information that isn't there.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189ba78-8c35-4cd2-8e73-4b7f31b97a00",
   "metadata": {},
   "source": [
    "You can now run the script and provide it with the sanitized conversations in <font color='olive'>sanitized-testing-chats.txt</font> that were the output of your previously engineered prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7ce41d0e-8f03-4400-abb9-b68b024beb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v5.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b006c803-0644-4ab2-8053-50a3ce69fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please work on below sanitized conversations:\n",
    "```\n",
    "{sanitized_conversations}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", config['role_prompt']),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8891fe4f-3ad2-45e7-a594-f9b2a91f9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_conversations = load_chat_messages('sanitized-testing-chats.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a4f3def-818b-4184-92ef-8f67e6fb8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d01d7e5-d6b9-4c7d-9ffa-d65ddc289e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ\n",
      "[Agent] 2023-08-12 : Hello! How can I assist you today?\n",
      "[Customer] 2023-08-12 : I can't download the monthly report!\n",
      "[Agent] 2023-08-12 : Can you try clearing your browser cache and refreshing the page?\n",
      "[Customer] 2023-08-12 : That did the trick. Thanks!\n",
      "[Agent] 2023-08-12 : It is my pleasure to help.\n",
      "\n",
      "üî•\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : üò§! You're right!\n",
      "\n",
      "üî•\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn‚Äôt arrived and it‚Äôs been 3 üò§ weeks.\n",
      "[Agent] 2023-10-05 : I‚Äôm really sorry about that. Let me check‚Ä¶ Okay, it looks like it was lost in transit. I‚Äôll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978efc8-0004-4504-b7f0-3c6b3ce0f71f",
   "metadata": {},
   "source": [
    "You could [add more examples](https://realpython.com/practical-prompt-engineering/#use-few-shot-prompting-to-improve-output), which is generally a good idea because it creates more context for the model to apply. Writing a [more detailed description](https://realpython.com/practical-prompt-engineering/#describe-your-request-in-numbered-steps) of your task helps as well, as you‚Äôve seen before. However, to tackle this task, you‚Äôll learn about another useful prompt engineering technique called chain-of-thought prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab736eb-dce4-4f07-938a-91bcffe9a0b4",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Walk the Model Through Chain-of-Thought Prompting</font></b>\n",
    "<font size='3ptx'><b>A widely successful prompt engineering approach can be summed up with the [anthropomorphism](https://en.wikipedia.org/wiki/Anthropomorphism) of giving the model time to think</b>. You can do this with a couple of different specific techniques. Essentially, it means that you prompt the LLM to produce intermediate results that become additional inputs. That way, the reasoning doesn‚Äôt need to take distant leaps but only hop from one lily pad to the next.</font>\n",
    "\n",
    "<b>One of these approaches is to use <font color='darkblue'>chain-of-thought (CoT) prompting techniques</font></b>. To apply CoT, you prompt the model to generate intermediate results that then become part of the prompt in a second request. The increased context makes it more likely that the model will arrive at a useful output.\n",
    "\n",
    "<b>The smallest form of CoT prompting is zero-shot CoT, where you literally ask the model to think step by step</b>. This approach yields [impressive results](https://arxiv.org/abs/2201.11903) for mathematical tasks that LLMs otherwise often solve incorrectly.\n",
    "\n",
    "Chain-of-thought operations are technically split into two stages:\n",
    "* **Reasoning extraction**, where the model generates the increased context\n",
    "* **Answer extraction**, where the model uses the increased context to generate the answer\n",
    "\n",
    "Reasoning extraction is useful across a variety of CoT contexts. You can generate few-shot examples from input, which you can then use for a separate step of extracting answers using more detailed chain-of-thought prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659f5b5-e672-49be-9d10-b49ef85c51d5",
   "metadata": {},
   "source": [
    "You can try zero-shot CoT on the sanitized chat conversations to embellish the few-shot examples that you‚Äôll use to classify the chat conversations more robustly. Remove the examples and replace the instructions describing the reasoning on how you would classify the conversations in more detail:\n",
    "- **<font color='olive'>settings_v6.toml</font>**\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "with \"üî•\" for negative and \"‚úÖ\" for positive.\n",
    "\n",
    "Follow these steps when classifying the conversations:\n",
    "1. Does the customer use swear words or üò§?\n",
    "2. Does the customer seem aggravated or angry?\n",
    "\n",
    "If you answer \"Yes\" to one of the above questions,\n",
    "then classify the conversation as negative with \"üî•\".\n",
    "Otherwise classify the conversation as positive with \"‚úÖ\".\n",
    "\n",
    "Let's think step by step\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e16e271c-63f8-4abf-9ec3-2aae674e88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v6.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f50fbe07-7f84-43b6-b4d9-abed589177b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91730ed0-11c1-4093-b347-a2460a4b252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the sentiment analysis of the provided conversations:\n",
      "\n",
      "**Conversation 1:**\n",
      "\n",
      "*   The customer does not use swear words or üò§.\n",
      "*   The customer does not seem aggravated or angry.\n",
      "*   **Classification:** ‚úÖ\n",
      "\n",
      "**Conversation 2:**\n",
      "\n",
      "*   The customer uses üò§.\n",
      "*   The customer seems aggravated.\n",
      "*   **Classification:** üî•\n",
      "\n",
      "**Conversation 3:**\n",
      "\n",
      "*   The customer uses üò§ and \"Damn\".\n",
      "*   The customer initially seems aggravated but expresses gratitude after the agent's solution.\n",
      "*   **Classification:** üî•\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0ac00-e186-4c3b-91e2-87f9a85330aa",
   "metadata": {},
   "source": [
    "The reasoning is straightforward and sticks to your instructions. If the instructions accurately represent the criteria for marking a conversation as positive or negative, then you‚Äôve got a good playbook at hand.\n",
    "\n",
    "You can now use this information to improve the few-shot examples for your sentiment classification task:\n",
    "- **<font color='olive'>settings_v7.toml</font>**\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "with \"üî•\" for negative and \"‚úÖ\" for positive.\n",
    "\n",
    "Follow these steps when classifying the conversations:\n",
    "1. Does the customer use swear words or üò§?\n",
    "2. Does the customer seem aggravated or angry?\n",
    "\n",
    "If you answer \"Yes\" to one of the above questions,\n",
    "then classify the conversation as negative with \"üî•\".\n",
    "Otherwise classify the conversation as positive with \"‚úÖ\".\n",
    "\n",
    "Let's think step by step\n",
    "\n",
    "#### START EXAMPLES\n",
    "\n",
    "------ Example Inputs ------\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : üò§! You're right!\n",
    "   - Does the customer use swear words or üò§? Yes\n",
    "   - Does the customer seem aggravated or angry? Yes\n",
    "   - Sentiment: üî•\n",
    "\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "   - Does the customer use swear words or üò§? No\n",
    "   - Does the customer seem aggravated or angry? No\n",
    "   - Sentiment: ‚úÖ\n",
    "\n",
    "------ Example Outputs ------\n",
    "üî• - Customer uses swear words and seems aggravated or angry.\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : üò§! You're right!\n",
    "\n",
    "‚úÖ - Customer does not use swear words and feel neither angry nor aggravated.\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "\n",
    "#### END EXAMPLES\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd7c881e-81cc-4c75-877f-ab623e12176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v7.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69ad046b-10d2-490e-a353-913e7f9458a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "352e94af-c47c-4b37-890d-92ec9e109721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ - Customer does not use swear words and feel neither angry nor aggravated.\n",
      "[Agent] 2023-08-12 : Hello! How can I assist you today?\n",
      "[Customer] 2023-08-12 : I can't download the monthly report!\n",
      "[Agent] 2023-08-12 : Can you try clearing your browser cache and refreshing the page?\n",
      "[Customer] 2023-08-12 : That did the trick. Thanks!\n",
      "[Agent] 2023-08-12 : It is my pleasure to help.\n",
      "\n",
      "üî• - Customer uses swear words and seems aggravated or angry.\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : üò§! You're right!\n",
      "\n",
      "üî• - Customer uses swear words and seems aggravated or angry.\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn‚Äôt arrived and it‚Äôs been 3 üò§ weeks.\n",
      "[Agent] 2023-10-05 : I‚Äôm really sorry about that. Let me check‚Ä¶ Okay, it looks like it was lost in transit. I‚Äôll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc30835-74e2-4ddb-8892-029a982841e0",
   "metadata": {},
   "source": [
    "In this section, you‚Äôve supported your examples with reasoning for why a conversation should be labeled as positive vs negative. You generated this reasoning with another call to the LLM.\n",
    "\n",
    "At this point, it seems that your prompt generalizes well to the available data and classifies the conversations as intended. And you only needed to carefully craft your words to make it happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af1a0c-6b4a-4606-a1ab-99509321ea17",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Structure Your Output Format as JSON</font></b>\n",
    "<font size='3ptx'>As a final showcase for effective prompting when incorporating an LLM into your workflow, you‚Äôll tackle the last task, which you added to the list youself: <b>to pass the data on in a structured format that‚Äôll make it straightforward for the customer support team to process further</b>.</font>\n",
    "\n",
    "You already specified a format to follow in the previous prompt, and the LLM returned what you asked for. So it might just be a matter of asking for a different, more structured format, for example [**JSON**](https://realpython.com/python-json/):\n",
    "\n",
    "- **<font color='olive'>settings_v8.toml</font>**\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "as \"negative\" and \"positive\".\n",
    "Return the output as valid JSON.\n",
    "\n",
    "Follow these steps when classifying the conversations:\n",
    "1. Does the customer use swear words or üò§?\n",
    "2. Does the customer seem aggravated or angry?\n",
    "\n",
    "If you answer \"Yes\" to one of the above questions,\n",
    "then classify the conversation as \"negative\".\n",
    "Otherwise classify the conversation as \"positive\".\n",
    "\n",
    "Let's think step by step\n",
    "\n",
    "#### START EXAMPLES\n",
    "\n",
    "------ Example Inputs ------\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : üò§! You're right!\n",
    "   - Does the customer use swear words or üò§? Yes\n",
    "   - Does the customer seem aggravated or angry? Yes\n",
    "   - Sentiment: \"negative\"\n",
    "\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "   - Does the customer use swear words or üò§? No\n",
    "   - Does the customer seem aggravated or angry? No\n",
    "   - Sentiment: \"positive\"\n",
    "\n",
    "------ Example Output ------\n",
    "\n",
    "{\n",
    "  \"negative\": [\n",
    "    {\n",
    "      \"date\": \"2023-07-24\",\n",
    "      \"conversation\": [\n",
    "        \"A: What can I help you with?\",\n",
    "        \"C: I CAN'T CONNECT TO MY üò§ ACCOUNT\",\n",
    "        \"A: Are you sure it's not your caps lock?\",\n",
    "        \"C: üò§! You're right!\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"positive\": [\n",
    "    {\n",
    "      \"date\": \"2023-06-15\",\n",
    "      \"conversation\": [\n",
    "        \"A: Hello! How can I assist you today?\",\n",
    "        \"C: I can't seem to find the download link for my purchased software.\",\n",
    "        \"A: No problem, ****. Let me find that for you. Can you please provide your order number?\",\n",
    "        \"C: It's ****. Thanks for helping me out!\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "#### END EXAMPLES\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c331c2f5-3138-4567-8b71-965d092fd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v8.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cddebfac-fe50-4c60-8e89-5e503896bef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
      "as \"negative\" and \"positive\". For the output format:\n",
      "1. Return the output as valid JSON format.\n",
      "2. Skip the prefix \"```json\" from the generated output.\n",
      "\n",
      "Follow these steps when classifying the conversations:\n",
      "1. Does the customer use swear words or üò§?\n",
      "2. Does the customer seem aggravated or angry?\n",
      "\n",
      "If you answer \"Yes\" to one of the above questions,\n",
      "then classify the conversation as \"negative\".\n",
      "Otherwise classify the conversation as \"positive\".\n",
      "\n",
      "Let's think step by step\n",
      "\n",
      "#### START EXAMPLES\n",
      "\n",
      "------ Example Inputs ------\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : üò§! You're right!\n",
      "   - Does the customer use swear words or üò§? Yes\n",
      "   - Does the customer seem aggravated or angry? Yes\n",
      "   - Sentiment: \"negative\"\n",
      "\n",
      "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
      "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
      "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
      "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
      "   - Does the customer use swear words or üò§? No\n",
      "   - Does the customer seem aggravated or angry? No\n",
      "   - Sentiment: \"positive\"\n",
      "\n",
      "------ Example Output ------\n",
      "\n",
      "{\n",
      "  \"negative\": [\n",
      "    {\n",
      "      \"date\": \"2023-07-24\",\n",
      "      \"conversation\": [\n",
      "        \"A: What can I help you with?\",\n",
      "        \"C: I CAN'T CONNECT TO MY üò§ ACCOUNT\",\n",
      "        \"A: Are you sure it's not your caps lock?\",\n",
      "        \"C: üò§! You're right!\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"positive\": [\n",
      "    {\n",
      "      \"date\": \"2023-06-15\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hello! How can I assist you today?\",\n",
      "        \"C: I can't seem to find the download link for my purchased software.\",\n",
      "        \"A: No problem, ****. Let me find that for you. Can you please provide your order number?\",\n",
      "        \"C: It's ****. Thanks for helping me out!\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "#### END EXAMPLES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config['instruction_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e82772f8-5a98-47fb-af17-c5b22f264e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please apply instruction above onto below sanitized conversations to generate the desired output:\n",
    "```\n",
    "{sanitized_conversations}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", config['role_prompt']),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23f72d48-0d2b-4a8b-8d38-fae195bb02c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
      "as \"negative\" and \"positive\". For the output format:\n",
      "1. Return the output as valid JSON format.\n",
      "2. Please don't include prefix ```json...``` in the output.\n",
      "\n",
      "Follow these steps when classifying the conversations:\n",
      "1. Does the customer use swear words or üò§?\n",
      "2. Does the customer seem aggravated or angry?\n",
      "\n",
      "If you answer \"Yes\" to one of the above questions,\n",
      "then classify the conversation as \"negative\".\n",
      "Otherwise classify the conversation as \"positive\".\n",
      "\n",
      "Let's think step by step\n",
      "\n",
      "#### START EXAMPLES\n",
      "\n",
      "------ Example Inputs ------\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : üò§! You're right!\n",
      "   - Does the customer use swear words or üò§? Yes\n",
      "   - Does the customer seem aggravated or angry? Yes\n",
      "   - Sentiment: \"negative\"\n",
      "\n",
      "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
      "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
      "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
      "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
      "   - Does the customer use swear words or üò§? No\n",
      "   - Does the customer seem aggravated or angry? No\n",
      "   - Sentiment: \"positive\"\n",
      "\n",
      "------ Example Output ------\n",
      "\n",
      "{\n",
      "  \"negative\": [\n",
      "    {\n",
      "      \"date\": \"2023-07-24\",\n",
      "      \"conversation\": [\n",
      "        \"A: What can I help you with?\",\n",
      "        \"C: I CAN'T CONNECT TO MY üò§ ACCOUNT\",\n",
      "        \"A: Are you sure it's not your caps lock?\",\n",
      "        \"C: üò§! You're right!\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"positive\": [\n",
      "    {\n",
      "      \"date\": \"2023-06-15\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hello! How can I assist you today?\",\n",
      "        \"C: I can't seem to find the download link for my purchased software.\",\n",
      "        \"A: No problem, ****. Let me find that for you. Can you please provide your order number?\",\n",
      "        \"C: It's ****. Thanks for helping me out!\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "#### END EXAMPLES\n",
      "\n",
      "\n",
      "Please apply instruction above onto below sanitized conversations to generate the desired output:\n",
      "```\n",
      "[Agent] 2023-08-12 : Hello! How can I assist you today?\n",
      "[Customer] 2023-08-12 : I can't download the monthly report!\n",
      "[Agent] 2023-08-12 : Can you try clearing your browser cache and refreshing the page?\n",
      "[Customer] 2023-08-12 : That did the trick. Thanks!\n",
      "[Agent] 2023-08-12 : It is my pleasure to help.\n",
      "\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : üò§! You're right!\n",
      "\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn‚Äôt arrived and it‚Äôs been 3 üò§ weeks.\n",
      "[Agent] 2023-10-05 : I‚Äôm really sorry about that. Let me check‚Ä¶ Okay, it looks like it was lost in transit. I‚Äôll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\n",
      "\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}).messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c196635b-c494-4a27-aa24-f045c364dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "db7929c2-73aa-4c62-a0dc-3d17217abbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"negative\": [\n",
      "    {\n",
      "      \"date\": \"2023-07-24\",\n",
      "      \"conversation\": [\n",
      "        \"A: What can I help you with?\",\n",
      "        \"C: I CAN'T CONNECT TO MY üò§ ACCOUNT\",\n",
      "        \"A: Are you sure it's not your caps lock?\",\n",
      "        \"C: üò§! You're right!\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"date\": \"2023-10-05\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hi there! Need help with something?\",\n",
      "        \"C: My order hasn‚Äôt arrived and it‚Äôs been 3 üò§ weeks.\",\n",
      "        \"A: I‚Äôm really sorry about that. Let me check‚Ä¶ Okay, it looks like it was lost in transit. I‚Äôll send a replacement with express shipping right now.\",\n",
      "        \"C: Damn, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"positive\": [\n",
      "    {\n",
      "      \"date\": \"2023-08-12\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hello! How can I assist you today?\",\n",
      "        \"C: I can't download the monthly report!\",\n",
      "        \"A: Can you try clearing your browser cache and refreshing the page?\",\n",
      "        \"C: That did the trick. Thanks!\",\n",
      "        \"A: It is my pleasure to help.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076248d-4bc0-4a50-a697-ad41bc4add98",
   "metadata": {},
   "source": [
    "In this case, you receive valid JSON, as requested. The classification still works as before and the output censors personally identifiable information, replaces swear words, and applies all the additional requested formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982d650-6173-4fdd-8fda-231ec8aa3e35",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Improve Your Output With the Power of Conversation</font></b> ([back](#Start-Engineering-Your-Prompts))\n",
    "<font size='3ptx'>You added a [**role prompt**](https://realpython.com/practical-prompt-engineering/#add-a-role-prompt-to-set-the-tone) earlier on, but otherwise you haven‚Äôt tapped into the power of conversations yet.</font>\n",
    "\n",
    "<b>In this final section, you‚Äôll learn how you can provide additional context to the model by splitting your prompt into multiple separate messages with different labels.</b>\n",
    "\n",
    "In calls to the /chat/completions endpoint, a prompt is split into several **messages**. Each message has its content, which represents the prompt text. Additionally, it also has a role. There are different [**roles**](https://platform.openai.com/docs/api-reference/chat/create#chat/create-role) that a message can have, and you‚Äôll work with three of them:\n",
    "* **\"system\"** gives context for the conversation and helps to set the overall tone.\n",
    "* **\"user\"** represents the input that a user of your application might provide.\n",
    "* **\"assistant\"** represents the output that the model would reply with.\n",
    "\n",
    "So far, you‚Äôve provided context for different parts of your prompt all mashed together in a single prompt, more or less well separated [using delimiters](https://realpython.com/practical-prompt-engineering/#use-delimiters-to-clearly-mark-sections-of-your-prompt). When you use a model that‚Äôs optimized for chat, such as GPT-4, then you can use roles to let the LLM know what type of message you‚Äôre sending.\n",
    "\n",
    "For example, you can create some variables for your few-shot examples and separate variables for the associated CoT reasoning and outputs:\n",
    "- **<font color='olive'>settings_v9.toml</font>**\n",
    "```toml\n",
    "[prompts]\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "as \"negative\" and \"positive\".\n",
    "Return the output as valid JSON.\n",
    "\"\"\"\n",
    "role_prompt = \"\"\"You are a thoroughly trained machine learning\n",
    "model that is an expert at sentiment classification.\n",
    "You diligently complete tasks as instructed.\n",
    "You never make up any information that isn't there.\"\"\"\n",
    "positive_example = \"\"\"\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "\"\"\"\n",
    "positive_reasoning = \"\"\"\n",
    "- Does the customer use swear words or üò§? No\n",
    "- Does the customer seem aggravated or angry? No\n",
    "- Sentiment: \"positive\"\n",
    "\"\"\"\n",
    "positive_output = \"\"\"\n",
    "\"positive\": [\n",
    "  {\n",
    "    \"date\": \"2023-06-15\",\n",
    "    \"conversation\": [\n",
    "      \"A: Hello! How can I assist you today?\",\n",
    "      \"C: I can't seem to find the download link for my purchased software.\",\n",
    "      \"A: No problem, ****. Let me find that for you. Can you please provide your order number?\",\n",
    "      \"C: It's ****. Thanks for helping me out!\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "negative_example = \"\"\"\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : üò§! You're right!\n",
    "\"\"\"\n",
    "negative_reasoning = \"\"\"\n",
    "- Does the customer use swear words or üò§? Yes\n",
    "- Does the customer seem aggravated or angry? Yes\n",
    "- Sentiment: \"negative\"\n",
    "\"\"\"\n",
    "negative_output = \"\"\"\n",
    "\"negative\": [\n",
    "  {\n",
    "    \"date\": \"2023-07-24\",\n",
    "    \"conversation\": [\n",
    "      \"A: What can I help you with?\",\n",
    "      \"C: I CAN'T CONNECT TO MY üò§ ACCOUNT\",\n",
    "      \"A: Are you sure it's not your caps lock?\",\n",
    "      \"C: üò§! You're right!\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e8378-67b7-4c3e-91fd-6d84f3494708",
   "metadata": {},
   "source": [
    "You‚Äôve disassembled your `instruction_prompt` into seven separate prompts, based on what role the messages have in your conversation with the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f0913-6c98-4cfa-8ffa-2cb76983e1da",
   "metadata": {},
   "source": [
    "The helper function that builds a messages payload, <font color='blue'>assemble_chat_messages()</font>, is already set up to include all of these prompts in the API request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a212fe2f-6df8-409b-ac38-459b18e7c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_chat_messages(settings: Any, content: str) -> list[dict]:\n",
    "    \"\"\"Combine all messages into a well-formatted list of dicts.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": settings['role_prompt']},\n",
    "        {\"role\": \"user\", \"content\": settings['negative_example']},\n",
    "        {\"role\": \"system\", \"content\": settings['negative_reasoning']},\n",
    "        {\"role\": \"assistant\", \"content\": settings['negative_output']},\n",
    "        {\"role\": \"user\", \"content\": settings['positive_example']},\n",
    "        {\"role\": \"system\", \"content\": settings['positive_reasoning']},\n",
    "        {\"role\": \"assistant\", \"content\": settings['positive_output']},\n",
    "        {\"role\": \"user\", \"content\": f\">>>>>\\n{content}\\n<<<<<\"},\n",
    "        {\"role\": \"user\", \"content\": settings['instruction_prompt']},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fce87-4d14-43ec-bdc8-9674a8522ca4",
   "metadata": {},
   "source": [
    "Your prompt is now split into distinct parts, each of which has a certain role label:\n",
    "* **Example** input has the \"user\" role.\n",
    "* **Reasoning** that the model created has the \"system\" role.\n",
    "* **Example** output has the \"assistant\" role.\n",
    "\n",
    "You‚Äôre now providing context for how user input might look, how the model can reason about classifying the input, and how your expected output should look. You removed the delimiters that you previously used for labeling the example sections. They aren‚Äôt necessary now that you‚Äôre providing context for the parts of your prompt through separate messages.\n",
    "\n",
    "Give your script a final run to see whether the power of conversation has managed to improve the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4695b40b-accc-4f30-9f49-4c51253962e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v9.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aea7b5cc-871e-4170-aa94-777859be015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_messages = assemble_chat_messages(config['prompts'], sanitized_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29368412-aab4-49cf-bdbb-a8d4cda294d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a thoroughly trained machine learning\\nmodel that is an expert at sentiment classification.\\nYou diligently complete tasks as instructed.\\nYou never make up any information that isn't there.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"[Agent] 2023-07-24 : What can I help you with?\\n[Customer] 2023-07-24 : I CAN'T CONNECT TO MY üò§ ACCOUNT\\n[Agent] 2023-07-24 : Are you sure it's not your caps lock?\\n[Customer] 2023-07-24 : üò§! You're right!\\n\"},\n",
       " {'role': 'system',\n",
       "  'content': '- Does the customer use swear words or üò§? Yes\\n- Does the customer seem aggravated or angry? Yes\\n- Sentiment: \"negative\"\\n'}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompted_messages[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a521379c-38d0-439d-9c1c-2b579c055327",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompted_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "787bbf06-2761-42da-a540-c61f39bd5e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"positive\": [\n",
      "    {\n",
      "      \"date\": \"2023-08-12\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hello! How can I assist you today?\",\n",
      "        \"C: I can't download the monthly report!\",\n",
      "        \"A: Can you try clearing your browser cache and refreshing the page?\",\n",
      "        \"C: That did the trick. Thanks!\",\n",
      "        \"A: It is my pleasure to help.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"negative\": [\n",
      "    {\n",
      "      \"date\": \"2023-07-24\",\n",
      "      \"conversation\": [\n",
      "        \"A: What can I help you with?\",\n",
      "        \"C: I CAN'T CONNECT TO MY üò§ ACCOUNT\",\n",
      "        \"A: Are you sure it's not your caps lock?\",\n",
      "        \"C: üò§! You're right!\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"date\": \"2023-10-05\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hi there! Need help with something?\",\n",
      "        \"C: My order hasn‚Äôt arrived and it‚Äôs been 3 üò§ weeks.\",\n",
      "        \"A: I‚Äôm really sorry about that. Let me check‚Ä¶ Okay, it looks like it was lost in transit. I‚Äôll send a replacement with express shipping right now.\",\n",
      "        \"C: Damn, I was ready to explode‚Äîbut that actually helps. Thanks for fixing it fast.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4cc094-493a-4ea5-9691-386e1fda5b04",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Next Steps</font></b>\n",
    "<font size='3ptx'><b>In this tutorial, you‚Äôve learned about various prompt engineering techniques, and you‚Äôve built an LLM-assisted Python application along the way.</b></font>\n",
    "\n",
    "The field of prompt engineering is quite new, and LLMs keep developing quickly as well. The landscape, best practices, and most effective approaches are therefore changing rapidly. To continue learning about prompt engineering using free and open-source resources, you can check out [**Learn Prompting**](https://learnprompting.org/docs/intro/) and the [**Prompt Engineering Guide**](https://www.promptingguide.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0ce77-35f6-45ac-96b4-e2384bed64d4",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [LangChain - Google AI chat models](https://python.langchain.com/v0.1/docs/integrations/chat/google_generative_ai/)\n",
    "* [LangChain - How to use few shot examples](https://python.langchain.com/docs/how_to/few_shot_examples/)\n",
    "* [RealPython - Python and TOML: New Best Friends](https://realpython.com/python-toml/)\n",
    "* [YT - How to Use Directional Stimulus Prompting in ChatGPT & Python: Step-by-Step Tutorial](https://www.youtube.com/watch?v=WEAaVKVfy3M)\n",
    "* [Prompt Engineering Guide - Directional Stimulus Prompting](https://www.promptingguide.ai/techniques/dsp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
