{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae7742d-c790-47a6-a0f7-9bb22ee9bfbb",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([source](https://realpython.com/practical-prompt-engineering/)) <font size='3ptx'><b>You’ve used [ChatGPT](https://realpython.com/chatgpt-coding-mentor-python/), and you understand the potential of using a large language model (LLM) to assist you in your tasks.</b> Maybe you’re already working on an LLM-supported application and have read about <b><font color='darkblue'>prompt engineering</font></b>, but you’re unsure how to translate the theoretical concepts into a practical example.</font>\n",
    "\n",
    "<b>Your text prompt instructs the LLM’s responses, so tweaking it can get you vastly different output. In this tutorial, you’ll apply multiple prompt engineering techniques to a real-world example</b>. You’ll experience prompt engineering as an iterative process, see the effects of applying various techniques, and learn about related concepts from machine learning and data engineering.\n",
    "\n",
    "In this tutorial, you’ll learn how to:\n",
    "* Work with OpenAI’s **GPT-3.5**, **GPT-4** and **Gemini** models through their API\n",
    "* Apply prompt engineering techniques to a **practical, real-world example**.\n",
    "* Use **numbered steps, delimiters**, and **few-shot prompting** to improve your results\n",
    "* Understand and use **chain-of-thought prompting** to add more context\n",
    "* Tap into the power of **roles** in messages to go beyond using singular **role prompts**.\n",
    "\n",
    "You’ll work with a Python script that you can repurpose to fit your own LLM-assisted task. So if you’d like to use practical examples to discover how you can use prompt engineering to get better results from an LLM, then you’ve found the right tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaaeaa9-00ba-40fa-bcdc-3fc35881dc5a",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Understand the Purpose of Prompt Engineering</font></b>\n",
    "<b><font size='3ptx'>Prompt engineering is more than a buzzword. You can get vastly different output from an LLM when using different prompts.</font></b>\n",
    "\n",
    "That may seem obvious when you consider that you get different output when you ask different questions—but it also applies to phrasing the same conceptual question differently. <b><font color='darkblue'>Prompt engineering</font> means constructing your text input to the LLM using specific approaches</b>.\n",
    "\n",
    "You can think of prompts as arguments and the LLM as the function to which you pass these arguments. Different input means different output:\n",
    "```python\n",
    ">>> def hello(name):\n",
    "...     print(f\"Hello, {name}!\")\n",
    "...\n",
    ">>> hello(\"World\")\n",
    "Hello, World!\n",
    ">>> hello(\"Engineer\")\n",
    "Hello, Engineer!\n",
    "```\n",
    "\n",
    "While an LLM is much more complex than the toy function above, the fundamental idea holds true. For a successful function call, you’ll need to know exactly which argument will produce the desired output. In the case of an LLM, that argument is text that consists of many different tokens, or pieces of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486cfe11-b050-413c-8dfb-3ee93c8ac687",
   "metadata": {},
   "source": [
    "<b>The field of prompt engineering is still changing rapidly, and there’s a lot of active research happening in this area.</b> As LLMs continue to evolve, so will the prompting approaches that will help you achieve the best results.\n",
    "\n",
    "<b>In this tutorial, you’ll cover some prompt engineering techniques, along with approaches to iteratively developing prompts</b>, that you can use to get better text completions for your own LLM-assisted projects:\n",
    "* Zero-Shot Prompting\n",
    "* Few-Shot Prompting\n",
    "* Delimiters\n",
    "* Numbered Steps\n",
    "* Role Prompts\n",
    "* Chain-of-Thought (CoT) Prompting\n",
    "* Structured Output\n",
    "* Labeled Conversations\n",
    "\n",
    "<b>There are more techniques to uncover, and you’ll also find links to additional resources in the tutorial</b>. Applying the mentioned techniques in a practical example will give you a great starting point for improving your LLM-supported programs. If you’ve never worked with an LLM before, then you may want to peruse [**OpenAI’s GPT documentation**](https://platform.openai.com/docs/guides/gpt) before diving in, but you should be able to follow along either way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476024e-09fc-4bae-ac32-79a956a51b18",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Get to Know the Practical Prompt Engineering Project</font></b>\n",
    "<font size='3ptx'><b>You’ll explore various prompt engineering techniques in service of a practical example: sanitizing customer chat conversations</b>. By practicing different prompt engineering techniques on a single real-world project, you’ll get a good idea of why you might want to use one technique over another and how you can apply them in practice.</font>\n",
    "\n",
    "Imagine that you’re the resident Python developer at a company that handles thousands of customer support chats on a daily basis. <b>Your job is to format and sanitize these conversations. You also help with deciding which of them require additional attention</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21fea1c-528e-4315-ab23-0f028f9e25f8",
   "metadata": {},
   "source": [
    "#### <b><font size='3ptx'>Collect Your Tasks</font></b>\n",
    "Your big-picture assignment is to help your company stay on top of handling customer chat conversations. The conversations that you work with may look like the one shown below:\n",
    "```text\n",
    "[support_tom] 2023-07-24T10:02:23+00:00 : What can I help you with?\n",
    "[johndoe] 2023-07-24T10:03:15+00:00 : I CAN'T CONNECT TO MY BLASTED ACCOUNT\n",
    "[support_tom] 2023-07-24T10:03:30+00:00 : Are you sure it's not your caps lock?\n",
    "[johndoe] 2023-07-24T10:04:03+00:00 : Blast! You're right!\n",
    "```\n",
    "\n",
    "You’re supposed to make these text conversations more accessible for further processing by the customer support department in a few different ways:\n",
    "* Remove personally identifiable information.\n",
    "* Remove swear words.\n",
    "* Clean the date-time information to only show the date.\n",
    "\n",
    "The swear words that you’ll encounter in this tutorial won’t be spicy at all, but you can consider them stand-ins for more explicit phrasing that you might find out in the wild. After sanitizing the chat conversation, you’d expect it to look like this:\n",
    "```text\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : 😤! You're right!\n",
    "```\n",
    "\n",
    "Sure—you could handle it [using Python’s `str.replace()`](https://realpython.com/replace-string-python/) or show off your [regular expression skills](https://realpython.com/regex-python/). But there’s more to the task than immediately meets the eye.\n",
    "\n",
    "<b>Your project manager isn’t a technical person, and they stuck another task at the end of this list.</b> They may think of the task as a normal continuation of the previous tasks. But you know that it requires an entirely different approach and technology stack:\n",
    "> Mark the conversations as “positive” or “negative.”\n",
    "\n",
    "That task lies in the realm of [**machine learning**](https://realpython.com/learning-paths/machine-learning-python/), namely [**text classification**](https://realpython.com/python-keras-text-classification/), and more specifically [**sentiment analysis**](https://realpython.com/python-nltk-sentiment-analysis/). Even [**advanced regex skills**](https://realpython.com/regex-python-part-2/) won’t get you far in this challenge.\n",
    "\n",
    "Additionally, you know that the customer support team that you’re preparing the data for will want to continue working on it programmatically. Plain text isn’t necessarily the best format for doing that. **You want to do work that’s useful for others, so you add yet another stretch goal to your growing list of tasks**:\n",
    "> Format the output as JSON.\n",
    "\n",
    "This task list is quickly growing out of proportion! Fortunately, **you’ve got access to the [**OpenAI API**](https://platform.openai.com/docs/api-reference/), and you’ll employ the help of their LLM to solve all of these challenges**.\n",
    "\n",
    "One of the impressive features of LLMs is the breadth of tasks that you can use them for. So **you’ll cover a lot of ground and different areas of use. And you’ll learn how to tackle them all with prompt engineering techniques.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad3e5b-aa68-4b5a-b853-f685a9659b80",
   "metadata": {},
   "source": [
    "#### <b><font size='3ptx'>Prepare Your Tools</font></b>\n",
    "<b><font size='3ptx'>To follow along with this tutorial, you’ll need to know [how to run a Python script](https://realpython.com/run-python-scripts/) from your command-line interface (CLI), and you’ll [need an API key from OpenAI](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key).</font></b>\n",
    "\n",
    "To get started, go ahead and download the example Python script that you’ll work with throughout the tutorial:\n",
    "> Get Sample Code: Click here to download the sample code that you’ll use to get the most out of large language models through prompt engineering.\n",
    "\n",
    "The codebase represents a light abstraction layer on top of the OpenAI API and exposes one function called get_chat_completion() that’ll be of primary interest for the tutorial. The function interacts with OpenAI’s /chat/completions endpoint to generate responses using different models, such as GPT-3.5-Turbo and GPT-4. You’ll explore both models, starting with GPT-3.5-Turbo, and eventually you’ll move on to the more powerful GPT-4 model.\n",
    "\n",
    "Most of the code in `app.py` revolves around setting up and fetching the settings from `settings.toml`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b3914-d44e-4d0a-b4e1-412984539389",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Start Engineering Your Prompts</font></b>\n",
    "<b><font size='3ptx'>Now that you have an understanding of prompt engineering and the practical project that you’ll be working with, it’s time to dive into some prompt engineering techniques.</font></b>\n",
    "\n",
    "In this section, you’ll learn how to apply the following techniques to your prompts to get the desired output from the language model:\n",
    "* **Zero-shot prompting**: Giving the language model normal instructions without any additional context\n",
    "* **Few-shot prompting**: Conditioning the model on a few examples to boost its performance\n",
    "* **Using delimiters**: Adding special tokens or phrases to provide structure and instructions to the model\n",
    "* **Detailed, numbered steps**: Breaking down a complex prompt into a series of small, specific steps.\n",
    "\n",
    "By practicing these techniques with the customer chat conversation example, you’ll gain a deeper understanding of how prompt engineering can enhance the capabilities of language models and improve their usefulness in real-world applications.\n",
    "\n",
    "* <b><font size='3ptx'><a href='#Describe-Your-Task'>Describe Your Task</font></b>\n",
    "* <b><font size='3ptx'><a href='#Switch-to-a-Different-Model'>Switch to a Different Model</font></b>\n",
    "* <b><font size='3ptx'><a href='#Add-a-Role-Prompt-to-Set-the-Tone'>Add a Role Prompt to Set the Tone</font></b>\n",
    "* <b><font size='3ptx'><a href='#Classify-the-Sentiment-of-Chat-Conversations'>Classify the Sentiment of Chat Conversations</font></b>\n",
    "* <b><font size='3ptx'><a href='#Walk-the-Model-Through-Chain-of-Thought-Prompting'>Walk the Model Through Chain-of-Thought Prompting</font></b>\n",
    "* <b><font size='3ptx'><a href='#Structure-Your-Output-Format-as-JSON'>Structure Your Output Format as JSON</font></b>\n",
    "* <b><font size='3ptx'><a href='#Improve-Your-Output-With-the-Power-of-Conversation-(back)'>Improve Your Output With the Power of Conversation</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf15e3-dbed-4fda-808a-151fe39761d7",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "### <b><font color='darkgreen'>Describe Your Task</font></b>\n",
    "You’ll start your prompt engineering journey with a concept called <b><font color='darkblue'>zero-shot prompting</font></b>, which is just a fancy way of saying that you’re asking a question or describing a task:\n",
    "> Remove personally identifiable information, only show the date, and replace all swear words with “😤”\n",
    "\n",
    "This task description focuses on the requested steps for sanitizing the customer chat conversation and literally spells them out. This is the prompt that’s currently saved as `instruction_prompt` in the <font color='olive'>settings.toml</font> file:\n",
    "- <font color='olive'>settings.toml</font>\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Remove personally identifiable information, only show the date,\n",
    "and replace all swear words with \"😤\"\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1d5234ed-8270-429e-abe1-1ba3a61bb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import tomli\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "_ = load_dotenv(find_dotenv(os.path.expanduser('~/.env')))\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "config = tomli.load(open('settings.toml', 'rb'))\n",
    "CHAT_MESSAGE = open('chats.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15fe1cbb-4201-43bb-9e39-c28a17d73e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file: str = 'settings.toml'):\n",
    "    return tomli.load(open(config_file, 'rb'))\n",
    "\n",
    "def load_chat_messages(chat_file: str = 'chats.txt'):\n",
    "    return open(chat_file).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61463022-1e08-49d1-8e24-ef82171f51a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[support_tom] 2023-07-24T10:02:23+00:00 : What can I help you with?\n",
      "[johndoe] 2023-07-24T10:03:15+00:00 : I CAN'T CONNECT TO MY BLASTED ACCOUNT\n",
      "[support_tom] 2023-07-24T10:03:30+00:00 : Are you sure it's not your caps lock?\n",
      "[johndoe] 2023-07-24T10:04:03+00:00 : Blast! You're right!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CHAT_MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef777a6-e651-4ced-88d3-282e11c94114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction_prompt': 'Remove personally identifiable information, only show the date,\\nand replace all swear words with \"😤\"\\n'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55fbf6a-fc84-407e-a17a-7c4cc00a7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please work on below chat messages:\n",
    "```\n",
    "{chat_messages}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a159c0a-e9e0-4371-9e2c-39e4366b75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': CHAT_MESSAGE,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54b0d7c6-3acd-4587-a7f6-5f276f0140b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "2023-07-24: What can I help you with?\n",
      "2023-07-24: I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
      "2023-07-24: Are you sure it's not your caps lock?\n",
      "2023-07-24: 😤! You're right!\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafaeda-e123-4fc9-ab6e-93778a40cf20",
   "metadata": {},
   "source": [
    "<b>The user (`[johndoe]`) and suppport team `[support_tom]` are removed which is not expected!</b>\n",
    "\n",
    "<b>One way to do that is by increasing the number of shots, or examples, that you give to the model</b>. When you’ve given the model zero shots, the only way to go is up! That’s why <b>you’ll improve your results through few-shot prompting in the next section</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a82fc-3e85-422f-b456-032a4ffa1233",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Use Few-Shot Prompting to Improve Output</font></b>\n",
    "<font size='3ptx'><b>Few-shot prompting is a prompt engineering technique where you provide example tasks and their expected solutions in your prompt</b>. So, instead of just describing the task like you did before, you’ll now add an example of a chat conversation and its sanitized version.</font>\n",
    "\n",
    "Open up <font color='olive'>settings_v2.toml</font> which changed the `instruction_prompt` by adding such an example:\n",
    "- <font color='olive'>settings_v2.toml</font>\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Remove personally identifiable information, only show the date,\n",
    "and replace all swear words with \"😤\"\n",
    "\n",
    "Example Input:\n",
    "[support_tom] 2023-07-24T10:02:23+00:00 : What can I help you with?\n",
    "[johndoe] 2023-07-24T10:03:15+00:00 : I CAN'T CONNECT TO MY BLASTED ACCOUNT\n",
    "[support_tom] 2023-07-24T10:03:30+00:00 : Are you sure it's not your caps lock?\n",
    "[johndoe] 2023-07-24T10:04:03+00:00 : Blast! You're right!\n",
    "\n",
    "Example Output:\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : 😤! You're right!\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4dc282c-b5f0-4104-a078-843378289670",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v2.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6ab0ede-0a48-475b-a4f5-f0a4a44ac905",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': CHAT_MESSAGE,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5202b5-c195-4361-8ff4-188cb986bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : 😤! You're right!\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76283e-5e0b-43eb-999a-b7dc98265676",
   "metadata": {},
   "source": [
    "Okay, great! This time at least the LLM didn’t eat up all the personal information that you passed to it without giving anything useful back!\n",
    "\n",
    "Let's try one more example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ba39989-4da1-4582-b740-fd358f9f4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat1_messages = load_chat_messages('chat_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a63b841-aff4-4d41-b4a9-1f183aab881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': chat1_messages,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3054c54a-bec4-4e9f-8187-1611618b036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[support_anna] 2023-08-12T08:45:00+00:00 : Hello! How can I assist you today?\n",
      "[melvin_r] 2023-08-12T08:45:27+00:00 : I can't download the monthly report!\n",
      "[support_anna] 2023-08-12T08:46:10+00:00 : Can you try clearing your browser cache and refreshing the page?\n",
      "[melvin_r] 2023-08-12T08:47:21+00:00 : That did the trick. Thanks!\n",
      "[support_anna] 2023-08-12T08:47:23+00:00 : It is my pleasure to help, Melvin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat1_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abc29e2c-f9aa-40e0-a863-b5d03476b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "[Agent] 2023-08-12 : Hello! How can I assist you today?\n",
      "[Customer] 2023-08-12 : I can't download the monthly report!\n",
      "[Agent] 2023-08-12 : Can you try clearing your browser cache and refreshing the page?\n",
      "[Customer] 2023-08-12 : That did the trick. Thanks!\n",
      "[Agent] 2023-08-12 : It is my pleasure to help.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f5a4c-1ca6-4a7a-b869-07e33b0d06b8",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "### <b><font color='darkgreen'>Switch to a Different Model</font></b>\n",
    "<b><font size='3ptx'>Generally, latest larger models will give you better results, especially for prompts that you didn’t heavily engineer.</font></b>\n",
    "\n",
    "<b>Additionally, it’s also helpful to keep in mind that API calls to larger, latest models will generally cost more money per request</b>. While it can be fun to always use the latest and greatest LLM, it may be worthwhile to consider whether you really need to upgrade to tackle the task that you’re trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb9fb669-885d-4eec-bd48-ab9e674d6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro-exp-03-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0bb0710-0843-417e-8af1-8b360303f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat2_messages = load_chat_messages('chat_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93b625df-d86b-4238-9765-def7a67002ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[support_joe] 2023-09-01T14:12:11+00:00 : Welcome to support. What seems to be the issue?\n",
      "[karen_b] 2023-09-01T14:13:02+00:00 : My promo code isn't working at checkout.\n",
      "[support_joe] 2023-09-01T14:14:35+00:00 : That code expired last week.\n",
      "[karen_b] 2023-09-01T14:15:00+00:00 : What the hell?! You guys just sent me that damn promo this morning! This is a total scam. I'm beyond pissed off right now.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat2_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38fed665-360c-4ff3-849b-be79ed1d7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': chat2_messages,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33b3525e-5315-4c77-bd38-70c6b720744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn’t arrived and it’s been 3 😤 weeks.\n",
      "[Agent] 2023-10-05 : I’m really sorry about that. Let me check… Okay, it looks like it was lost in transit. I’ll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode—but that actually helps. Thanks for fixing it fast.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d45fad-5e91-4c4a-a63b-227c60b63695",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Add a Role Prompt to Set the Tone</font></b>\n",
    "<font size='3ptx'>There are some additional possibilities when interacting with the API endpoint that you’ve only used implicitly, but haven’t explored yet, such as <b>adding role labels to a part of the prompt</b>.</font>\n",
    "\n",
    "In this section, you’ll use the \"system\" role to create a system message, and you’ll revisit the concept later on when you [**add more roles**](https://realpython.com/practical-prompt-engineering/#improve-your-output-with-the-power-of-conversation) to improve the output.\n",
    "\n",
    "<b>Role prompting usually refers to adding system messages, which represent information that helps to set the context for upcoming completions that the model will produce.</b> System messages usually aren’t visible to the end user. Keep in mind that the `/chat/completions` endpoint models were initially designed for conversational interactions.\n",
    "\n",
    "You can also use system messages to set a context for your completion task. You’ll craft a bespoke role prompt in a moment. However, for this specific task, the role prompt is likely less important than it might be for some other tasks. To explore the possible influence of a role prompt, you’ll take a little detour and ask your model to play a role:\n",
    "- **<font color='olive'>settings_v3.toml</font>**\n",
    "```toml\n",
    "role_prompt = \"\"\"You are a 16th century villain poet who treats\n",
    "customers with nothing but contempt.\n",
    "Rephrase every line spoken by an Agent with your unique voice.\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "Unleash, thou shall, the parchment’s code and behold the marvels unexpected, as the results may stir wonderment and awe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98b85e97-7282-4a46-8034-974a7513e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "config = tomli.load(open('settings_v3.toml', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b651fdf-0366-4f9b-9476-0ac483b18de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat3_messages = load_chat_messages('chat_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "665e0dfc-4667-4422-8c63-7b646b5f1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please work on below chat messages:\n",
    "```\n",
    "{chat_messages}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", config['role_prompt']),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "962fc89c-5f8c-4bb2-8353-d1a27b4b3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[support_lee] 2023-10-05T16:01:09+00:00 : Hi there! Need help with something?\n",
      "[mrfixit99] 2023-10-05T16:01:44+00:00 : My order hasn’t arrived and it’s been 3 f***ing weeks.\n",
      "[support_lee] 2023-10-05T16:02:30+00:00 : I’m really sorry about that. Let me check… Okay, it looks like it was lost in transit. I’ll send a replacement with express shipping right now.\n",
      "[mrfixit99] 2023-10-05T16:03:17+00:00 : Damn, I was ready to explode—but that actually helps. Thanks for fixing it fast.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat3_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fbb8e38-7e2c-42e3-adc5-1ca081c24cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': chat3_messages,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9793659c-460b-4e60-bc89-864e77d7f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] 2023-10-05 : Hmph, what paltry trifle vexes thee today, good sir?\n",
      "[Customer] 2023-10-05 : My order hasn’t arrived and it’s been 3 😤 weeks.\n",
      "[Agent] 2023-10-05 : My profoundest apologies, you blithering buffoon. Let mine eyes assess this... Ah, lost to the ether, it seems. Fear not, for I shall dispatch a replacement with the swiftness of a poisoned dart.\n",
      "[Customer] 2023-10-05 : 😤, I was ready to explode—but that actually helps. Thanks for fixing it fast.\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257b692-75b6-4352-bc9f-a2d9049aba10",
   "metadata": {},
   "source": [
    "To practice writing a role prompt—and to see whether you can release your customer chat conversations from the reign of that 16th century villain poet—you’ll craft a more appropriate role prompt:\n",
    "- **<font color='olive'>settings_v4.toml</font>**\n",
    "```toml\n",
    "role_prompt = \"\"\"You are a helpful assistant with a vast knowledge\n",
    "of customer chat conversations.\n",
    "You diligently complete tasks as instructed.\n",
    "You never make up any information that isn't there.\"\"\"\n",
    "```\n",
    "\n",
    "This role prompt is more appropriate to your use case. You don’t want the model to introduce randomness or to change any of the language that’s used in the conversations. Instead, you just want it to execute the tasks that you describe. Run the script another time and take a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "837408ef-e6ab-4c1e-ad00-724efac6838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v4.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94e4ba0d-05a0-4bb8-b22c-9879fcdee887",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please work on below chat messages:\n",
    "```\n",
    "{chat_messages}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", config['role_prompt']),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2917cb1-91bf-4e10-a6e6-8104f682a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'chat_messages': chat3_messages,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "114c75fa-2fe8-4677-9afc-c20e0208b78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn’t arrived and it’s been 3 😤 weeks.\n",
      "[Agent] 2023-10-05 : I’m really sorry about that. Let me check… Okay, it looks like it was lost in transit. I’ll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode—but that actually helps. Thanks for fixing it fast.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0999a-16fa-476e-9a33-2962770bae8d",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Classify the Sentiment of Chat Conversations</font></b>\n",
    "<font size='3ptx'><b>At this point, you’ve engineered a decent prompt that seems to perform quite well in sanitizing and reformatting the provided customer chat conversations</b>. To fully grasp the power of LLM-assisted workflows, <b>you’ll next tackle the tacked-on request by your manager to also classify the conversations as positive or negative.</b></font>\n",
    "\n",
    "Again, you want the model to do the work for you. All you need to do is craft a prompt that spells out the task at hand, and provide examples. You can also edit the role prompt to set the context for this new task that the model should perform:\n",
    "- **<font color='olive'>settings_v5.toml</font>**\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "with \"🔥\" for negative and \"✅\" for positive:\n",
    "\n",
    "#### START EXAMPLES\n",
    "\n",
    "------ Example Inputs ------\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : 😤! You're right!\n",
    "\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "\n",
    "------ Example Outputs ------\n",
    "🔥\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : 😤! You're right!\n",
    "\n",
    "✅\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "\n",
    "#### END EXAMPLES\n",
    "\"\"\"\n",
    "role_prompt = \"\"\"You are a thoroughly trained machine learning\n",
    "model that is an expert at sentiment classification.\n",
    "You diligently complete tasks as instructed.\n",
    "You never make up any information that isn't there.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189ba78-8c35-4cd2-8e73-4b7f31b97a00",
   "metadata": {},
   "source": [
    "You can now run the script and provide it with the sanitized conversations in <font color='olive'>sanitized-testing-chats.txt</font> that were the output of your previously engineered prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7ce41d0e-8f03-4400-abb9-b68b024beb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v5.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b006c803-0644-4ab2-8053-50a3ce69fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please work on below sanitized conversations:\n",
    "```\n",
    "{sanitized_conversations}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", config['role_prompt']),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8891fe4f-3ad2-45e7-a594-f9b2a91f9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_conversations = load_chat_messages('sanitized-testing-chats.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a4f3def-818b-4184-92ef-8f67e6fb8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d01d7e5-d6b9-4c7d-9ffa-d65ddc289e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n",
      "[Agent] 2023-08-12 : Hello! How can I assist you today?\n",
      "[Customer] 2023-08-12 : I can't download the monthly report!\n",
      "[Agent] 2023-08-12 : Can you try clearing your browser cache and refreshing the page?\n",
      "[Customer] 2023-08-12 : That did the trick. Thanks!\n",
      "[Agent] 2023-08-12 : It is my pleasure to help.\n",
      "\n",
      "🔥\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : 😤! You're right!\n",
      "\n",
      "🔥\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn’t arrived and it’s been 3 😤 weeks.\n",
      "[Agent] 2023-10-05 : I’m really sorry about that. Let me check… Okay, it looks like it was lost in transit. I’ll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode—but that actually helps. Thanks for fixing it fast.\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978efc8-0004-4504-b7f0-3c6b3ce0f71f",
   "metadata": {},
   "source": [
    "You could [add more examples](https://realpython.com/practical-prompt-engineering/#use-few-shot-prompting-to-improve-output), which is generally a good idea because it creates more context for the model to apply. Writing a [more detailed description](https://realpython.com/practical-prompt-engineering/#describe-your-request-in-numbered-steps) of your task helps as well, as you’ve seen before. However, to tackle this task, you’ll learn about another useful prompt engineering technique called chain-of-thought prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab736eb-dce4-4f07-938a-91bcffe9a0b4",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Walk the Model Through Chain-of-Thought Prompting</font></b>\n",
    "<font size='3ptx'><b>A widely successful prompt engineering approach can be summed up with the [anthropomorphism](https://en.wikipedia.org/wiki/Anthropomorphism) of giving the model time to think</b>. You can do this with a couple of different specific techniques. Essentially, it means that you prompt the LLM to produce intermediate results that become additional inputs. That way, the reasoning doesn’t need to take distant leaps but only hop from one lily pad to the next.</font>\n",
    "\n",
    "<b>One of these approaches is to use <font color='darkblue'>chain-of-thought (CoT) prompting techniques</font></b>. To apply CoT, you prompt the model to generate intermediate results that then become part of the prompt in a second request. The increased context makes it more likely that the model will arrive at a useful output.\n",
    "\n",
    "<b>The smallest form of CoT prompting is zero-shot CoT, where you literally ask the model to think step by step</b>. This approach yields [impressive results](https://arxiv.org/abs/2201.11903) for mathematical tasks that LLMs otherwise often solve incorrectly.\n",
    "\n",
    "Chain-of-thought operations are technically split into two stages:\n",
    "* **Reasoning extraction**, where the model generates the increased context\n",
    "* **Answer extraction**, where the model uses the increased context to generate the answer\n",
    "\n",
    "Reasoning extraction is useful across a variety of CoT contexts. You can generate few-shot examples from input, which you can then use for a separate step of extracting answers using more detailed chain-of-thought prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659f5b5-e672-49be-9d10-b49ef85c51d5",
   "metadata": {},
   "source": [
    "You can try zero-shot CoT on the sanitized chat conversations to embellish the few-shot examples that you’ll use to classify the chat conversations more robustly. Remove the examples and replace the instructions describing the reasoning on how you would classify the conversations in more detail:\n",
    "- **<font color='olive'>settings_v6.toml</font>**\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "with \"🔥\" for negative and \"✅\" for positive.\n",
    "\n",
    "Follow these steps when classifying the conversations:\n",
    "1. Does the customer use swear words or 😤?\n",
    "2. Does the customer seem aggravated or angry?\n",
    "\n",
    "If you answer \"Yes\" to one of the above questions,\n",
    "then classify the conversation as negative with \"🔥\".\n",
    "Otherwise classify the conversation as positive with \"✅\".\n",
    "\n",
    "Let's think step by step\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e16e271c-63f8-4abf-9ec3-2aae674e88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v6.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f50fbe07-7f84-43b6-b4d9-abed589177b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91730ed0-11c1-4093-b347-a2460a4b252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the sentiment analysis of the provided conversations:\n",
      "\n",
      "**Conversation 1:**\n",
      "\n",
      "*   The customer does not use swear words or 😤.\n",
      "*   The customer does not seem aggravated or angry.\n",
      "*   **Classification:** ✅\n",
      "\n",
      "**Conversation 2:**\n",
      "\n",
      "*   The customer uses 😤.\n",
      "*   The customer seems aggravated.\n",
      "*   **Classification:** 🔥\n",
      "\n",
      "**Conversation 3:**\n",
      "\n",
      "*   The customer uses 😤 and \"Damn\".\n",
      "*   The customer initially seems aggravated but expresses gratitude after the agent's solution.\n",
      "*   **Classification:** 🔥\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0ac00-e186-4c3b-91e2-87f9a85330aa",
   "metadata": {},
   "source": [
    "The reasoning is straightforward and sticks to your instructions. If the instructions accurately represent the criteria for marking a conversation as positive or negative, then you’ve got a good playbook at hand.\n",
    "\n",
    "You can now use this information to improve the few-shot examples for your sentiment classification task:\n",
    "- **<font color='olive'>settings_v7.toml</font>**\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "with \"🔥\" for negative and \"✅\" for positive.\n",
    "\n",
    "Follow these steps when classifying the conversations:\n",
    "1. Does the customer use swear words or 😤?\n",
    "2. Does the customer seem aggravated or angry?\n",
    "\n",
    "If you answer \"Yes\" to one of the above questions,\n",
    "then classify the conversation as negative with \"🔥\".\n",
    "Otherwise classify the conversation as positive with \"✅\".\n",
    "\n",
    "Let's think step by step\n",
    "\n",
    "#### START EXAMPLES\n",
    "\n",
    "------ Example Inputs ------\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : 😤! You're right!\n",
    "   - Does the customer use swear words or 😤? Yes\n",
    "   - Does the customer seem aggravated or angry? Yes\n",
    "   - Sentiment: 🔥\n",
    "\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "   - Does the customer use swear words or 😤? No\n",
    "   - Does the customer seem aggravated or angry? No\n",
    "   - Sentiment: ✅\n",
    "\n",
    "------ Example Outputs ------\n",
    "🔥 - Customer uses swear words and seems aggravated or angry.\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : 😤! You're right!\n",
    "\n",
    "✅ - Customer does not use swear words and feel neither angry nor aggravated.\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "\n",
    "#### END EXAMPLES\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd7c881e-81cc-4c75-877f-ab623e12176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v7.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69ad046b-10d2-490e-a353-913e7f9458a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "352e94af-c47c-4b37-890d-92ec9e109721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ - Customer does not use swear words and feel neither angry nor aggravated.\n",
      "[Agent] 2023-08-12 : Hello! How can I assist you today?\n",
      "[Customer] 2023-08-12 : I can't download the monthly report!\n",
      "[Agent] 2023-08-12 : Can you try clearing your browser cache and refreshing the page?\n",
      "[Customer] 2023-08-12 : That did the trick. Thanks!\n",
      "[Agent] 2023-08-12 : It is my pleasure to help.\n",
      "\n",
      "🔥 - Customer uses swear words and seems aggravated or angry.\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : 😤! You're right!\n",
      "\n",
      "🔥 - Customer uses swear words and seems aggravated or angry.\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn’t arrived and it’s been 3 😤 weeks.\n",
      "[Agent] 2023-10-05 : I’m really sorry about that. Let me check… Okay, it looks like it was lost in transit. I’ll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode—but that actually helps. Thanks for fixing it fast.\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc30835-74e2-4ddb-8892-029a982841e0",
   "metadata": {},
   "source": [
    "In this section, you’ve supported your examples with reasoning for why a conversation should be labeled as positive vs negative. You generated this reasoning with another call to the LLM.\n",
    "\n",
    "At this point, it seems that your prompt generalizes well to the available data and classifies the conversations as intended. And you only needed to carefully craft your words to make it happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af1a0c-6b4a-4606-a1ab-99509321ea17",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Structure Your Output Format as JSON</font></b>\n",
    "<font size='3ptx'>As a final showcase for effective prompting when incorporating an LLM into your workflow, you’ll tackle the last task, which you added to the list youself: <b>to pass the data on in a structured format that’ll make it straightforward for the customer support team to process further</b>.</font>\n",
    "\n",
    "You already specified a format to follow in the previous prompt, and the LLM returned what you asked for. So it might just be a matter of asking for a different, more structured format, for example [**JSON**](https://realpython.com/python-json/):\n",
    "\n",
    "- **<font color='olive'>settings_v8.toml</font>**\n",
    "```toml\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "as \"negative\" and \"positive\".\n",
    "Return the output as valid JSON.\n",
    "\n",
    "Follow these steps when classifying the conversations:\n",
    "1. Does the customer use swear words or 😤?\n",
    "2. Does the customer seem aggravated or angry?\n",
    "\n",
    "If you answer \"Yes\" to one of the above questions,\n",
    "then classify the conversation as \"negative\".\n",
    "Otherwise classify the conversation as \"positive\".\n",
    "\n",
    "Let's think step by step\n",
    "\n",
    "#### START EXAMPLES\n",
    "\n",
    "------ Example Inputs ------\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : 😤! You're right!\n",
    "   - Does the customer use swear words or 😤? Yes\n",
    "   - Does the customer seem aggravated or angry? Yes\n",
    "   - Sentiment: \"negative\"\n",
    "\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "   - Does the customer use swear words or 😤? No\n",
    "   - Does the customer seem aggravated or angry? No\n",
    "   - Sentiment: \"positive\"\n",
    "\n",
    "------ Example Output ------\n",
    "\n",
    "{\n",
    "  \"negative\": [\n",
    "    {\n",
    "      \"date\": \"2023-07-24\",\n",
    "      \"conversation\": [\n",
    "        \"A: What can I help you with?\",\n",
    "        \"C: I CAN'T CONNECT TO MY 😤 ACCOUNT\",\n",
    "        \"A: Are you sure it's not your caps lock?\",\n",
    "        \"C: 😤! You're right!\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"positive\": [\n",
    "    {\n",
    "      \"date\": \"2023-06-15\",\n",
    "      \"conversation\": [\n",
    "        \"A: Hello! How can I assist you today?\",\n",
    "        \"C: I can't seem to find the download link for my purchased software.\",\n",
    "        \"A: No problem, ****. Let me find that for you. Can you please provide your order number?\",\n",
    "        \"C: It's ****. Thanks for helping me out!\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "#### END EXAMPLES\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c331c2f5-3138-4567-8b71-965d092fd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v8.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cddebfac-fe50-4c60-8e89-5e503896bef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
      "as \"negative\" and \"positive\". For the output format:\n",
      "1. Return the output as valid JSON format.\n",
      "2. Skip the prefix \"```json\" from the generated output.\n",
      "\n",
      "Follow these steps when classifying the conversations:\n",
      "1. Does the customer use swear words or 😤?\n",
      "2. Does the customer seem aggravated or angry?\n",
      "\n",
      "If you answer \"Yes\" to one of the above questions,\n",
      "then classify the conversation as \"negative\".\n",
      "Otherwise classify the conversation as \"positive\".\n",
      "\n",
      "Let's think step by step\n",
      "\n",
      "#### START EXAMPLES\n",
      "\n",
      "------ Example Inputs ------\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : 😤! You're right!\n",
      "   - Does the customer use swear words or 😤? Yes\n",
      "   - Does the customer seem aggravated or angry? Yes\n",
      "   - Sentiment: \"negative\"\n",
      "\n",
      "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
      "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
      "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
      "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
      "   - Does the customer use swear words or 😤? No\n",
      "   - Does the customer seem aggravated or angry? No\n",
      "   - Sentiment: \"positive\"\n",
      "\n",
      "------ Example Output ------\n",
      "\n",
      "{\n",
      "  \"negative\": [\n",
      "    {\n",
      "      \"date\": \"2023-07-24\",\n",
      "      \"conversation\": [\n",
      "        \"A: What can I help you with?\",\n",
      "        \"C: I CAN'T CONNECT TO MY 😤 ACCOUNT\",\n",
      "        \"A: Are you sure it's not your caps lock?\",\n",
      "        \"C: 😤! You're right!\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"positive\": [\n",
      "    {\n",
      "      \"date\": \"2023-06-15\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hello! How can I assist you today?\",\n",
      "        \"C: I can't seem to find the download link for my purchased software.\",\n",
      "        \"A: No problem, ****. Let me find that for you. Can you please provide your order number?\",\n",
      "        \"C: It's ****. Thanks for helping me out!\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "#### END EXAMPLES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config['instruction_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e82772f8-5a98-47fb-af17-c5b22f264e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Instruction: {instruction}\n",
    "\n",
    "Please apply instruction above onto below sanitized conversations to generate the desired output:\n",
    "```\n",
    "{sanitized_conversations}\n",
    "```\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", config['role_prompt']),\n",
    "    (\"user\", TASK_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23f72d48-0d2b-4a8b-8d38-fae195bb02c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
      "as \"negative\" and \"positive\". For the output format:\n",
      "1. Return the output as valid JSON format.\n",
      "2. Please don't include prefix ```json...``` in the output.\n",
      "\n",
      "Follow these steps when classifying the conversations:\n",
      "1. Does the customer use swear words or 😤?\n",
      "2. Does the customer seem aggravated or angry?\n",
      "\n",
      "If you answer \"Yes\" to one of the above questions,\n",
      "then classify the conversation as \"negative\".\n",
      "Otherwise classify the conversation as \"positive\".\n",
      "\n",
      "Let's think step by step\n",
      "\n",
      "#### START EXAMPLES\n",
      "\n",
      "------ Example Inputs ------\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : 😤! You're right!\n",
      "   - Does the customer use swear words or 😤? Yes\n",
      "   - Does the customer seem aggravated or angry? Yes\n",
      "   - Sentiment: \"negative\"\n",
      "\n",
      "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
      "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
      "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
      "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
      "   - Does the customer use swear words or 😤? No\n",
      "   - Does the customer seem aggravated or angry? No\n",
      "   - Sentiment: \"positive\"\n",
      "\n",
      "------ Example Output ------\n",
      "\n",
      "{\n",
      "  \"negative\": [\n",
      "    {\n",
      "      \"date\": \"2023-07-24\",\n",
      "      \"conversation\": [\n",
      "        \"A: What can I help you with?\",\n",
      "        \"C: I CAN'T CONNECT TO MY 😤 ACCOUNT\",\n",
      "        \"A: Are you sure it's not your caps lock?\",\n",
      "        \"C: 😤! You're right!\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"positive\": [\n",
      "    {\n",
      "      \"date\": \"2023-06-15\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hello! How can I assist you today?\",\n",
      "        \"C: I can't seem to find the download link for my purchased software.\",\n",
      "        \"A: No problem, ****. Let me find that for you. Can you please provide your order number?\",\n",
      "        \"C: It's ****. Thanks for helping me out!\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "#### END EXAMPLES\n",
      "\n",
      "\n",
      "Please apply instruction above onto below sanitized conversations to generate the desired output:\n",
      "```\n",
      "[Agent] 2023-08-12 : Hello! How can I assist you today?\n",
      "[Customer] 2023-08-12 : I can't download the monthly report!\n",
      "[Agent] 2023-08-12 : Can you try clearing your browser cache and refreshing the page?\n",
      "[Customer] 2023-08-12 : That did the trick. Thanks!\n",
      "[Agent] 2023-08-12 : It is my pleasure to help.\n",
      "\n",
      "[Agent] 2023-07-24 : What can I help you with?\n",
      "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
      "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
      "[Customer] 2023-07-24 : 😤! You're right!\n",
      "\n",
      "[Agent] 2023-10-05 : Hi there! Need help with something?\n",
      "[Customer] 2023-10-05 : My order hasn’t arrived and it’s been 3 😤 weeks.\n",
      "[Agent] 2023-10-05 : I’m really sorry about that. Let me check… Okay, it looks like it was lost in transit. I’ll send a replacement with express shipping right now.\n",
      "[Customer] 2023-10-05 : Damn, I was ready to explode—but that actually helps. Thanks for fixing it fast.\n",
      "\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}).messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c196635b-c494-4a27-aa24-f045c364dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompt_template.invoke({\n",
    "    'instruction': config['instruction_prompt'],\n",
    "    'sanitized_conversations': sanitized_conversations,\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "db7929c2-73aa-4c62-a0dc-3d17217abbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"negative\": [\n",
      "    {\n",
      "      \"date\": \"2023-07-24\",\n",
      "      \"conversation\": [\n",
      "        \"A: What can I help you with?\",\n",
      "        \"C: I CAN'T CONNECT TO MY 😤 ACCOUNT\",\n",
      "        \"A: Are you sure it's not your caps lock?\",\n",
      "        \"C: 😤! You're right!\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"date\": \"2023-10-05\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hi there! Need help with something?\",\n",
      "        \"C: My order hasn’t arrived and it’s been 3 😤 weeks.\",\n",
      "        \"A: I’m really sorry about that. Let me check… Okay, it looks like it was lost in transit. I’ll send a replacement with express shipping right now.\",\n",
      "        \"C: Damn, I was ready to explode—but that actually helps. Thanks for fixing it fast.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"positive\": [\n",
      "    {\n",
      "      \"date\": \"2023-08-12\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hello! How can I assist you today?\",\n",
      "        \"C: I can't download the monthly report!\",\n",
      "        \"A: Can you try clearing your browser cache and refreshing the page?\",\n",
      "        \"C: That did the trick. Thanks!\",\n",
      "        \"A: It is my pleasure to help.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076248d-4bc0-4a50-a697-ad41bc4add98",
   "metadata": {},
   "source": [
    "In this case, you receive valid JSON, as requested. The classification still works as before and the output censors personally identifiable information, replaces swear words, and applies all the additional requested formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982d650-6173-4fdd-8fda-231ec8aa3e35",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Improve Your Output With the Power of Conversation</font></b> ([back](#Start-Engineering-Your-Prompts))\n",
    "<font size='3ptx'>You added a [**role prompt**](https://realpython.com/practical-prompt-engineering/#add-a-role-prompt-to-set-the-tone) earlier on, but otherwise you haven’t tapped into the power of conversations yet.</font>\n",
    "\n",
    "<b>In this final section, you’ll learn how you can provide additional context to the model by splitting your prompt into multiple separate messages with different labels.</b>\n",
    "\n",
    "In calls to the /chat/completions endpoint, a prompt is split into several **messages**. Each message has its content, which represents the prompt text. Additionally, it also has a role. There are different [**roles**](https://platform.openai.com/docs/api-reference/chat/create#chat/create-role) that a message can have, and you’ll work with three of them:\n",
    "* **\"system\"** gives context for the conversation and helps to set the overall tone.\n",
    "* **\"user\"** represents the input that a user of your application might provide.\n",
    "* **\"assistant\"** represents the output that the model would reply with.\n",
    "\n",
    "So far, you’ve provided context for different parts of your prompt all mashed together in a single prompt, more or less well separated [using delimiters](https://realpython.com/practical-prompt-engineering/#use-delimiters-to-clearly-mark-sections-of-your-prompt). When you use a model that’s optimized for chat, such as GPT-4, then you can use roles to let the LLM know what type of message you’re sending.\n",
    "\n",
    "For example, you can create some variables for your few-shot examples and separate variables for the associated CoT reasoning and outputs:\n",
    "- **<font color='olive'>settings_v9.toml</font>**\n",
    "```toml\n",
    "[prompts]\n",
    "instruction_prompt = \"\"\"\n",
    "Classify the sentiment of each conversation in >>>>>CONTENT<<<<<\n",
    "as \"negative\" and \"positive\".\n",
    "Return the output as valid JSON.\n",
    "\"\"\"\n",
    "role_prompt = \"\"\"You are a thoroughly trained machine learning\n",
    "model that is an expert at sentiment classification.\n",
    "You diligently complete tasks as instructed.\n",
    "You never make up any information that isn't there.\"\"\"\n",
    "positive_example = \"\"\"\n",
    "[Agent] 2023-06-15 : Hello! How can I assist you today?\n",
    "[Customer] 2023-06-15 : I can't seem to find the download link for my purchased software.\n",
    "[Agent] 2023-06-15 : No problem, ****. Let me find that for you. Can you please provide your order number?\n",
    "[Customer] 2023-06-15 : It's ****. Thanks for helping me out!\n",
    "\"\"\"\n",
    "positive_reasoning = \"\"\"\n",
    "- Does the customer use swear words or 😤? No\n",
    "- Does the customer seem aggravated or angry? No\n",
    "- Sentiment: \"positive\"\n",
    "\"\"\"\n",
    "positive_output = \"\"\"\n",
    "\"positive\": [\n",
    "  {\n",
    "    \"date\": \"2023-06-15\",\n",
    "    \"conversation\": [\n",
    "      \"A: Hello! How can I assist you today?\",\n",
    "      \"C: I can't seem to find the download link for my purchased software.\",\n",
    "      \"A: No problem, ****. Let me find that for you. Can you please provide your order number?\",\n",
    "      \"C: It's ****. Thanks for helping me out!\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "negative_example = \"\"\"\n",
    "[Agent] 2023-07-24 : What can I help you with?\n",
    "[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\n",
    "[Agent] 2023-07-24 : Are you sure it's not your caps lock?\n",
    "[Customer] 2023-07-24 : 😤! You're right!\n",
    "\"\"\"\n",
    "negative_reasoning = \"\"\"\n",
    "- Does the customer use swear words or 😤? Yes\n",
    "- Does the customer seem aggravated or angry? Yes\n",
    "- Sentiment: \"negative\"\n",
    "\"\"\"\n",
    "negative_output = \"\"\"\n",
    "\"negative\": [\n",
    "  {\n",
    "    \"date\": \"2023-07-24\",\n",
    "    \"conversation\": [\n",
    "      \"A: What can I help you with?\",\n",
    "      \"C: I CAN'T CONNECT TO MY 😤 ACCOUNT\",\n",
    "      \"A: Are you sure it's not your caps lock?\",\n",
    "      \"C: 😤! You're right!\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e8378-67b7-4c3e-91fd-6d84f3494708",
   "metadata": {},
   "source": [
    "You’ve disassembled your `instruction_prompt` into seven separate prompts, based on what role the messages have in your conversation with the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f0913-6c98-4cfa-8ffa-2cb76983e1da",
   "metadata": {},
   "source": [
    "The helper function that builds a messages payload, <font color='blue'>assemble_chat_messages()</font>, is already set up to include all of these prompts in the API request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a212fe2f-6df8-409b-ac38-459b18e7c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_chat_messages(settings: Any, content: str) -> list[dict]:\n",
    "    \"\"\"Combine all messages into a well-formatted list of dicts.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": settings['role_prompt']},\n",
    "        {\"role\": \"user\", \"content\": settings['negative_example']},\n",
    "        {\"role\": \"system\", \"content\": settings['negative_reasoning']},\n",
    "        {\"role\": \"assistant\", \"content\": settings['negative_output']},\n",
    "        {\"role\": \"user\", \"content\": settings['positive_example']},\n",
    "        {\"role\": \"system\", \"content\": settings['positive_reasoning']},\n",
    "        {\"role\": \"assistant\", \"content\": settings['positive_output']},\n",
    "        {\"role\": \"user\", \"content\": f\">>>>>\\n{content}\\n<<<<<\"},\n",
    "        {\"role\": \"user\", \"content\": settings['instruction_prompt']},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fce87-4d14-43ec-bdc8-9674a8522ca4",
   "metadata": {},
   "source": [
    "Your prompt is now split into distinct parts, each of which has a certain role label:\n",
    "* **Example** input has the \"user\" role.\n",
    "* **Reasoning** that the model created has the \"system\" role.\n",
    "* **Example** output has the \"assistant\" role.\n",
    "\n",
    "You’re now providing context for how user input might look, how the model can reason about classifying the input, and how your expected output should look. You removed the delimiters that you previously used for labeling the example sections. They aren’t necessary now that you’re providing context for the parts of your prompt through separate messages.\n",
    "\n",
    "Give your script a final run to see whether the power of conversation has managed to improve the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4695b40b-accc-4f30-9f49-4c51253962e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('settings_v9.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aea7b5cc-871e-4170-aa94-777859be015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_messages = assemble_chat_messages(config['prompts'], sanitized_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29368412-aab4-49cf-bdbb-a8d4cda294d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a thoroughly trained machine learning\\nmodel that is an expert at sentiment classification.\\nYou diligently complete tasks as instructed.\\nYou never make up any information that isn't there.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"[Agent] 2023-07-24 : What can I help you with?\\n[Customer] 2023-07-24 : I CAN'T CONNECT TO MY 😤 ACCOUNT\\n[Agent] 2023-07-24 : Are you sure it's not your caps lock?\\n[Customer] 2023-07-24 : 😤! You're right!\\n\"},\n",
       " {'role': 'system',\n",
       "  'content': '- Does the customer use swear words or 😤? Yes\\n- Does the customer seem aggravated or angry? Yes\\n- Sentiment: \"negative\"\\n'}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompted_messages[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a521379c-38d0-439d-9c1c-2b579c055327",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.invoke(prompted_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "787bbf06-2761-42da-a540-c61f39bd5e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"positive\": [\n",
      "    {\n",
      "      \"date\": \"2023-08-12\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hello! How can I assist you today?\",\n",
      "        \"C: I can't download the monthly report!\",\n",
      "        \"A: Can you try clearing your browser cache and refreshing the page?\",\n",
      "        \"C: That did the trick. Thanks!\",\n",
      "        \"A: It is my pleasure to help.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"negative\": [\n",
      "    {\n",
      "      \"date\": \"2023-07-24\",\n",
      "      \"conversation\": [\n",
      "        \"A: What can I help you with?\",\n",
      "        \"C: I CAN'T CONNECT TO MY 😤 ACCOUNT\",\n",
      "        \"A: Are you sure it's not your caps lock?\",\n",
      "        \"C: 😤! You're right!\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"date\": \"2023-10-05\",\n",
      "      \"conversation\": [\n",
      "        \"A: Hi there! Need help with something?\",\n",
      "        \"C: My order hasn’t arrived and it’s been 3 😤 weeks.\",\n",
      "        \"A: I’m really sorry about that. Let me check… Okay, it looks like it was lost in transit. I’ll send a replacement with express shipping right now.\",\n",
      "        \"C: Damn, I was ready to explode—but that actually helps. Thanks for fixing it fast.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4cc094-493a-4ea5-9691-386e1fda5b04",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Next Steps</font></b>\n",
    "<font size='3ptx'><b>In this tutorial, you’ve learned about various prompt engineering techniques, and you’ve built an LLM-assisted Python application along the way.</b></font>\n",
    "\n",
    "The field of prompt engineering is quite new, and LLMs keep developing quickly as well. The landscape, best practices, and most effective approaches are therefore changing rapidly. To continue learning about prompt engineering using free and open-source resources, you can check out [**Learn Prompting**](https://learnprompting.org/docs/intro/) and the [**Prompt Engineering Guide**](https://www.promptingguide.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0ce77-35f6-45ac-96b4-e2384bed64d4",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [LangChain - Google AI chat models](https://python.langchain.com/v0.1/docs/integrations/chat/google_generative_ai/)\n",
    "* [LangChain - How to use few shot examples](https://python.langchain.com/docs/how_to/few_shot_examples/)\n",
    "* [RealPython - Python and TOML: New Best Friends](https://realpython.com/python-toml/)\n",
    "* [YT - How to Use Directional Stimulus Prompting in ChatGPT & Python: Step-by-Step Tutorial](https://www.youtube.com/watch?v=WEAaVKVfy3M)\n",
    "* [Prompt Engineering Guide - Directional Stimulus Prompting](https://www.promptingguide.ai/techniques/dsp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
