{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fef3413b",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article source](https://www.analyticsvidhya.com/blog/2020/07/types-of-feature-transformation-and-scaling/)) <font size='3ptx'><b>In my machine learning journey, more often than not, I have found that feature preprocessing is a more effective technique in improving my evaluation metric than any other step, like choosing a model algorithm, hyperparameter tuning, etc.</b></font>\n",
    "\n",
    "<b>Feature preprocessing is one of the most crucial steps in building a Machine learning model</b>. Too few features and your model won’t have much to learn from. Too many features and we might be feeding unnecessary information to the model. Not only this, but the values in each of the features need to be considered as well.\n",
    "\n",
    "We know that there are some set rules of dealing with categorical data, as in, encoding them in different ways. However, <b>a large chunk of the process involves dealing with continuous variables. There are various methods of dealing with continuous variables. Some of them include converting them to a normal distribution or converting them to categorical variables, etc</b>.\n",
    "\n",
    "There are a couple of go-to techniques I always use regardless of the model I am using, or whether it is a classification task or regression task, or even an unsupervised learning model. These techniques are:\n",
    "* Feature Transformation and\n",
    "* Feature Scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d9cd0",
   "metadata": {},
   "source": [
    "<a id='sect0'></a>\n",
    "### <font color='darkgreen'>Table of Contents</font>\n",
    "1. <font size='3ptx'><b><a href='#sect1'>Why do we need Feature Transformation and Scaling?</a></b></font>\n",
    "2. <font size='3ptx'><b><a href='#sect2'>MinMax Scaler</a></b></font>\n",
    "3. <font size='3ptx'><b><a href='#sect3'>Standard Scaler</a></b></font>\n",
    "4. <font size='3ptx'><b><a href='#sect4'>MaxAbsScaler</a></b></font>\n",
    "5. <font size='3ptx'><b><a href='#sect5'>Robust Scaler</a></b></font>\n",
    "6. <font size='3ptx'><b><a href='#sect6'>Quantile Transformer Scaler</a></b></font>\n",
    "7. <font size='3ptx'><b><a href='#sect7'>Log Transformation</a></b></font>\n",
    "8. <font size='3ptx'><b><a href='#sect8'>Power Transformer Scaler</a></b></font>\n",
    "9. <font size='3ptx'><b><a href='#sect9'>Unit Vector Scaler/Normalizer</a></b></font>\n",
    "10. <font size='3ptx'><b><a href='#sect10'>Customer Transformer</a></b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a4160b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c4433",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "## <font color='darkblue'>Why do we need Feature Transformation and Scaling?</font>\n",
    "<b><font size='3ptx'>Oftentimes, we have datasets in which different columns have different units</font></b> – like one column can be in kilograms, while another column can be in centimeters. Furthermore, we can have columns like income which can range from 20,000 to 100,000, and even more; while an age column which can range from 0 to 100 (<font color='brown'>at the most</font>). Thus, Income is about 1,000 times larger than age.\n",
    "\n",
    "<b>But how can we be sure that the model treats both these variables equally?</b> When we feed these features to the model as is, there is every chance that the income will influence the result more due to its larger value. But this doesn’t necessarily mean it is more important as a predictor. So, to give importance to both Age, and Income, we need feature scaling.\n",
    "\n",
    "In most examples of machine learning models, you would have observed either the Standard Scaler or MinMax Scaler. However, <b>the powerful [sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html) offers many other feature transformations scaling techniques as well, which we can leverage depending on the data we are dealing with.</b> So, what are you waiting for?\n",
    "\n",
    "Let us explore them one by one with Python code. We will work with a simple dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f6e861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Income': [15000, 1800, 120000, 10000],\n",
    "    'Age': [25, 18, 42, 51],\n",
    "    'Department': ['HR','Legal','Marketing','Management']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0124b",
   "metadata": {},
   "source": [
    "Before directly applying any feature transformation or scaling technique, we need to remember the categorical column: `Department` and first deal with it. This is because we cannot scale non-numeric values.\n",
    "\n",
    "For that, we 1st create a copy of our dataframe and store the numerical feature names in a list, and their values as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "677b13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df.copy()\n",
    "col_names = ['Income', 'Age'] \n",
    "features = df_scaled[col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e2c0b1",
   "metadata": {},
   "source": [
    "We will execute this snippet before using a new scaler every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548622c",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "## <font color='darkblue'>MinMax Scaler</font>\n",
    "The MinMax scaler is one of the simplest scalers to understand.  It just scales all the data between 0 and 1. The formula for calculating the scaled value is:\n",
    "> $x\\_scaled = (x – x\\_min)/(x\\_max – x\\_min)$\n",
    "\n",
    "<br/>\n",
    "\n",
    "Thus, a point to note is that it does so for every feature separately. Though (0, 1) is the default range, we can define our range of max and min values as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4415d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a378321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply it on only the values of the features:\n",
    "normalized_col_names = ['Income_minmax_norm', 'Age_minmax_norm']\n",
    "df_scaled[normalized_col_names] = scaler.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a6a1c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income_minmax_norm</th>\n",
       "      <th>Age_minmax_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.069374</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Income_minmax_norm  Age_minmax_norm\n",
       "0   15000   25            0.111675         0.212121\n",
       "1    1800   18            0.000000         0.000000\n",
       "2  120000   42            1.000000         0.727273\n",
       "3   10000   51            0.069374         1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names + normalized_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0db03",
   "metadata": {},
   "source": [
    "You can see how the values were scaled. The minimum value among the columns became 0, and the maximum value was changed to 1, with other values in between. <b>However, suppose we don’t want the income or age to have values like 0. Let us take the range to be (5, 10)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21e08205",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(5, 10))\n",
    "\n",
    "df_scaled[normalized_col_names] = scaler.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd66fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income_minmax_norm</th>\n",
       "      <th>Age_minmax_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>5.558376</td>\n",
       "      <td>6.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>5.346870</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Income_minmax_norm  Age_minmax_norm\n",
       "0   15000   25            5.558376         6.060606\n",
       "1    1800   18            5.000000         5.000000\n",
       "2  120000   42           10.000000         8.636364\n",
       "3   10000   51            5.346870        10.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names + normalized_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace4c48",
   "metadata": {},
   "source": [
    "<a id='sect3'></a>\n",
    "## <font color='darkblue'>Standard Scaler</font>\n",
    "<font size='3ptx'><b>Just like the MinMax Scaler, the Standard Scaler is another popular scaler that is very easy to understand and implement.</b></font>\n",
    "\n",
    "For each feature, the Standard Scaler scales the values such that the mean is 0 and the standard deviation is 1 (<font color='brown'>or the variance</font>).\n",
    "> $x\\_scaled = x – mean/std\\_dev$\n",
    "<br/>\n",
    "\n",
    "However, <b><font color='darkred'>Standard Scaler assumes that the distribution of the variable is normal</font></b>. Thus, in case, the variables are not normally distributed, we\n",
    "1. either choose a different scaler\n",
    "2. or first, convert the variables to a normal distribution and then apply this scaler\n",
    "<br/>\n",
    "\n",
    "Implementing the standard scaler is much similar to implementing a min-max scaler. Just like before, we will first import [**StandardScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) and then use it to transform our variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906454dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "standard_scaler_normalized_col_names = ['Income_standard_scaler_norm', 'Age_standard_scaler_norm']\n",
    "df_scaled[standard_scaler_normalized_col_names] = scaler.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df5ae3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income_standard_scaler_norm</th>\n",
       "      <th>Age_standard_scaler_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.449056</td>\n",
       "      <td>-0.685248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.722214</td>\n",
       "      <td>-1.218219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>1.723796</td>\n",
       "      <td>0.609110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.552525</td>\n",
       "      <td>1.294358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Income_standard_scaler_norm  Age_standard_scaler_norm\n",
       "0   15000   25                    -0.449056                 -0.685248\n",
       "1    1800   18                    -0.722214                 -1.218219\n",
       "2  120000   42                     1.723796                  0.609110\n",
       "3   10000   51                    -0.552525                  1.294358"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names + standard_scaler_normalized_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff95ec",
   "metadata": {},
   "source": [
    "Let us check the mean and standard deviation of both the columns by performing a [describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) function on `df_scaled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5e245d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income_standard_scaler_norm</th>\n",
       "      <th>Age_standard_scaler_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.154701</td>\n",
       "      <td>1.154701e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.722214</td>\n",
       "      <td>-1.218219e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.594947</td>\n",
       "      <td>-8.184910e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.500791</td>\n",
       "      <td>-3.806935e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.094157</td>\n",
       "      <td>7.804217e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.723796</td>\n",
       "      <td>1.294358e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income_standard_scaler_norm  Age_standard_scaler_norm\n",
       "count                     4.000000              4.000000e+00\n",
       "mean                      0.000000             -5.551115e-17\n",
       "std                       1.154701              1.154701e+00\n",
       "min                      -0.722214             -1.218219e+00\n",
       "25%                      -0.594947             -8.184910e-01\n",
       "50%                      -0.500791             -3.806935e-02\n",
       "75%                       0.094157              7.804217e-01\n",
       "max                       1.723796              1.294358e+00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[standard_scaler_normalized_col_names].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5102b4",
   "metadata": {},
   "source": [
    "<a id='sect4'></a>\n",
    "## <font color='darkblue'>MaxAbsScaler</font>\n",
    "<b><font size='3ptx'>In simplest terms, the [MaxAbs scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler) takes the absolute maximum value of each column and divides each value in the column by the maximum value.</font></b>\n",
    "\n",
    "Thus, it first takes the absolute value of each value in the column and then takes the maximum value out of those. This operation scales the data between the range \\[-1, 1].  <b>To see how it works, we will add another column called `Balance` which contains negative values</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bff61016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    \"Balance\": [100.0, -263.0, 2000.0, -5.0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6deaf2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balance</th>\n",
       "      <th>Balance_maxabs_scaler_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-263.0</td>\n",
       "      <td>-0.1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>-0.0025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Balance  Balance_maxabs_scaler_norm\n",
       "0    100.0                      0.0500\n",
       "1   -263.0                     -0.1315\n",
       "2   2000.0                      1.0000\n",
       "3     -5.0                     -0.0025"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "\n",
    "max_abs_normalized_col_names = ['Balance_maxabs_scaler_norm']\n",
    "df2[max_abs_normalized_col_names] = scaler.fit_transform(df2[['Balance']].values)\n",
    "df2[['Balance'] + max_abs_normalized_col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3de41729",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_balance = df2.Balance.max()\n",
    "df2['reconstruct_balance'] = df2.apply(lambda row: row.Balance_maxabs_scaler_norm * max_balance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33a39a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balance</th>\n",
       "      <th>Balance_maxabs_scaler_norm</th>\n",
       "      <th>reconstruct_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-263.0</td>\n",
       "      <td>-0.1315</td>\n",
       "      <td>-263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Balance  Balance_maxabs_scaler_norm  reconstruct_balance\n",
       "0    100.0                      0.0500                100.0\n",
       "1   -263.0                     -0.1315               -263.0\n",
       "2   2000.0                      1.0000               2000.0\n",
       "3     -5.0                     -0.0025                 -5.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thus, we can confirm that each value in the Balance column is divided by 2000 (max_balance)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5161368",
   "metadata": {},
   "source": [
    "<a id='sect5'></a>\n",
    "## <font color='darkblue'>Robust Scaler</font>\n",
    "If you have noticed in the scalers we used so far, each of them was using values like the mean, maximum and minimum values of the columns. All these values are sensitive to outliers. <b><font color='darkred' size='3ptx'>If there are too many outliers in the data, they will influence the mean and the max value or the min value. Thus, even if we scale this data using the above methods, we cannot guarantee a balanced data with a normal distribution.</font></b>\n",
    "\n",
    "The [**Robust Scaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler), as the name suggests is not sensitive to outliers. This scaler-\n",
    "* removes the median from the data\n",
    "* scales the data by the InterQuartile Range(IQR)\n",
    "<br/>\n",
    "\n",
    "Are you familiar with the [**Inter-Quartile Range**](https://en.wikipedia.org/wiki/Interquartile_range)? It is nothing but the difference between the first and third quartile of the variable. The interquartile range can be defined as-\n",
    "> $IQR = Q3 – Q1$\n",
    "<br/>\n",
    "\n",
    "Thus, the formula would be:\n",
    "> $x\\_scaled = (x – Q1)/(Q3 – Q1)$\n",
    "<br/>\n",
    "\n",
    "This is the default range, though we can define our own range if we want to. Now let us see how can we implement the [**Robust Scaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler) in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "807e7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "robust_normalized_col_names = ['Income_robust_scaler_norm', 'Age_robust_scaler_norm']\n",
    "df_scaled[robust_normalized_col_names] = scaler.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "879f7e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income_robust_scaler_norm</th>\n",
       "      <th>Age_robust_scaler_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.075075</td>\n",
       "      <td>-0.404762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.321321</td>\n",
       "      <td>-0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>3.228228</td>\n",
       "      <td>0.404762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.075075</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Income_robust_scaler_norm  Age_robust_scaler_norm\n",
       "0   15000   25                   0.075075               -0.404762\n",
       "1    1800   18                  -0.321321               -0.738095\n",
       "2  120000   42                   3.228228                0.404762\n",
       "3   10000   51                  -0.075075                0.833333"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names + robust_normalized_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae069945",
   "metadata": {},
   "source": [
    "<a id='sect6'></a>\n",
    "## <font color='darkblue'>Quantile Transformer Scaler</font> ([back](#sect0))\n",
    "One of the most interesting feature transformation techniques that I have used, <font size='3ptx'><b>the [Quantile Transformer Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer) converts the variable distribution to a normal distribution. and scales it accordingly</b></font>. Since it makes the variable normally distributed, it also deals with the outliers. Here are a few important points regarding the [**Quantile Transformer Scaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer):\n",
    "1. It computes the cumulative distribution function of the variable\n",
    "2. It uses this cdf to map the values to a normal distribution\n",
    "3. Maps the obtained values to the desired output distribution using the associated quantile function\n",
    "<br/>\n",
    "\n",
    "<b><font color='darkred'>A caveat to keep in mind though: Since this scaler changes the very distribution of the variables, linear relationships among variables may be destroyed by using this scaler</font></b>. Thus, it is best to use this for non-linear data. Here is the code for using the Quantile Transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "691c77fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Github/ml_courses/env/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:2588: UserWarning: n_quantiles (1000) is greater than the total number of samples (4). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = QuantileTransformer()\n",
    "\n",
    "quantile_normalized_col_names = ['Income_quantile_scaler_norm', 'Age_quantile_scaler_norm']\n",
    "df_scaled[quantile_normalized_col_names] = scaler.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cb5e621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income_quantile_scaler_norm</th>\n",
       "      <th>Age_quantile_scaler_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Income_quantile_scaler_norm  Age_quantile_scaler_norm\n",
       "0   15000   25                     0.666667                  0.333333\n",
       "1    1800   18                     0.000000                  0.000000\n",
       "2  120000   42                     1.000000                  0.666667\n",
       "3   10000   51                     0.333333                  1.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names + quantile_normalized_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe684c",
   "metadata": {},
   "source": [
    "<b>The effects of both the [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler) and the [QuantileTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer) can be seen on a larger dataset instead of one with 4 rows</b>. Thus, I encourage you to take up a larger dataset and try these Scalers on their columns to fully understand the changes to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0faa62a",
   "metadata": {},
   "source": [
    "<a id='sect7'></a>\n",
    "## <font color='darkblue'>Log Transform</font> ([back](#sect0))\n",
    "<b><font size='3ptx'>The Log Transform is one of the most popular Transformation techniques out there. It is primarily used to convert a [skewed distribution](https://www.analyticsvidhya.com/blog/2020/07/what-is-skewness-statistics/?utm_source=blog&utm_medium=Feature_Transformation_and_Scaling_Techniques) to a normal distribution/less-skewed distribution</font></b>. In this transform, we take the log of the values in a column and use these values as the column instead.\n",
    "\n",
    "Why does it work? It is because the log function is equipped to deal with large numbers. Here is an example-\n",
    "1. log(10) = 1\n",
    "2. log(100) = 2, and\n",
    "3. log(10000) = 4.\n",
    "<br/>\n",
    "\n",
    "Thus, in our example, while plotting the histogram of Income, it ranges from 0 to 1,20,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2ea09eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX2UlEQVR4nO3df5Dcd33f8eer8g8cHSPLiFxVSbHkqafBoGJbOzIMTNmjIJ9dak1mPBNpFEciaK5DEEmIaSuXiZ0aZmrzo0kYHOwbogoyoIMAJqqsxlGBq5OhNpKI6rMMsg9ZDbo6FliOyBkNzpl3/9iPYO/Y03f3bndP+/28HjM79/1+vp/vfj/v+9y9bu+7391VRGBmZvn4Jws9ADMz6y4Hv5lZZhz8ZmaZcfCbmWXGwW9mlpmLFnoAjSxbtixWr15d2O/FF19k8eLFnR9Ql5SpnjLVAuWqp0y1QLnqmU8thw8f/kFEvLqZvhdk8K9evZpDhw4V9hsdHaVarXZ+QF1SpnrKVAuUq54y1QLlqmc+tUj6v8329akeM7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDJTGPySVkn6uqQnJR2V9NsN+kjSxyWNS3pc0vV127ZKejrdtra7ADMza00z1/FPAbdHxLckvRI4LOlARDxZ1+cm4Op0uwH4JHCDpCuAu4AKEGnfvRHxQlurMDOzphU+4o+IZyPiW2n5H4BvAytmdNsIfCZqHgUul7QcuBE4EBGnU9gfAAbbWoGZmbWkpVfuSloNXAc8NmPTCuB7desnU9ts7Y3uewgYAujv72d0dLRwPJOTkz/Xb2ziTOF+nbB2xZJ530ejenpVmWqBctVTplqgXPV0q5amg19SH/Al4Hci4oftHkhEDAPDAJVKJZp52XKjlzdv2/lQu4fWlBNbqoV9ivil5xeuMtVTplqgXPV0q5amruqRdDG10P9sRHy5QZcJYFXd+srUNlu7mZktkGau6hHwJ8C3I+K/ztJtL/Dr6eqeNwBnIuJZ4GFgg6SlkpYCG1KbmZktkGZO9bwJuA0Yk3Qktf0n4JcAIuJ+YD9wMzAO/Ah4Z9p2WtIHgYNpv7sj4nTbRm9mZi0rDP6I+GtABX0CeM8s23YBu+Y0OjMzazu/ctfMLDMOfjOzzDj4zcwy4+A3M8uMg9/MLDMOfjOzzDj4zcwy4+A3M8uMg9/MLDMOfjOzzDj4zcwy4+A3M8uMg9/MLDMOfjOzzDj4zcwy4+A3M8tM4QexSNoFvAM4FRGva7D93wNb6u7vNcCr06dvnQD+AXgZmIqISrsGbmZmc9PMI/7dwOBsGyPiIxFxbURcC9wB/K8ZH684kLY79M3MLgCFwR8RjwDNfk7uZmDPvEZkZmYd1bZz/JJ+gdp/Bl+qaw7gLyUdljTUrmOZmdncqfY56QWdpNXAvkbn+Ov6/CrwaxHxb+vaVkTEhKRfBA4A703/QTTafwgYAujv7183MjJSOK7JyUn6+vqmtY1NnCncrxPWrlgy7/toVE+vKlMtUK56ylQLlKue+dQyMDBwuNlT6oVP7rZgEzNO80TERPp6StKDwHqgYfBHxDAwDFCpVKJarRYecHR0lJn9tu18qPWRt8GJLdXCPkUa1dOrylQLlKueMtUC5aqnW7W05VSPpCXAW4A/r2tbLOmV55aBDcAT7TiemZnNXTOXc+4BqsAySSeBu4CLASLi/tTtV4C/jIgX63btBx6UdO44n4uIv2jf0M3MbC4Kgz8iNjfRZze1yz7r244Dr5/rwMzMrDP8yl0zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8wUBr+kXZJOSWr4ebmSqpLOSDqSbnfWbRuUdEzSuKSd7Ry4mZnNTTOP+HcDgwV9/ioirk23uwEkLQLuA24CrgE2S7pmPoM1M7P5Kwz+iHgEOD2H+14PjEfE8Yh4CRgBNs7hfszMrI0UEcWdpNXAvoh4XYNtVeBLwEng/wHvj4ijkm4FBiNie+p3G3BDROyY5RhDwBBAf3//upGRkcJxTU5O0tfXN61tbOJM4X6dsHbFknnfR6N6elWZaoFy1VOmWqBc9cynloGBgcMRUWmm70VzOsJ03wKujIhJSTcDXwGubvVOImIYGAaoVCpRrVYL9xkdHWVmv207H2r10G1xYku1sE+RRvX0qjLVAuWqp0y1QLnq6VYt876qJyJ+GBGTaXk/cLGkZcAEsKqu68rUZmZmC2jewS/pn0pSWl6f7vN54CBwtaQ1ki4BNgF753s8MzObn8JTPZL2AFVgmaSTwF3AxQARcT9wK/BuSVPAWWBT1J44mJK0A3gYWATsioijHanCzMyaVhj8EbG5YPsngE/Msm0/sH9uQzMzs07wK3fNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDJTGPySdkk6JemJWbZvkfS4pDFJ35D0+rptJ1L7EUmH2jlwMzObm2Ye8e8GBs+z/RngLRGxFvggMDxj+0BEXBsRlbkN0czM2qmZz9x9RNLq82z/Rt3qo8DKNozLzMw6RBFR3KkW/Psi4nUF/d4P/HJEbE/rzwAvAAE8EBEz/xuo33cIGALo7+9fNzIyUjiuyclJ+vr6prWNTZwp3K8T1q5YMu/7aFRPrypTLVCuespUC5SrnvnUMjAwcLjZMyuFj/ibJWkAeBfw5rrmN0fEhKRfBA5I+k5EPNJo//RHYRigUqlEtVotPObo6Cgz+23b+dCcxj9fJ7ZUC/sUaVRPrypTLVCuespUC5Srnm7V0pareiT9S+BTwMaIeP5ce0RMpK+ngAeB9e04npmZzd28g1/SLwFfBm6LiKfq2hdLeuW5ZWAD0PDKIDMz657CUz2S9gBVYJmkk8BdwMUAEXE/cCfwKuCPJQFMpfNM/cCDqe0i4HMR8RcdqMHMzFrQzFU9mwu2bwe2N2g/Drz+5/cwM7OF5FfumpllxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llpqngl7RL0ilJDT8zVzUflzQu6XFJ19dt2yrp6XTb2q6Bm5nZ3DT7iH83MHie7TcBV6fbEPBJAElXUPuM3huA9cBdkpbOdbBmZjZ/TQV/RDwCnD5Pl43AZ6LmUeByScuBG4EDEXE6Il4ADnD+PyBmZtZhiojmOkqrgX0R8boG2/YB90TEX6f1rwL/EagCr4iID6X23wPORsRHG9zHELX/Fujv7183MjJSOKbJyUn6+vqmtY1NnGmqngtR/2Xw3NnW91u7Ykn7BzNPjeaml5WpnjLVAp2pZ6FyZM2SRXOuZWBg4HBEVJrpe9GcjtABETEMDANUKpWoVquF+4yOjjKz37adD3VgdN1x+9opPjbW+pSc2FJt/2DmqdHc9LIy1VOmWqAz9SxUjuweXNyVuWnXVT0TwKq69ZWpbbZ2MzNbIO0K/r3Ar6ere94AnImIZ4GHgQ2SlqYndTekNjMzWyBNnVeQtIfa+fplkk5Su1LnYoCIuB/YD9wMjAM/At6Ztp2W9EHgYLqruyPifE8Sm5lZhzUV/BGxuWB7AO+ZZdsuYFfrQzMzs07wK3fNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLTVPBLGpR0TNK4pJ0Ntv+BpCPp9pSkv6/b9nLdtr1tHLuZmc1B4UcvSloE3Ae8HTgJHJS0NyKePNcnIt5X1/+9wHV1d3E2Iq5t24jNzGxemnnEvx4Yj4jjEfESMAJsPE//zcCedgzOzMzaT7XPST9PB+lWYDAitqf124AbImJHg75XAo8CKyPi5dQ2BRwBpoB7IuIrsxxnCBgC6O/vXzcyMlI4+MnJSfr6+qa1jU2cKdzvQtV/GTx3tvX91q5Y0v7BzFOjuellZaqnTLVAZ+pZqBxZs2TRnGsZGBg4HBGVZvoWnupp0Sbgi+dCP7kyIiYkXQV8TdJYRHx35o4RMQwMA1QqlahWq4UHGx0dZWa/bTsfmvvoF9jta6f42FjrU3JiS7X9g5mnRnPTy8pUT5lqgc7Us1A5sntwcVfmpplTPRPAqrr1lamtkU3MOM0TERPp63FglOnn/83MrMuaCf6DwNWS1ki6hFq4/9zVOZJ+GVgK/O+6tqWSLk3Ly4A3AU/O3NfMzLqn8LxCRExJ2gE8DCwCdkXEUUl3A4ci4twfgU3ASEx/0uA1wAOSfkLtj8w99VcDmZlZ9zV1Qjki9gP7Z7TdOWP99xvs9w1g7TzGZ2ZmbeZX7pqZZcbBb2aWGQe/mVlmHPxmZplx8JuZZcbBb2aWGQe/mVlmHPxmZplx8JuZZcbBb2aWGQe/mVlmHPxmZplx8JuZZcbBb2aWGQe/mVlmHPxmZplx8JuZZaap4Jc0KOmYpHFJOxts3ybp+5KOpNv2um1bJT2dblvbOXgzM2td4UcvSloE3Ae8HTgJHJS0t8Fn534+InbM2PcK4C6gAgRwOO37QltGb2ZmLWvmEf96YDwijkfES8AIsLHJ+78ROBARp1PYHwAG5zZUMzNrB0XE+TtItwKDEbE9rd8G3FD/6F7SNuC/AN8HngLeFxHfk/R+4BUR8aHU7/eAsxHx0QbHGQKGAPr7+9eNjIwUDn5ycpK+vr5pbWMTZwr3u1D1XwbPnW19v7UrlrR/MPPUaG56WZnqKVMt0Jl6FipH1ixZNOdaBgYGDkdEpZm+had6mvTfgT0R8WNJ/w74NPDWVu4gIoaBYYBKpRLVarVwn9HRUWb227bzoVYOe0G5fe0UHxtrfUpObKm2fzDz1GhuelmZ6ilTLdCZehYqR3YPLu7K3DRzqmcCWFW3vjK1/VREPB8RP06rnwLWNbuvmZl1VzPBfxC4WtIaSZcAm4C99R0kLa9bvQX4dlp+GNggaamkpcCG1GZmZguk8LxCRExJ2kEtsBcBuyLiqKS7gUMRsRf4LUm3AFPAaWBb2ve0pA9S++MBcHdEnO5AHWZm1qSmTihHxH5g/4y2O+uW7wDumGXfXcCueYzRzMzayK/cNTPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLTFPBL2lQ0jFJ45J2Ntj+u5KelPS4pK9KurJu28uSjqTb3pn7mplZdxV+9KKkRcB9wNuBk8BBSXsj4sm6bn8DVCLiR5LeDXwY+NW07WxEXNveYZuZ2Vw184h/PTAeEccj4iVgBNhY3yEivh4RP0qrjwIr2ztMMzNrF0XE+TtItwKDEbE9rd8G3BARO2bp/wng7yLiQ2l9CjgCTAH3RMRXZtlvCBgC6O/vXzcyMlI4+MnJSfr6+qa1jU2cKdzvQtV/GTx3tvX91q5Y0v7BzFOjuellZaqnTLVAZ+pZqBxZs2TRnGsZGBg4HBGVZvoWnupphaRfAyrAW+qar4yICUlXAV+TNBYR3525b0QMA8MAlUolqtVq4fFGR0eZ2W/bzofmPP6FdvvaKT421vqUnNhSbf9g5qnR3PSyMtVTplqgM/UsVI7sHlzclblp5lTPBLCqbn1laptG0tuADwC3RMSPz7VHxET6ehwYBa6bx3jNzGyemgn+g8DVktZIugTYBEy7OkfSdcAD1EL/VF37UkmXpuVlwJuA+ieFzcysywrPK0TElKQdwMPAImBXRByVdDdwKCL2Ah8B+oA/kwTwtxFxC/Aa4AFJP6H2R+aeGVcDmZlZlzV1Qjki9gP7Z7TdWbf8tln2+wawdj4DNDOz9vIrd83MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMtNU8EsalHRM0riknQ22Xyrp82n7Y5JW1227I7Ufk3RjG8duZmZzUBj8khYB9wE3AdcAmyVdM6Pbu4AXIuKfA38A3Jv2vYbah7O/FhgE/jjdn5mZLZBmHvGvB8Yj4nhEvASMABtn9NkIfDotfxH416p96vpGYCQifhwRzwDj6f7MzGyBNPNh6yuA79WtnwRumK1PRExJOgO8KrU/OmPfFY0OImkIGEqrk5KONTG2ZcAPmujXE35rjvXo3g4MZv5KNTeUq54y1QIlqmfg3nnVcmWzHZsJ/q6IiGFguJV9JB2KiEqHhtR1ZaqnTLVAueopUy1Qrnq6VUszp3omgFV16ytTW8M+ki4ClgDPN7mvmZl1UTPBfxC4WtIaSZdQe7J274w+e4GtaflW4GsREal9U7rqZw1wNfDN9gzdzMzmovBUTzpnvwN4GFgE7IqIo5LuBg5FxF7gT4A/lTQOnKb2x4HU7wvAk8AU8J6IeLmN42/p1FAPKFM9ZaoFylVPmWqBctXTlVpUe2BuZma58Ct3zcwy4+A3M8tMzwZ/0dtILBRJqyR9XdKTko5K+u3UfoWkA5KeTl+XpnZJ+niq43FJ19fd19bU/2lJW+va10kaS/t8PL1YrpM1LZL0N5L2pfU16a05xtNbdVyS2lt+645uz6OkyyV9UdJ3JH1b0ht7dW4kvS/9jD0haY+kV/TS3EjaJemUpCfq2jo+F7MdowO1fCT9nD0u6UFJl9dta+l7Ppd5Pa+I6LkbtSeZvwtcBVwC/B/gmoUeVxrbcuD6tPxK4Clqb3XxYWBnat8J3JuWbwb+ByDgDcBjqf0K4Hj6ujQtL03bvpn6Ku17U4dr+l3gc8C+tP4FYFNavh94d1r+TeD+tLwJ+HxavibN0aXAmjR3ixZiHqm9wnx7Wr4EuLwX54baCyGfAS6rm5NtvTQ3wL8CrgeeqGvr+FzMdowO1LIBuCgt31tXS8vf81bntXC8nfwl69QNeCPwcN36HcAdCz2uWcb658DbgWPA8tS2HDiWlh8ANtf1P5a2bwYeqGt/ILUtB75T1z6tXwfGvxL4KvBWYF/6JfpB3Q/0T+eC2pVfb0zLF6V+mjk/5/p1ex6pvb7kGdJFDTO/5700N/zs1fJXpO/1PuDGXpsbYDXTw7LjczHbMdpdy4xtvwJ8ttH3suh7PpffuaKx9uqpnkZvI9HwrSAWUvq36zrgMaA/Ip5Nm/4O6E/Ls9VyvvaTDdo75Q+B/wD8JK2/Cvj7iJhqcPxpb90B1L91Rys1dsoa4PvAf1Pt1NWnJC2mB+cmIiaAjwJ/CzxL7Xt9mN6dm3O6MRezHaOTfoPafx3Qei1z+Z07r14N/guepD7gS8DvRMQP67dF7c/zBX8draR3AKci4vBCj6VNLqL27/gnI+I64EVq/+r/VA/NzVJqb4K4BvhnwGJq74BbGt2Yi24cQ9IHqL2O6bOdPE4rejX4L+i3gpB0MbXQ/2xEfDk1Pydpedq+HDiV2mer5XztKxu0d8KbgFsknaD2rqxvBf4IuFy1t+aYefxW37qj2/N4EjgZEY+l9S9S+0PQi3PzNuCZiPh+RPwj8GVq89Wrc3NON+ZitmO0naRtwDuALemPDAVjbtT+PK3P6/l14vxjp2/UHrkdp/Zo59yTIK9d6HGlsQn4DPCHM9o/wvQnlD6clv8N05+0+mZqv4La+eil6fYMcEXaNvNJq5u7UFeVnz25+2dMf6LpN9Pye5j+RNMX0vJrmf5k1nFqT2R1fR6BvwL+RVr+/TQvPTc31N4h9yjwC+lYnwbe22tzw8+f4+/4XMx2jA7UMkjtXQtePaNfy9/zVue1cKyd/CXr5I3as/xPUXsW/AMLPZ66cb2Z2r+OjwNH0u1maufdvgo8DfzPuh9OUfugm+8CY0Cl7r5+g9pnGIwD76xrrwBPpH0+QRNP5rShrio/C/6r0i/VePqBvDS1vyKtj6ftV9Xt/4E03mPUXenS7XkErgUOpfn5SgqLnpwb4D8D30nH+9MUJD0zN8Aeas9P/CO1/8be1Y25mO0YHahlnNr59yPpdv9cv+dzmdfz3fyWDWZmmenVc/xmZjZHDn4zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMvP/ARxau6ZeNjuNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Income'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e810334",
   "metadata": {},
   "source": [
    "Let us see what happens when we apply log on this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb54282c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>log_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>15000</td>\n",
       "      <td>9.615805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1800</td>\n",
       "      <td>7.495542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>120000</td>\n",
       "      <td>11.695247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>10000</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Income  log_income\n",
       "0   25   15000    9.615805\n",
       "1   18    1800    7.495542\n",
       "2   42  120000   11.695247\n",
       "3   51   10000    9.210340"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled['log_income'] = np.log(df['Income'])\n",
    "df_scaled[['Age', 'Income', 'log_income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae31400",
   "metadata": {},
   "source": [
    "Wow! While our Income column had extreme values ranging from 1800 to 1,20,000 – the log values are now ranging from approximately 7.5 to 11.7! Thus, the log operation had a dual role:\n",
    "* Reducing the impact of too-low values\n",
    "* Reducing the impact of too-high values.\n",
    "<br/>\n",
    "\n",
    "<b><font color='darkred'>A small caveat though – if our data has negative values or values ranging from 0 to 1, we cannot apply log transform directly</font></b> – since the log of negative numbers and numbers between 0 and 1 is undefined, we would get error or NaN values in our data. <b>In such cases, we can add a number to these values to make them all greater than 1. Then, we can apply the log transform.</b>\n",
    "\n",
    "Let us plot a histogram of the above, using 5 bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e28a96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_scaled['log_income'].plot.hist(bins = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610384bd",
   "metadata": {},
   "source": [
    "<a id='sect8'></a>\n",
    "## <font color='darkblue'>Power Transformer Scaler</font> ([back](#sect0))\n",
    "<b><font size='3ptx'>I often use this feature transformation technique when I am building a linear model</font>. To be more specific, I use it when I am dealing with [heteroskedasticity](https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/?utm_source=blog&utm_medium=Feature_Transformation_and_Scaling_Techniques).</b> Like some other scalers we studied above, <b><font color='darkred'>the [PowerTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer) also changes the distribution of the variable, as in, it makes it more Gaussian (normal)</font></b>. We are familiar with similar power transforms such as square root, and cube root transforms, and log transforms.\n",
    "\n",
    "However, to use them, we need to first study the original distribution, and then make a choice. The [**PowerTransformer**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer) actually automates this decision making by introducing a parameter called `lambda`. It decides on a generalized power transform by finding the best value of lambda using either the:\n",
    "1. [Box-Cox transform](https://en.wikipedia.org/wiki/Box%E2%80%93Cox_distribution)\n",
    "2. [The Yeo-Johnson transform](https://www.wikidata.org/wiki/Q22670426)\n",
    "<br/>\n",
    "\n",
    "While I will not get into too much detail of how each of the above transforms works, <b>it is helpful to know that Box-Cox works with only positive values, while Yeo-Johnson works with both positive and negative values</b>.\n",
    "\n",
    "In our case, we will use the Box-Cox transform since all our values are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebf79f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = PowerTransformer(method = 'box-cox')\n",
    "'''\n",
    "parameters:\n",
    "method = 'box-cox' or 'yeo-johnson'\n",
    "'''\n",
    "\n",
    "boxcox_normalized_col_names = ['Income_boxcox_norm', 'Age_boxcox_norm']\n",
    "df_scaled[boxcox_normalized_col_names] = scaler.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fad3c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income_boxcox_norm</th>\n",
       "      <th>Age_boxcox_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.125158</td>\n",
       "      <td>-0.597385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.395497</td>\n",
       "      <td>-1.301984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>1.419403</td>\n",
       "      <td>0.681202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.149064</td>\n",
       "      <td>1.218168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Income_boxcox_norm  Age_boxcox_norm\n",
       "0   15000   25            0.125158        -0.597385\n",
       "1    1800   18           -1.395497        -1.301984\n",
       "2  120000   42            1.419403         0.681202\n",
       "3   10000   51           -0.149064         1.218168"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names + boxcox_normalized_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2514a74",
   "metadata": {},
   "source": [
    "<a id='sect9'></a>\n",
    "## <font color='darkblue'>Unit Vector Scaler/Normalizer</font>\n",
    "<b><font size='3ptx'>Normalization is the process of scaling individual samples to have unit norm</font>. The most interesting part is that unlike the other scalers which work on the individual column values, the Normalizer works on the rows</b>! Each row of the dataframe with at least one non-zero component is rescaled independently of other samples so that its norm (l1, l2, or inf) equals one.\n",
    "\n",
    "Just like MinMax Scaler, the Normalizer also converts the values between 0 and 1, and between -1 to 1 when there are negative values in our data.\n",
    "\n",
    "However, there is a difference in the way it does so.\n",
    "* **If we are using L1 norm**, the values in each column are converted so that the sum of their absolute values along the row = 1\n",
    "* **If we are using L2 norm**, the values in each column are first squared and added so that the sum of their absolute values along the row = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f122cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer(norm = 'l2')\n",
    "# norm = 'l2' is default\n",
    "\n",
    "l2_normalized_col_names = ['Income_l2_norm', 'Age_l2_norm']\n",
    "df_scaled[l2_normalized_col_names] = scaler.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e4640ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income_l2_norm</th>\n",
       "      <th>Age_l2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Income_l2_norm  Age_l2_norm\n",
       "0   15000   25        0.999999     0.001667\n",
       "1    1800   18        0.999950     0.010000\n",
       "2  120000   42        1.000000     0.000350\n",
       "3   10000   51        0.999987     0.005100"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names + l2_normalized_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6dd42a",
   "metadata": {},
   "source": [
    "Thus, if you check the first row,\n",
    "> $(.999999)^2 + (0.001667)^2 = 1.000$ (approx)\n",
    "<br/>\n",
    "\n",
    "Similarly, you can check for all rows, and try out the above with norm = ‘l1’ as well.\n",
    "\n",
    "You may refer to this article to understand the difference between Normalization and Standard Scaler – [Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/?utm_source=blog&utm_medium=types_of_scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffafb3a9",
   "metadata": {},
   "source": [
    "<a id='sect10'></a>\n",
    "## <font color='darkblue'>Custom Transformer</font> ([back](#sect0))\n",
    "<b><font size='3ptx'>Consider this situation – Suppose you have your own Python function to transform the data. Sklearn also provides the ability to apply this transform to our dataset using what is called a [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer).</font></b>\n",
    "\n",
    "Let us take a simple example. I have a feature transformation technique that involves taking (<font color='brown'>log to the base 2</font>) of the values. In NumPy, there is a function called log2 which does that for us.\n",
    "\n",
    "Thus, we can now apply the [**FunctionTransformer**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6538f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FunctionTransformer(np.log2, validate = True)\n",
    "\n",
    "log2_transformed_col_names = ['Income_log2_transform', 'Age_log2_transform']\n",
    "df_scaled[log2_transformed_col_names] = transformer.transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "021f8f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income_log2_transform</th>\n",
       "      <th>Age_log2_transform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>13.872675</td>\n",
       "      <td>4.643856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>10.813781</td>\n",
       "      <td>4.169925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>16.872675</td>\n",
       "      <td>5.392317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>13.287712</td>\n",
       "      <td>5.672425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Income_log2_transform  Age_log2_transform\n",
       "0   15000   25              13.872675            4.643856\n",
       "1    1800   18              10.813781            4.169925\n",
       "2  120000   42              16.872675            5.392317\n",
       "3   10000   51              13.287712            5.672425"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names + log2_transformed_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe9744",
   "metadata": {},
   "source": [
    "Each feature scaling technique has its own characteristics which we can leverage to improve our model. However, just like other steps in building a predictive model, <b>choosing the right scaler is also a trial and error process, and there is no single best scaler that works every time</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030c651",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Supplement</font>\n",
    "* [iT 邦幫忙 - Day-10 Feature Engineering -- 3. Variable transformation 變數轉換(2)](https://ithelp.ithome.com.tw/articles/10235219)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
