{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8dd7486-109e-47af-b4ca-bc06babc7dc3",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([source](https://www.analyticsvidhya.com/blog/2025/01/prompting-with-dspy/)) <font size='3ptx'><b>[DSPy](https://dspy.ai/) (Declarative Self-improving Python), or Declarative Self-improving Language Programs, revolutionizes how developers interact with Large Language Models (LLMs)</b>. By abstracting the intricacies of prompt engineering, it enables users to develop, test, and improve their apps more effectively and dependably.</font>\n",
    "\n",
    "This comprehensive tutorial delves deeply into DSPy, offering thorough insights to assist you in getting started and creating potent AI-powered apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fdd3f654-0d23-4837-90df-a66eaffa1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import dspy\n",
    "\n",
    "# Expand the '~' to the user's home directory path\n",
    "home_directory = os.path.expanduser('~')\n",
    "\n",
    "# Construct the full path to your .env file\n",
    "dotenv_path = os.path.join(home_directory, '.env')\n",
    "\n",
    "# Load the environment variables from the specified path\n",
    "load_dotenv(dotenv_path)\n",
    "API_KEY = os.environ.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e65dec7-712a-4b58-849d-cbafb82c1a4a",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Learning Objectives</font></b>\n",
    "* Understand DSPy’s declarative approach for simplifying language model application development.\n",
    "* Learn how DSPy automates prompt engineering and optimizes performance for complex tasks.\n",
    "* Explore practical examples of DSPy in action, such as math problem-solving and [sentiment analysis](https://www.analyticsvidhya.com/blog/2021/06/nlp-sentiment-analysis/).\n",
    "* Discover the advantages of DSPy, including modularity, scalability, and continuous self-improvement.\n",
    "* Gain insights into integrating DSPy into existing systems and optimizing LLM-powered workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3edd4-a5e4-48aa-9ef0-866c712efd77",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Background</font></b>\n",
    "In the traditional approach, we manually construct the prompt string, manage the API key configuration directly in the logic, and parse the unstructured text response to do Sentimental analysis. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0b96f58f-90de-4bc4-8a7d-90bf35527a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-generativeai==0.8.5\n"
     ]
    }
   ],
   "source": [
    "#!pip install google-generativeai\n",
    "!pip freeze | grep 'google-generativeai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8b53e09f-5964-49cc-8b5a-f83025285d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# 1. Setup (Vendor specific)\n",
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "37947fe2-6052-4293-9122-ca632c1d6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Result: Positive\n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment_manual(text):\n",
    "    # 2. Manual Prompt Engineering (String manipulation)\n",
    "    prompt = f\"\"\"\n",
    "    You are a sentiment classifier. \n",
    "    Analyze the following text and output ONLY one of these labels: Positive, Negative, Neutral.\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    Label:\n",
    "    \"\"\"\n",
    "\n",
    "    # 3. Call the API\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    # 4. Manual Parsing (Cleaning whitespace, handling potential markdown)\n",
    "    return response.text.strip()\n",
    "\n",
    "# Run it\n",
    "sentence = \"I got a perfect score and feel happy!\"\n",
    "print(f\"Manual Result: {analyze_sentiment_manual(sentence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96689c6-50d2-4e09-adb7-fe77bd528ab2",
   "metadata": {},
   "source": [
    "In DSPy, the code looks nearly identical to the `analyze_sentiment_manual` version. You only change the `lm` definition. <b>DSPy handles the prompt structure, meaning you don't write \"You are a classifier...\" text</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "257035b9-f21c-4806-a860-cd5fbdca3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# 1. Setup (Unified interface)\n",
    "# We tell DSPy to use Gemini. The syntax is \"provider/model_name\"\n",
    "lm = dspy.LM(\"gemini/gemini-2.5-flash\", api_key=API_KEY)\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6bd76284-83c6-4ff0-bb0a-0c1d91d9caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the Signature (Declarative Logic)\n",
    "# Notice: No prompt engineering here. Just inputs and outputs.\n",
    "class SentimentAnalysis(dspy.Signature):\n",
    "    sentence = dspy.InputField()\n",
    "    sentiment = dspy.OutputField(desc=\"Positive, Negative, or Neutral\")\n",
    "    reason=dspy.OutputField(desc=\"The judging reason.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9cfe7ba4-66c4-4ce3-9851-b62ac20c4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the Module\n",
    "# dspy.Predict compiles the prompt for Gemini automatically\n",
    "classifier = dspy.Predict(SentimentAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "73456afe-94e1-47da-8bd2-9f242a7db908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy Result:   Positive (The sentence contains two strong indicators of positive sentiment: \"perfect score\" which signifies a great achievement, and \"feel happy!\" which is an explicit declaration of a positive emotion.)\n"
     ]
    }
   ],
   "source": [
    "# 4. Run it (Structured Object In -> Structured Object Out)\n",
    "response = classifier(sentence=sentence)\n",
    "\n",
    "print(f\"DSPy Result:   {response.sentiment} ({response.reason})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8eaf8-a618-4bbc-8dc0-430861b313db",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>What is DSPy?</font></b>\n",
    "<font size='3ptx'><b>[DSPy](https://dspy.ai/) is a framework designed to simplify the development of language model-powered applications</b>. It introduces a declarative approach where users specify what they want the model to do without getting bogged down in the implementation details.</font>\n",
    "\n",
    "Here are the core components of DSPy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a1035-bada-4dd1-b71a-7314432e194d",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Key Components of DSPy</font></b>\n",
    "* <b><font size='3ptx'>[Signatures](https://dspy.ai/learn/programming/signatures/)</font></b>: Declarative specifications known as signatures specify how a DSPy module should behave both in terms of input and output. For instance, “`question -> answer`” could be a signature for a task that requires answering questions. Signatures make it easier to specify exactly what the model is supposed to do.\n",
    "* <b><font size='3ptx'>[Modules](https://dspy.ai/learn/programming/modules/)</font></b>: Within an LLM pipeline, modules abstract standard prompting mechanisms. Every built-in module manages a distinct DSPy signature and prompting method. Building complicated LLM applications is made easier by the ability to combine modules to form larger, more intricate modules.\n",
    "* <b><font size='3ptx'>[Optimizers](https://dspy.ai/learn/optimization/overview/)</font></b>: Optimizers modify a DSPy program’s parameters, such as language model weights and prompts, to improve predetermined metrics, such as accuracy. <b>Developers can concentrate on higher-level program logic since this automation eliminates the need for manual prompt engineering</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be8160-d743-4a6c-9652-206f85b1e21b",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>How DSPy Works?</font></b>\n",
    "<font size='3ptx'><b>DSPy is a framework that helps simplify the creation of workflows by using modular components and a declarative programming style.</b> It automates many aspects of workflow design, optimization, and execution, allowing users to focus on defining their goals rather than the implementation details.</font>\n",
    "\n",
    "Below is a detailed explanation of how DSPy works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d1655-1e23-48d0-822e-9ae9075aec58",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Task Definition</font></b>\n",
    "* <b><font size='3ptx'>Objective Specification</font></b>: Clearly define the task you aim to accomplish, such as text summarization, question answering, or sentiment analysis.\n",
    "* <b><font size='3ptx'>Performance Metrics</font></b>: Establish criteria to evaluate the success of the task, like accuracy, relevance, or response time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e4042-3a4f-4cc6-aa51-09028f5a49ee",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Data Collection</font></b>\n",
    "* <b><font size='3ptx'>Example Gathering</font></b>: Collect input examples pertinent to the task. These can be labeled (with expected outputs) or unlabeled, depending on the requirements.\n",
    "* <b><font size='3ptx'>Dataset Preparation</font></b>: Organize the collected data into a structured format suitable for processing within DSPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f9aa7-4c77-44eb-92bc-330777fe22a7",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Pipeline Construction</font></b>\n",
    "* <b><font size='3ptx'>[Module](https://dspy.ai/learn/programming/modules/) Selection</font></b>: Choose from DSPy’s built-in modules that correspond to various natural language processing tasks.\n",
    "* <b><font size='3ptx'>[Signature](https://dspy.ai/learn/programming/signatures/) Definition</font></b>: Define the input and output types for each module using signatures, ensuring compatibility and clarity in data flow.\n",
    "* <b><font size='3ptx'>Pipeline Assembly</font></b>: Arrange the selected modules into a coherent pipeline that processes inputs to produce the desired outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f05d5-b6fa-468c-beee-a1389e756f9b",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Optimization</font></b>\n",
    "* <b><font size='3ptx'>Prompt Refinement</font></b>: Utilize DSPy’s [**optimizers**](https://dspy.ai/learn/optimization/overview/) to automatically refine prompts and adjust parameters, enhancing the performance of each module.\n",
    "* <b><font size='3ptx'>Few-Shot Example Generation</font></b>: Leverage in-context learning to generate examples that improve the model’s understanding and output quality.\n",
    "* <b><font size='3ptx'>Self-Improvement</font></b>: Enable the pipeline to learn from its outputs and feedback, continuously improving performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa7312b-ef5c-458b-8031-f1ea3ac988a4",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Compilation and Execution</font></b>\n",
    "* <b><font size='3ptx'>Code Generation</font></b>: Compile the optimized pipeline into executable Python code, facilitating seamless integration into applications.\n",
    "* <b><font size='3ptx'>Deployment</font></b>: Deploy the compiled pipeline within your application’s environment to perform the specified tasks.\n",
    "* <b><font size='3ptx'>Evaluation</font></b>: Assess the pipeline’s performance using the predefined metrics, ensuring it meets the desired standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843049c-36b4-4dd9-9492-1d2e18b3aded",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Iteration</font></b>\n",
    "* <b><font size='3ptx'>Feedback Incorporation</font></b>: Analyze performance evaluations to identify areas for improvement.\n",
    "* <b><font size='3ptx'>Pipeline Refinement</font></b>: Iteratively refine the pipeline by revisiting previous steps, such as adjusting modules, updating data, or modifying optimization parameters, to achieve better results.\n",
    "\n",
    "![idea](https://cdn.analyticsvidhya.com/wp-content/uploads/2025/01/dspy.webp)\n",
    "Source: [Click Here](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6dd1229a-71ea-41f7-af23-091ce219bce4_1908x1070.png)\n",
    "\n",
    "By following this structured workflow, DSPy facilitates the development of robust, efficient, and adaptable language model applications. <b>It allows developers to <font size='4ptx'>concentrate on defining tasks and metrics</font> while the framework handles the intricacies of optimization and execution.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd988c7-feb6-4eb6-a056-45c28fd238b5",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>How DSPy Automates Prompt Engineering?</font></b>\n",
    "<b><font size='3ptx'>DSPy uses an optimization technique that views [prompt engineering](https://www.analyticsvidhya.com/blog/2023/06/what-is-prompt-engineering/) as a [machine learning](https://www.analyticsvidhya.com/machine-learning/) problem rather than creating prompts by hand.</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aff5c1-34c0-4967-af99-66f6bf7ec2f0",
   "metadata": {},
   "source": [
    "This procedure entails:\n",
    "* <b><font size='3ptx'>[Bootstrapping](https://www.datacamp.com/tutorial/bootstrapping)</font></b>: DSPy iteratively improves the initial seed prompt based on user-provided examples or assertions and the model’s outputs.\n",
    "* <b><font size='3ptx'>Prompt chaining</font></b> is dividing difficult jobs into a series of easier sub-prompts so that the model can better handle complex questions.\n",
    "* <b><font size='3ptx'>Combining several prompt variations</font></b> to increase resilience and performance is known as prompt ensembeling.\n",
    "\n",
    "DSPy automates quick engineering procedures, improving their efficacy and efficiency and resulting in more dependable LLM applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1fe4c-c07a-429e-9500-58f7da8772be",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Practical Examples of Prompting with DSPy</font></b>\n",
    "<b><font size='3ptx'>Below we will explore real-world applications of DSPy through practical examples, showcasing how to efficiently handle tasks like sentiment analysis and math problem-solving. </font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b350a5d-1acc-4074-a6b0-019cccef786a",
   "metadata": {},
   "source": [
    "But first we will start with the environment setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da60091-bdda-42b0-a637-bb00851b3cf9",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Install the library</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d9a9c3-68df-41ef-9e7d-31857c9fec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install dspy\n",
    "!pip freeze | grep 'dspy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fcd842-526b-4dac-8d54-f1bebf95858e",
   "metadata": {},
   "source": [
    "Set up the library with your AI model and API key: This initializes dspy for use with your preferred language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e2674c7-d1d7-46b7-8f03-33183e31abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import dspy\n",
    "\n",
    "# Expand the '~' to the user's home directory path\n",
    "home_directory = os.path.expanduser('~')\n",
    "\n",
    "# Construct the full path to your .env file\n",
    "dotenv_path = os.path.join(home_directory, '.env')\n",
    "\n",
    "# Load the environment variables from the specified path\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "\n",
    "API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "lm = dspy.LM(\"gemini/gemini-2.5-flash\", api_key=API_KEY)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117973e-45b2-4f2b-a13f-f7b46b9183c7",
   "metadata": {},
   "source": [
    "Now lets start our practical example and dive deep into it ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55822e-afd5-45f1-900a-2fab98d7f4c0",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Solving Math Problems with Chain of Thought</font></b>\n",
    "* <b><font size='3ptx'>Purpose</font></b>: Solve mathematical problems step-by-step.\n",
    "* <b><font size='3ptx'>Concept</font></b>: Use the [**Chain of Thought**](https://www.datacamp.com/tutorial/chain-of-thought-prompting?utm_cid=19589720824&utm_aid=157098106775&utm_campaign=230119_1-ps-other~dsa-tofu~all_2-b2c_3-apac_4-prc_5-na_6-na_7-le_8-pdsh-go_9-nb-e_10-na_11-na&utm_loc=9197821-&utm_mtd=-c&utm_kw=&utm_source=google&utm_medium=paid_search&utm_content=ps-other~apac-en~dsa~tofu~tutorial~artificial-intelligence&gad_source=1&gad_campaignid=19589720824&gbraid=0AAAAADQ9WsGGLCZqlrmrC_-6OEcO3H_SS&gclid=Cj0KCQiAuvTJBhCwARIsAL6DemgXsrk2FgmnjRCpbssQpbDL7Fq_J2x5P0MGD49NYTnweyRrdSyX7yEaAju5EALw_wcB) (CoT) approach to break down tasks into logical sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829f9430-a4e8-4c38-983a-e7cd8aeb61e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The average distance between Earth and the Sun is approximately 1 Astronomical Unit (AU). One AU is defined as 149.6 million kilometers.',\n",
      "    answer=149600000.0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "math = dspy.ChainOfThought(\"question -> answer: float\")\n",
    "response = math(question=\"What is the distance between Earth and the Sun in kilometers?\")\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf250f0-d3ae-466d-b63e-c2df8cf4a352",
   "metadata": {},
   "source": [
    "#### <b>Explanation:</b>\n",
    "* <b><font size='3ptx'>ChainOfThought</font></b>: This creates a prompt structure for solving problems.\n",
    "  - Input: “`question`” is the math problem.\n",
    "  - Output: “`answer: float`” specifies the expected result type (a floating-point number).\n",
    "* <b><font size='3ptx'>The model interprets the problem logically</font></b>, step-by-step, ensuring an accurate solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efff9a7-0795-4eee-aec9-8a79ba7ba48d",
   "metadata": {},
   "source": [
    "#### <b>Practical Use:</b>\n",
    "* Scientific calculations.\n",
    "* Business analytics requiring precise mathematical reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9e97b-3edc-4001-bd78-9d0d6d430fe9",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Sentiment Analysis</font></b>\n",
    "* <b><font size='3ptx'>Purpose</font></b>: Determine the emotional tone (positive, negative, or neutral) of a given sentence.\n",
    "* <b><font size='3ptx'>Concept</font></b>: Use a Signature to define the input and output fields explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0b7ddf-e6de-4142-871e-ec28920722cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='positive',\n",
       "    confidence=0.99\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "class Classify(dspy.Signature):\n",
    "    \"\"\"Classify sentiment of a given sentence.\"\"\"\n",
    "\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: Literal['positive', 'negative', 'neutral'] = dspy.OutputField()\n",
    "    confidence: float = dspy.OutputField()\n",
    "\n",
    "\n",
    "classify = dspy.Predict(Classify)\n",
    "classify(sentence=\"I love learning new skills!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060ef14-5738-4dd6-986f-c3d80cbab97c",
   "metadata": {},
   "source": [
    "#### <b>Explanation:</b>\n",
    "* <b><font size='3ptx'>Signature</font></b>: A structured template to define:\n",
    "  - Input: sentence (a string containing the text).\n",
    "  - Output:\n",
    "    - `sentiment` (categorical: positive, negative, or neutral).\n",
    "    - `confidence` (a float indicating the model’s certainty in its prediction).\n",
    "* <b><font size='3ptx'>Predict</font></b>: Applies the defined SentimentAnalysis signature to the input sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f367b94-40d4-41b5-8176-2d8973907576",
   "metadata": {},
   "source": [
    "#### <b>Practical Use:</b>\n",
    "* Monitor customer feedback for businesses.\n",
    "* Gauge public opinion on social media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c55be2-fa36-49a4-974f-e6d092c42014",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Spam Detection</font></b>\n",
    "* <b><font size='3ptx'>Purpose</font></b>: Detect whether an email or message is spam.\n",
    "* <b><font size='3ptx'>Concept</font></b>: Use a Signature to classify text into spam or non-spam categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e4a443-433e-48dc-a485-00e9e555e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Spam: True, Confidence: 0.95\n"
     ]
    }
   ],
   "source": [
    "class SpamDetect(dspy.Signature):\n",
    "    \"\"\"Detect if an email is spam.\"\"\"\n",
    "    email: str = dspy.InputField()\n",
    "    is_spam: bool = dspy.OutputField()\n",
    "    confidence: float = dspy.OutputField()\n",
    "\n",
    "spam_detector = dspy.Predict(SpamDetect)\n",
    "response = spam_detector(email=\"Congratulations! You've won a free vacation. Click here to claim!\")\n",
    "print(f\"Is Spam: {response.is_spam}, Confidence: {response.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25660c0a-dc5a-4aa3-83eb-38dc7321b28e",
   "metadata": {},
   "source": [
    "#### <b>Explanation:</b>\n",
    "* <b><font size='3ptx'>Input</font></b>: email field contains the text of the email.\n",
    "* <b><font size='3ptx'>Output</font></b>:\n",
    "  - `is_spam` (boolean indicating whether the email is spam).\n",
    "  - `confidence` (a float showing the certainty of the classification).\n",
    "* <b><font size='3ptx'>Practical Workflow</font></b>: The model detects patterns common in spam messages, such as exaggerated claims or links to unknown websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dcb2e5-90dd-4d58-86e6-e8d9f1dd4796",
   "metadata": {},
   "source": [
    "#### <b>Practical Use:</b>\n",
    "* Email filtering systems.\n",
    "* Protecting users from phishing attempts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139c037-c25f-443d-b989-5a072f323bb2",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>FAQ Automation</fnot></b>\n",
    "* <b><font size='3ptx'>Purpose:</font></b> Answer Frequently Asked Questions (FAQs) using AI.\n",
    "* <b><font size='3ptx'>Concept:</font></b> Define a custom Signature for FAQ inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd6963f0-4e50-43d5-bddd-e22113c5ad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "class FAQ(dspy.Signature):\n",
    "    \"\"\"Answer FAQ queries.\"\"\"\n",
    "    question: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField()\n",
    "\n",
    "faq_handler = dspy.Predict(FAQ)\n",
    "response = faq_handler(question=\"What is the capital of France?\")\n",
    "print(response.answer)  # Output: \"Paris\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dac0e0-5bb3-4cc7-9972-cd52478726d7",
   "metadata": {},
   "source": [
    "#### <b>Explanation:</b>\n",
    "* <b><font size='3ptx'>Input:</font></b> question, containing the FAQ query.\n",
    "* <b><font size='3ptx'>Output:</font></b> answer, providing the AI-generated response.\n",
    "* <b><font size='3ptx'>The model</font></b> retrieves the most relevant information to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ae189-dcb8-4e84-95f0-68e983913acf",
   "metadata": {},
   "source": [
    "#### <b>Practical Use:</b>\n",
    "* Chatbots for customer service.\n",
    "* Automated knowledge bases for websites or applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031fbfa-e455-4d8e-862e-0454e1077f28",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Building AI Applications by Customizing DSPy Modules</font></b>\n",
    "([source](https://dspy.ai/tutorials/custom_module/)) <b><font size='3ptx'>In this guide, we will walk you through how to build a GenAI application by customizing dspy.Module.</font></b>\n",
    "\n",
    "A [**DSPy module**](https://dspy.ai/learn/programming/modules/) is the building block for DSPy programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51533a52-2ca4-4b48-8f39-9e4fe347b264",
   "metadata": {},
   "source": [
    "* Each built-in module abstracts a prompting technique (<font color='brown'>like chain of thought or ReAct</font>). Crucially, they are generalized to handle any signature.\n",
    "* A DSPy module has learnable parameters (<font color='brown'>i.e., the little pieces comprising the prompt and the LM weights</font>) and can be invoked (<font color='brown'>called</font>) to process inputs and return outputs.\n",
    "* Multiple modules can be composed into bigger modules (<font color='brown'>programs</font>). DSPy modules are inspired directly by NN modules in PyTorch, but applied to LM programs.\n",
    "\n",
    "Although you can build a DSPy program without implementing a custom module, we highly recommend putting your logic with a custom module so that you can use other DSPy features, like DSPy optimizer or MLflow DSPy tracing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3611d43-a948-4d97-8935-de16270f1c7c",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Customize DSPy Module</font></b>\n",
    "<b><font size='3ptx'>You can implement custom prompting logic and integrate external tools or services by customizing a [DSPy module](https://dspy.ai/learn/programming/modules/).</font></b>\n",
    "\n",
    "To achieve this, subclass from dspy.Module and implement the following two key methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa67e3-87a1-4490-8747-a174a11c16d2",
   "metadata": {},
   "source": [
    "* `__init__`: This is the constructor, where you define the attributes and sub-modules of your program.\n",
    "* `forward`: This method contains the core logic of your DSPy program.\n",
    "\n",
    "Within the `forward()` method, you are not limited to calling only other DSPy modules; you can also integrate any standard Python functions, such as those for interacting with Langchain/Agno agents, MCP tools, database handlers, and more.\n",
    "\n",
    "The basic structure for a custom DSPy module looks like this:\n",
    "```python\n",
    "class MyProgram(dspy.Module):\n",
    "    \n",
    "    def __init__(self, ...):\n",
    "        # Define attributes and sub-modules here\n",
    "        {constructor_code}\n",
    "\n",
    "    def forward(self, input_name1, input_name2, ...):\n",
    "        # Implement your program's logic here\n",
    "        {custom_logic_code}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2373b7-1dd3-48ec-a0f6-13c3a28c582d",
   "metadata": {},
   "source": [
    "Let's illustrate this with a practical code example. We will build a simple [**Retrieval-Augmented Generation**](https://www.datacamp.com/blog/what-is-retrieval-augmented-generation-rag?utm_cid=19589720824&utm_aid=152984013054&utm_campaign=230119_1-ps-other~dsa-tofu~all_2-b2c_3-apac_4-prc_5-na_6-na_7-le_8-pdsh-go_9-nb-e_10-na_11-na&utm_loc=9197821-&utm_mtd=-c&utm_kw=&utm_source=google&utm_medium=paid_search&utm_content=ps-other~apac-en~dsa~tofu~blog~artificial-intelligence&gad_source=1&gad_campaignid=19589720824&gbraid=0AAAAADQ9WsGGLCZqlrmrC_-6OEcO3H_SS&gclid=Cj0KCQiAuvTJBhCwARIsAL6DemiMqL5H_X7QA_hFp7W2m3GJGfb_T4xGxurWXa8CZmxwInViKTy4ZmYaAstbEALw_wcB) (RAG) application with multiple stages:\n",
    "1. <b><font size='3ptx'>Query Generation</font></b>: Generate a suitable query based on the user's question to retrieve relevant context.\n",
    "2. <b><font size='3ptx'>Context Retrieval</font></b>: Fetch context using the generated query.\n",
    "3. <b><font size='3ptx'>Answer Generation</font></b>: Produce a final answer based on the retrieved context and the original question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef218b-97f1-483d-82b0-8c877249a111",
   "metadata": {},
   "source": [
    "The code implementation for this multi-stage program is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a270fe4a-0bc3-495d-94e7-fbf8da4f1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class QueryGenerator(dspy.Signature):\n",
    "    \"\"\"Generate a query based on question to fetch relevant context\"\"\"\n",
    "    question: str = dspy.InputField()\n",
    "    query: str = dspy.OutputField()\n",
    "\n",
    "def mock_search_wikipedia(query: str) -> list[str]:\n",
    "    \"\"\"Query ColBERT endpoint, which is a knowledge source based on wikipedia data\"\"\"\n",
    "    return [\n",
    "        'Gemini 3 has officially begun its rollout, with the Gemini 3 Pro model entering preview in mid-November 2025 and seeing wider release in December.',\n",
    "        'Two of the most highlighted features of Gemini 3 are \"Deep Think\" and \"Vibe Coding.\"',\n",
    "        'Gemini 3 represents a major pivot from simple chatbots to autonomous agents. It powers a new agentic development platform called Google Antigravity, designed to help developers build AI that can execute multi-step workflows independently.',\n",
    "    ]\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.query_generator = dspy.Predict(QueryGenerator)\n",
    "        self.answer_generator = dspy.ChainOfThought(\"question,context->answer\")\n",
    "\n",
    "    def forward(self, question, **kwargs):\n",
    "        query = self.query_generator(question=question).query\n",
    "        context = '\\n'.join(mock_search_wikipedia(query))\n",
    "        return self.answer_generator(question=question, context=context).answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffed594-07ff-427c-bc3a-7636f41d75be",
   "metadata": {},
   "source": [
    "Let's take a look at the `forward` method. We first send the question to `self.query_generator`, which is a `dspy.Predict`, to get the `query` for context retrieving. Then we use the `query` to call `ColBERT` and keep the first context retrieved. Finally, we send the `question` and `context` into `self.answer_generator`, which is a `dspy.ChainOfThought` to generate the final answer.\n",
    "\n",
    "Next, we'll create an instance of our RAG module to run the program.\n",
    "\n",
    "<b><font color='orange'>Important</font></b>: When invoking a custom DSPy module, you should use the module instance directly (<font color='brown'>which calls the `__call__` method internally</font>), rather than calling the `forward()` method explicitly. The `__call__` method handles necessary internal processing before executing the forward logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad34d91f-5fc3-4a2e-ba9d-a89b55bf4ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini 3 began its official rollout, with the Gemini 3 Pro model entering preview in mid-November 2025 and a wider release in December. Its most highlighted features are \"Deep Think\" and \"Vibe Coding.\" Gemini 3 marks a significant shift from simple chatbots to autonomous agents, and it powers Google Antigravity, a new agentic development platform that helps developers build AI capable of executing multi-step workflows independently.\n"
     ]
    }
   ],
   "source": [
    "rag = RAG()\n",
    "print(rag(question=\"Tell me something about Gemini 3?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbc9e8-1542-4130-943c-1a4010453c0c",
   "metadata": {},
   "source": [
    "That's it! In summary, to build your GenAI applications, we just put the custom logic into the `forward()` method, then create a module instance and call the instance itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c70d9-cdc1-407e-a987-cc0e20b3a391",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Why Customizing Module?</font></b>\n",
    "<font size='3ptx'><b>DSPy is a lightweight authoring and optimization framework, and our focus is to resolve the mess of prompt engineering by transforming prompting</b> (<font color='brown'>string in, string out</font>) <b>LLM into programming LLM</b> (<font color='brown'>structured inputs in, structured outputs out</font>) <b>for robust AI system.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd68d94-feda-4903-a938-4d3b8eb5495a",
   "metadata": {},
   "source": [
    "While we provide pre-built modules which have custom prompting logic like `dspy.ChainOfThought` for reasoning, `dspy.ReAct` for tool calling agent to facilitate building your AI applications, we don't aim at standardizing how you build agents.\n",
    "\n",
    "In DSPy, your application logic simply goes to the `forward` method of your custom Module, which doesn't have any constraint as long as you are writing python code. <b>With this layout, DSPy is easy to migrate to from other frameworks or vanilla SDK usage, and easy to migrate off because essentially it's just python code</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a635b8-6567-40b0-bab4-422c595edc69",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Few-Shot Learning Optimizers Overview</font></b>\n",
    "([source](https://codesignal.com/learn/courses/how-to-optimize-with-dspy/lessons/automatic-few-shot-learning-with-dspy)) <b><font size='3ptx'>Now, we'll dive deeper into the first category: Few-Shot Learning optimizers.</font></b>\n",
    "\n",
    "**As you may recall, [few-shot learning](https://www.promptingguide.ai/techniques/fewshot) is a technique where we provide the language model with examples of the task before asking it to solve a new instance**. This approach helps the model understand what we're asking for and improves its performance. While you could manually select and include examples in your prompts, DSPy's few-shot optimizers automate this process, finding the most effective examples to include."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd125d3-d2f8-47b2-a6b6-2e33a28a3c29",
   "metadata": {},
   "source": [
    "1. <b><font size='3ptx'>[LabeledFewShot](#LabeledFewShot:-Basic-Example-Selection)</font></b>: The simplest approach, which randomly selects examples from your training data.\n",
    "2. <b><font size='3ptx'>[BootstrapFewShot](#BootstrapFewShot:-Self-Generated-Examples)</font></b>: A more advanced approach that generates new examples using your program itself.\n",
    "3. <b><font size='3ptx'>[BootstrapFewShotWithRandomSearch](#BootstrapFewShotWithRandomSearch:-Finding-Optimal-Example-Sets)</font></b>: Extends <b><font color='blue'>BootstrapFewShot</font></b> by exploring multiple sets of examples to find the best combination.\n",
    "4. <b><font size='3ptx'>[KNNFewShot](#KNNFewShot:-Context-Aware-Example-Selection)</font></b>: A retrieval-based approach that selects examples most similar to the current input.\n",
    "\n",
    "Each optimizer has its strengths and is suited for different scenarios. If you have very few examples (<font color='brown'>around 10</font>), <b><font color='blue'>BootstrapFewShot</font></b> is a good starting point. With more data (<font color='brown'>50+ examples</font>), <b><font color='blue'>BootstrapFewShotWithRandomSearch</font></b> can yield better results. <b><font color='blue'>KNNFewShot</font></b> is particularly useful when the relevance of examples varies significantly depending on the input.\n",
    "\n",
    "Let's explore each of these optimizers in detail, with practical examples to help you understand how to implement them in your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506f4de-92f6-4f80-bb3b-55c020b3ccf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>LabeledFewShot: Basic Example Selection</font></b>\n",
    "<font size='3ptx'>The simplest few-shot optimizer in DSPy is [<b>LabeledFewShot</b>](https://dspy.ai/api/optimizers/LabeledFewShot/?h=labeledfewshot).</font>\n",
    "\n",
    "<b>This optimizer takes examples from your training data and includes them in the prompt sent to the language model</b>. It's straightforward but effective, especially when you have high-quality labeled examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a386c0-73d3-4a6e-a80a-0b1a11202261",
   "metadata": {},
   "source": [
    "Here's how to implement [**LabeledFewShot**](https://dspy.ai/api/optimizers/LabeledFewShot/?h=labeledfewshot):\n",
    "```python\n",
    "from dspy.teleprompt import LabeledFewShot\n",
    "\n",
    "# Create the optimizer with k=8 (8 examples will be included in each prompt)\n",
    "labeled_fewshot_optimizer = LabeledFewShot(k=8)\n",
    "\n",
    "# Compile your DSPy program with the optimizer\n",
    "your_dspy_program_compiled = labeled_fewshot_optimizer.compile(\n",
    "    student=your_dspy_program, \n",
    "    trainset=trainset\n",
    ")\n",
    "```\n",
    "\n",
    "In this example, we create a [**LabeledFewShot**](https://dspy.ai/api/optimizers/LabeledFewShot/?h=labeledfewshot) optimizer that will include 8 examples in each prompt. The k parameter controls the number of examples, and <b>you can adjust it based on your needs and the context window size of your language model</b>.\n",
    "\n",
    "<b>When you call `compile()`, the optimizer randomly selects `k` examples from your training set and incorporates them into the prompts of your DSPy program.</b> The result is a new program (`your_dspy_program_compiled`) that includes these examples in its prompts. Since [**LabeledFewShot**](https://dspy.ai/api/optimizers/LabeledFewShot/?h=labeledfewshot) selects examples randomly, the examples used may differ between runs unless you fix the random seed. If reproducibility is important—for example, when comparing results or debugging—you may want to <b>set a random seed before compiling the program to ensure consistency across runs</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257974c-23ad-49d0-8ea3-931c9a1a203c",
   "metadata": {},
   "source": [
    "Let's check a real workable example as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3bfe80e-37f4-41c3-925d-184bc876c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSignature(dspy.Signature):\n",
    "    \"\"\"Classify the sentiment of a sentence.\"\"\"\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: str = dspy.OutputField(desc=\"positive, negative, or neutral\")\n",
    "\n",
    "\n",
    "class SentimentClassifier(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predict = dspy.Predict(SentimentSignature)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        return self.predict(sentence=sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbd2c407-8f7e-4976-8658-0c0bfab5981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = [\n",
    "    dspy.Example(\n",
    "        sentence=\"I love this product, it works perfectly!\",\n",
    "        sentiment=\"positive\"\n",
    "    ).with_inputs(\"sentence\"),\n",
    "\n",
    "    dspy.Example(\n",
    "        sentence=\"This is the worst experience I’ve ever had.\",\n",
    "        sentiment=\"negative\"\n",
    "    ).with_inputs(\"sentence\"),\n",
    "\n",
    "    dspy.Example(\n",
    "        sentence=\"The package arrived on time.\",\n",
    "        sentiment=\"neutral\"\n",
    "    ).with_inputs(\"sentence\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2fa0c-9827-4033-af0e-432e982175ee",
   "metadata": {},
   "source": [
    "#### <b>Apply `LabeledFewShot` Teleprompter</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "756af4ab-699a-44ef-b9b3-233619e250ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import LabeledFewShot\n",
    "\n",
    "teleprompter = LabeledFewShot(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24ece18e-b9e6-41e4-bcfe-5c934db0cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SentimentClassifier()\n",
    "\n",
    "compiled_classifier = teleprompter.compile(\n",
    "    classifier,\n",
    "    trainset=train_examples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8c6a2-8130-4f0c-a700-1171bc5d1e2d",
   "metadata": {},
   "source": [
    "What this does:\n",
    "* Selects up to k=3 labeled examples\n",
    "* Injects them into the prompt\n",
    "* Locks them into the compiled program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0190b3-034a-4634-a3e7-f7c8b420c551",
   "metadata": {},
   "source": [
    "#### <b>Run Inference</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7120d9f-f576-4a41-bd72-dcfc4584bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "result = compiled_classifier(\n",
    "    sentence=\"The movie was okay, nothing special.\"\n",
    ")\n",
    "\n",
    "print(result.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898f68d-9d00-4c3d-8f56-a55cabbc06e0",
   "metadata": {},
   "source": [
    "#### <b>What `LabeledFewShot` Is Actually Doing</b>\n",
    "Internally, DSPy turns your examples into something like:\n",
    "```\n",
    "Sentence: I love this product, it works perfectly!\n",
    "Sentiment: positive\n",
    "\n",
    "Sentence: This is the worst experience I’ve ever had.\n",
    "Sentiment: negative\n",
    "\n",
    "Sentence: The package arrived on time.\n",
    "Sentiment: neutral\n",
    "\n",
    "Sentence: The movie was okay, nothing special.\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "But:\n",
    "- You don’t write prompts\n",
    "- You don’t manage formatting\n",
    "- You can later swap teleprompters (BootstrapFewShot, COPRO, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cee2e8-da7f-4156-8fcf-dcb1277980fa",
   "metadata": {},
   "source": [
    "#### <b>When to Use `LabeledFewShot`</b>\n",
    "Use it when:\n",
    "- You already have labeled data\n",
    "- You want deterministic, simple few-shot behavior\n",
    "- You don’t need optimization or self-bootstrapping\n",
    "\n",
    "Don’t use it when:\n",
    "- You want the model to discover examples\n",
    "- You want automatic prompt optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850ed01-133b-4600-bed7-c62578452fce",
   "metadata": {},
   "source": [
    "**The main advantage of [LabeledFewShot](https://dspy.ai/api/optimizers/LabeledFewShot/?h=labeledfewshot) is its simplicity. It doesn't require a metric function and doesn't perform any complex optimization.** However, this simplicity also means it doesn't adapt the examples to the specific input or try to find the most effective examples. It's a good baseline approach, especially when you have a small but high-quality training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2fb875-d071-4934-898c-6ebd7483235a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>BootstrapFewShot: Self-Generated Examples</font></b>\n",
    "<font size='3ptx'>While [**LabeledFewShot**](https://dspy.ai/api/optimizers/LabeledFewShot/?h=labeledfewshot) simply uses examples from your training data, <b>[BootstrapFewShot](https://dspy.ai/api/optimizers/BootstrapFewShot/?h=bootstrapfewshot) goes a step further by generating additional examples using your program itself</b>.</font>\n",
    "\n",
    "This is particularly useful when you have limited labeled data or when you want to create more diverse examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d545759-c36a-4117-a969-d6fa43235d08",
   "metadata": {},
   "source": [
    "Here's how to implement [**BootstrapFewShot**](https://dspy.ai/api/optimizers/BootstrapFewShot/?h=bootstrapfewshot):\n",
    "```python\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Create the optimizer\n",
    "fewshot_optimizer = BootstrapFewShot(\n",
    "    metric=your_defined_metric,\n",
    "    max_bootstrapped_demos=4,\n",
    "    max_labeled_demos=16,\n",
    "    max_rounds=1,\n",
    "    max_errors=5\n",
    ")\n",
    "\n",
    "# Compile your DSPy program with the optimizer\n",
    "your_dspy_program_compiled = fewshot_optimizer.compile(\n",
    "    student=your_dspy_program,   # DSPY program\n",
    "    trainset=trainset,           # Dataset\n",
    ")\n",
    "```\n",
    "\n",
    "In this example, we create a [**BootstrapFewShot**](https://dspy.ai/api/optimizers/BootstrapFewShot/?h=bootstrapfewshot) optimizer with several parameters:\n",
    "* <b><font size='3ptx'>`metric`</font></b>: A function that evaluates the quality of generated examples.\n",
    "* <b><font size='3ptx'>`max_bootstrapped_demos`</font></b>: The maximum number of examples to generate (4 in this case).\n",
    "* <b><font size='3ptx'>`max_labeled_demos`</font></b>: The maximum number of examples to use from the training set (16 in this case).\n",
    "* <b><font size='3ptx'>`max_rounds`</font></b>: The number of rounds of bootstrapping to perform.\n",
    "* <b><font size='3ptx'>`max_errors`</font></b>: The maximum number of errors allowed before stopping the bootstrapping process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0e8af0-f9b4-4671-83f4-ca86163c2884",
   "metadata": {},
   "source": [
    "The bootstrapping process works as follows:\n",
    "1. The optimizer selects examples from your training set (<font color='brown'>up to `max_labeled_demos`</font>).\n",
    "2. It uses your program (<font color='brown'>or a specified \"teacher\" program</font>) to generate complete demonstrations for these examples.\n",
    "3. It evaluates the generated demonstrations using your `metric` function.\n",
    "4. It includes only the successful demonstrations (<font color='brown'>those that pass the `metric`</font>) in the compiled program.\n",
    "\n",
    "You can also use a different language model for the teacher by specifying it in the `teacher_settings`:\n",
    "```python\n",
    "# Using another LM for compilation\n",
    "fewshot_optimizer = BootstrapFewShot(\n",
    "    metric=your_defined_metric,\n",
    "    max_bootstrapped_demos=4,\n",
    "    max_labeled_demos=16,\n",
    "    max_rounds=1,\n",
    "    max_errors=5,\n",
    "    teacher_settings=dict(lm=gpt4)  # Use GPT-4 as the teacher\n",
    ")\n",
    "```\n",
    "\n",
    "This is particularly useful when you have access to a more powerful model (<font color='brown'>like GPT-4</font>) that can generate high-quality examples but want to optimize a program that will run on a smaller, more efficient model.\n",
    "\n",
    "The main advantage of [**BootstrapFewShot**](https://dspy.ai/api/optimizers/BootstrapFewShot/?h=bootstrapfewshot) over [**LabeledFewShot**](https://dspy.ai/api/optimizers/LabeledFewShot/?h=labeledfewshot) is that it can <b>generate new, high-quality examples beyond what's in your training set. This can lead to better performance, especially when your training data is limited</b>.\n",
    "\n",
    "Let's check a real example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "006f7957-1b95-4875-a895-ca5762229cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "\n",
    "# 1. Define the task signature\n",
    "class QA(dspy.Signature):\n",
    "    \"\"\"You are going to receive a question and provide an answer.\n",
    "\n",
    "    Regarding the answer, please don't use more than 5 sentences to answer the question.\n",
    "    If you don't know or have no confidence, just reply \"I don't know, sorry.\"\n",
    "    \"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"A short, factual answer\")\n",
    "\n",
    "\n",
    "# 2. Create a module\n",
    "class QAModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predict = dspy.Predict(QA)\n",
    "\n",
    "    def forward(self, question):\n",
    "        return self.predict(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2d87f2b-b668-4c65-ac9f-8afff1a3384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare training examples\n",
    "trainset = [\n",
    "    dspy.Example(\n",
    "        question=\"What is the capital of France?\",\n",
    "        answer=\"Paris\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    dspy.Example(\n",
    "        question=\"Who wrote Hamlet?\",\n",
    "        answer=\"William Shakespeare\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    dspy.Example(\n",
    "        question=\"What is Cockatoo.AI?\",\n",
    "        answer=\"It is a famework to use models (A-B-C as shown below) to form the pipeline as the final language tutor.\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    dspy.Example(\n",
    "        question=\"What is 1+1?\",\n",
    "        answer=\"2\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    dspy.Example(\n",
    "        question=\"What is LLM?\",\n",
    "        answer=\"Large Lange Model\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    dspy.Example(\n",
    "        question=\"Give me 3 kinds of animals.\",\n",
    "        answer=\"Dog, Cat and Bird.\"\n",
    "    ).with_inputs(\"question\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24075e9e-1c62-4b17-95bf-af9c5ac86ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define a metric\n",
    "def exact_match(example, pred, trace=None):\n",
    "    return example.answer.strip().lower() == pred.answer.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac2acd1b-9aac-4d56-8d81-20fa62d011a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:08<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 5 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "CPU times: user 225 ms, sys: 12.9 ms, total: 237 ms\n",
      "Wall time: 8.94 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5. Bootstrap few-shot examples\n",
    "teleprompter = BootstrapFewShot(\n",
    "    metric=exact_match,\n",
    "    max_bootstrapped_demos=4,\n",
    "    max_labeled_demos=3)\n",
    "\n",
    "compiled_module = teleprompter.compile(\n",
    "    student=QAModule(),\n",
    "    trainset=trainset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a659f28a-cd60-49fd-8792-9418f5af54c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Taiwan is Taipei.\n"
     ]
    }
   ],
   "source": [
    "# 6. Run inference\n",
    "dspy.settings.configure(trace=[])\n",
    "result = compiled_module(question=\"What is the capital of Taiwan?\")\n",
    "print(result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cbd11c9-10ea-4c85-9fad-d0ed9d2f71ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Predict(QA(question -> answer\n",
       "     instructions='You are going to receive a question and provide an answer.\\n\\nRegarding the answer, please don\\'t use more than 5 sentences to answer the question.\\nIf you don\\'t know or have no confidence, just reply \"I don\\'t know, sorry.\"'\n",
       "     question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "     answer = Field(annotation=str required=True json_schema_extra={'desc': 'A short, factual answer', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
       " )),\n",
       " {'question': 'What is the capital of Taiwan?'},\n",
       " Prediction(\n",
       "     answer='The capital of Taiwan is Taipei.'\n",
       " ))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dspy.settings.trace[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "365c7145-1483-49c8-9ec4-16ff1a6d46a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-14T04:59:48.915081]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str):\n",
      "Your output fields are:\n",
      "1. `answer` (str): A short, factual answer\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are going to receive a question and provide an answer.\n",
      "        \n",
      "        Regarding the answer, please don't use more than 5 sentences to answer the question.\n",
      "        If you don't know or have no confidence, just reply \"I don't know, sorry.\"\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the capital of France?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Paris\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is 1+1?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "2\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is LLM?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Large Lange Model\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the capital of Taiwan?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## answer ## ]]\n",
      "The capital of Taiwan is Taipei.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check last interaction from history\n",
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cfd788-7405-4b0a-9730-8cac9cc8743c",
   "metadata": {},
   "source": [
    "#### <b>What [BootstrapFewShot](https://dspy.ai/api/optimizers/BootstrapFewShot/?h=bootstrapfewshot) does here</b>\n",
    "1. Runs the model on the training set.\n",
    "2. Collects **successful model-generated examples**.\n",
    "3. Selects the best ones according to your metric.\n",
    "4. Automatically inserts them as few-shot demonstrations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442be29c-62aa-4414-9e0d-bd232dc589e1",
   "metadata": {},
   "source": [
    "#### <b>When to use [BootstrapFewShot](https://dspy.ai/api/optimizers/BootstrapFewShot/?h=bootstrapfewshot)</b>\n",
    "* You have **few or no hand-written prompts**.\n",
    "* You want the model to **discover effective examples itself**.\n",
    "* You can **define a clear evaluation metric**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2436f-8cfd-45e5-8f26-ab80a12cc59c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>BootstrapFewShotWithRandomSearch: Finding Optimal Example Sets</font></b>\n",
    "<font size='3ptx'>Building on [BootstrapFewShot](https://dspy.ai/api/optimizers/BootstrapFewShot/?h=bootstrapfewshot), the [**BootstrapFewShotWithRandomSearch**](https://dspy.ai/api/optimizers/BootstrapFewShotWithRandomSearch/?h=bootstrapfewshotwithrandomsearch) optimizer adds another layer of optimization by exploring multiple sets of examples to find the best combination.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e10ced-7bc5-4988-b3d7-be3b56dc6cf5",
   "metadata": {},
   "source": [
    "<b>This is particularly useful when you have a larger training set and want to find the most effective subset of examples.</b>\n",
    "\n",
    "Here's how to implement [**BootstrapFewShotWithRandomSearch**](https://dspy.ai/api/optimizers/BootstrapFewShotWithRandomSearch/?h=bootstrapfewshotwithrandomsearch):\n",
    "```python\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Configure the optimizer\n",
    "config = dict(\n",
    "    max_bootstrapped_demos=4,\n",
    "    max_labeled_demos=4,\n",
    "    num_candidate_programs=10,\n",
    "    num_threads=4\n",
    ")\n",
    "\n",
    "# Create the optimizer\n",
    "teleprompter = BootstrapFewShotWithRandomSearch(\n",
    "    metric=YOUR_METRIC_HERE,\n",
    "    **config\n",
    ")\n",
    "\n",
    "# Compile your DSPy program with the optimizer\n",
    "optimized_program = teleprompter.compile(\n",
    "    YOUR_PROGRAM_HERE,\n",
    "    trainset=YOUR_TRAINSET_HERE\n",
    ")\n",
    "```\n",
    "\n",
    "n this example, we configure the optimizer with several parameters:\n",
    "* <b><font size='3ptx'>max_bootstrapped_demos</font></b>: The maximum number of examples to generate (<font color='brown'>4 in this case</font>).\n",
    "* <b><font size='3ptx'>max_labeled_demos</font></b>: The maximum number of examples to use from the training set (<font color='brown'>4 in this case</font>).\n",
    "* <b><font size='3ptx'>num_candidate_programs</font></b>: The number of random programs to evaluate (<font color='brown'>10 in this case</font>).\n",
    "* <b><font size='3ptx'>num_threads</font></b>: The number of threads to use for parallel evaluation (<font color='brown'>4 in this case</font>).\n",
    "\n",
    "The random search process works as follows:\n",
    "1. The optimizer creates multiple candidate programs, each with a different set of examples.\n",
    "2. These candidates include the uncompiled program, a program optimized with `LabeledFewShot`, a program optimized with `BootstrapFewShot` using unshuffled examples, and `num_candidate_programs` programs optimized with `BootstrapFewShot` using randomized example sets.\n",
    "3. It evaluates all these candidates on your validation set using your metric function.\n",
    "4. It returns the candidate program that performs best according to your metric.\n",
    "\n",
    "The parallelization through num_threads can significantly speed up the optimization process, especially when evaluating many candidate programs. Let's check a workable example to see how it goes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4c7b4-7270-490e-9bf8-85034d36e9bf",
   "metadata": {},
   "source": [
    "#### <b>Example</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9792c5dd-d128-44e3-9931-421b30156731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# 1. Define the Signature (Input -> Output)\n",
    "class TicketTriage(dspy.Signature):\n",
    "    \"\"\"Classify the severity of a software issue based on the description.\"\"\"\n",
    "    \n",
    "    issue_description = dspy.InputField(desc=\"The raw text from the user ticket\")\n",
    "    severity = dspy.OutputField(desc=\"Severity level: High, Medium, or Low\")\n",
    "    reasoning = dspy.OutputField(desc=\"Brief explanation for the classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "304402cd-2110-434d-b4cb-d5982ed6b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a small labeled dataset (Train & Dev)\n",
    "# In a real scenario, you'd want 10-50 examples here.\n",
    "trainset = [\n",
    "    dspy.Example(issue_description=\"The entire system is down and no one can login.\", severity=\"High\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"There is a typo in the footer of the dashboard.\", severity=\"Low\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"The reports are taking 5 minutes to load instead of 10 seconds.\", severity=\"Medium\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"Data loss occurred when clicking save.\", severity=\"High\").with_inputs('issue_description'),\n",
    "]\n",
    "\n",
    "devset = [\n",
    "    dspy.Example(issue_description=\"The color of the 'Submit' button is slightly off.\", severity=\"Low\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"API returns 500 error for all POST requests.\", severity=\"High\").with_inputs('issue_description'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6c3309d-f356-4854-80a9-800cc1bb70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the Module (ChainOfThought is usually best for reasoning tasks)\n",
    "module = dspy.ChainOfThought(TicketTriage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7f6e1846-4689-4c83-93f1-be54ab7d37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define the Metric\n",
    "# We check if the predicted severity matches the actual severity\n",
    "def validate_severity(example, prediction, trace=None):\n",
    "    # Normalize strings for comparison (case-insensitive)\n",
    "    return example.severity.lower() == prediction.severity.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0539c0ce-f1d4-487f-9118-f62e38462057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling...\n",
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to bootstrap 5 candidate sets.\n",
      "CPU times: user 309 μs, sys: 95 μs, total: 404 μs\n",
      "Wall time: 375 μs\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize the Optimizer\n",
    "print(\"Compiling...\")\n",
    "optimizer = BootstrapFewShotWithRandomSearch(\n",
    "    metric=validate_severity,\n",
    "    max_bootstrapped_demos=4,    # How many examples to generate total\n",
    "    max_labeled_demos=4,         # How many real examples to use\n",
    "    num_candidate_programs=5,    # How many different prompts to try testing\n",
    "    num_threads=4                # Parallel threads for speed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f738bda-3439-4259-bc62-c5ad725468b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 2 (100.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 05:22:44 INFO dspy.evaluate.evaluate: Average Metric: 2 / 2 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 100.0 for seed -3\n",
      "Scores so far: [100.0]\n",
      "Best score so far: 100.0\n",
      "Average Metric: 2.00 / 2 (100.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 05:22:46 INFO dspy.evaluate.evaluate: Average Metric: 2 / 2 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [100.0, 100.0]\n",
      "Best score so far: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 2.00 / 2 (100.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 05:22:56 INFO dspy.evaluate.evaluate: Average Metric: 2 / 2 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [100.0, 100.0, 100.0]\n",
      "Best score so far: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 2.00 / 2 (100.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 05:23:05 INFO dspy.evaluate.evaluate: Average Metric: 2 / 2 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [100.0, 100.0, 100.0, 100.0]\n",
      "Best score so far: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████▌                                                            | 2/4 [00:01<00:01,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 2.00 / 2 (100.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 05:23:08 INFO dspy.evaluate.evaluate: Average Metric: 2 / 2 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Best score so far: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████████████▎                                                                                          | 1/4 [00:01<00:05,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Average Metric: 2.00 / 2 (100.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 05:23:13 INFO dspy.evaluate.evaluate: Average Metric: 2 / 2 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Best score so far: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████▌                                                            | 2/4 [00:00<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 2.00 / 2 (100.0%): 100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1734.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 05:23:13 INFO dspy.evaluate.evaluate: Average Metric: 2 / 2 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Best score so far: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████▌                                                            | 2/4 [00:03<00:03,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 2.00 / 2 (100.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 05:23:19 INFO dspy.evaluate.evaluate: Average Metric: 2 / 2 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Best score so far: 100.0\n",
      "8 candidate programs found.\n",
      "CPU times: user 812 ms, sys: 76 ms, total: 888 ms\n",
      "Wall time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 6. Compile (Optimize) the module\n",
    "# This will run the random search over your trainset\n",
    "compiled_module = optimizer.compile(student=module, trainset=trainset, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02ccca75-b7fd-4db4-a6ac-ebc50bc219b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Optimized Module ---\n",
      "Issue: I can't export the CSV file, it just does nothing when I click.\n",
      "Predicted Severity: High\n",
      "Reasoning: The user is completely blocked from exporting data, which is a core functionality and impacts their ability to use or analyze data outside the application. There is no workaround mentioned.\n"
     ]
    }
   ],
   "source": [
    "# 7. Test it out\n",
    "print(\"\\n--- Testing Optimized Module ---\")\n",
    "test_issue = \"I can't export the CSV file, it just does nothing when I click.\"\n",
    "pred = compiled_module(issue_description=test_issue)\n",
    "\n",
    "print(f\"Issue: {test_issue}\")\n",
    "print(f\"Predicted Severity: {pred.severity}\")\n",
    "print(f\"Reasoning: {pred.reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c7ed3-651a-4d66-84b9-f997218ae57a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <b>When to use this vs. standard `BootstrapFewShot`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcbff31-5b67-4ea1-aac2-85f4f297fcf0",
   "metadata": {},
   "source": [
    "<b>The main advantage of [BootstrapFewShotWithRandomSearch](https://dspy.ai/api/optimizers/BootstrapFewShotWithRandomSearch/?h=bootstrapfewshotwithrandomsearch) over [BootstrapFewShot](https://dspy.ai/api/optimizers/BootstrapFewShot/?h=bootstrapfewshot) is that it explores a larger space of possible example combinations, increasing the chances of finding a particularly effective set</b>. However, this comes at <b><font color='red'>the cost of increased computation time</font></b>, as it needs to evaluate multiple candidate programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e04c7c-2470-45e3-8dcd-25dede00a56b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <b><font color='darkgreen'>KNNFewShot: Context-Aware Example Selection</font></b>\n",
    "<font size='3ptx'>The final few-shot optimizer we'll explore is [**KNNFewShot**](https://dspy.ai/api/optimizers/KNNFewShot/?h=knnfewshot), which takes a different approach by selecting examples based on their similarity to the current input. <b>This is particularly useful when the relevance of examples varies significantly depending on the input.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd96b72c-f874-4bcc-8693-72a25bb6befc",
   "metadata": {},
   "source": [
    "Here's how to implement [**KNNFewShot**](https://dspy.ai/api/optimizers/KNNFewShot/?h=knnfewshot):\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dspy import Embedder\n",
    "from dspy.teleprompt import KNNFewShot\n",
    "from dspy import ChainOfThought\n",
    "\n",
    "# Create an embedder using SentenceTransformer\n",
    "embedder = Embedder(SentenceTransformer(\"all-MiniLM-L6-v2\").encode)\n",
    "\n",
    "# Create the optimizer\n",
    "knn_optimizer = KNNFewShot(\n",
    "    k=3,\n",
    "    trainset=trainset,\n",
    "    vectorizer=embedder\n",
    ")\n",
    "\n",
    "# Compile your DSPy program with the optimizer\n",
    "qa_compiled = knn_optimizer.compile(\n",
    "    student=ChainOfThought(\"question -> answer\")\n",
    ")\n",
    "```\n",
    "\n",
    "In this example, we first create an [**Embedder**](https://dspy.ai/api/models/Embedder/?h=embedder) using a pre-trained `SentenceTransformer` model. This `embedder` converts text into vector representations that capture semantic meaning. Then, we create a [**KNNFewShot**](https://dspy.ai/api/optimizers/KNNFewShot/?h=knnfewshot) optimizer with several parameters:\n",
    "* <b><font size='3ptx'>k</font></b>: The number of nearest neighbors (examples) to include in each prompt (3 in this case).\n",
    "* <b><font size='3ptx'>trainset</font></b>: Your training set of examples.\n",
    "* <b><font size='3ptx'>vectorizer</font></b>: The embedder that converts text to vectors for similarity comparison.\n",
    "\n",
    "The KNN ([k-nearest neighbors](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/)) process works as follows:\n",
    "1. When your program receives a new input, the optimizer converts it to a vector using the embedder.\n",
    "2. It compares this vector to the vectors of all examples in your training set.\n",
    "3. It selects the k examples that are most similar to the current input.\n",
    "4. It includes these examples in the prompt sent to the language model.\n",
    "\n",
    "Let's check a workable example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f21f2-14d2-49f3-8dfb-c9de3b200267",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### <b>Example</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08dd7d12-5695-471c-b0df-b018927e062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers==5.2.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install sentence_transformers\n",
    "!pip freeze | grep 'sentence-transformers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2a2ec63-d6bf-4cb5-a513-982fd8e5297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/johnkclee/Github/ml_articles/env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.teleprompt import KNNFewShot\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dspy import Embedder\n",
    "\n",
    "# 1. Define the Signature (Input -> Output)\n",
    "class TicketTriage(dspy.Signature):\n",
    "    \"\"\"Classify the severity of a software issue.\"\"\"\n",
    "    issue_description = dspy.InputField(desc=\"The raw text from the user ticket\")\n",
    "    severity = dspy.OutputField(desc=\"Severity level: High, Medium, or Low\")\n",
    "    reasoning = dspy.OutputField(desc=\"Brief explanation for the classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71e30337-7e72-4357-bbe9-6ffd00c9b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a small labeled dataset (Train & Dev)\n",
    "# KNN shines when it has a \"library\" of examples to choose from.\n",
    "trainset = [\n",
    "    dspy.Example(issue_description=\"System crash on startup.\", severity=\"High\", reasoning=\"Prevents use.\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"Typo in 'Welcome' message.\", severity=\"Low\", reasoning=\"Cosmetic only.\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"SQL injection vulnerability found.\", severity=\"High\", reasoning=\"Security risk.\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"Blue button looks purple on mobile.\", severity=\"Low\", reasoning=\"Cosmetic UI.\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"Export to PDF fails with error 404.\", severity=\"Medium\", reasoning=\"Feature broken but system works.\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"Payment gateway timeout.\", severity=\"High\", reasoning=\"Revenue impact.\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"Font size too small on settings page.\", severity=\"Low\", reasoning=\"Accessibility/Cosmetic.\").with_inputs('issue_description'),\n",
    "    dspy.Example(issue_description=\"Search bar takes 10 seconds to respond.\", severity=\"Medium\", reasoning=\"Performance degradation.\").with_inputs('issue_description'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e1f215d9-4e3d-45e3-b08a-faebdc36719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the Module (ChainOfThought is usually best for reasoning tasks)\n",
    "module = dspy.ChainOfThought(TicketTriage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "84261488-3204-41ac-8d63-c297e08fc9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize the Optimizer\n",
    "# k: The number of similar examples to fetch for each query\n",
    "# Create an embedder using SentenceTransformer\n",
    "embedder = Embedder(SentenceTransformer(\"all-MiniLM-L6-v2\").encode)\n",
    "\n",
    "optimizer = KNNFewShot(k=3, trainset=trainset, vectorizer=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4500659e-92d4-48f6-9dbf-79768506951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling...\n",
      "CPU times: user 308 μs, sys: 0 ns, total: 308 μs\n",
      "Wall time: 302 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5. Initialize the Optimizer\n",
    "print(\"Compiling...\")\n",
    "compiled_module = optimizer.compile(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87a57bf1-2577-4cb0-92e6-77f901a44111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing KNN Module ---\n",
      ">> Input: 'User password exposed in logs'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Predicted: High\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Test it out\n",
    "print(\"\\n--- Testing KNN Module ---\")\n",
    "\n",
    "# Case A: A security/crash issue -> Should pull 'System crash' or 'SQL injection' examples\n",
    "print(\">> Input: 'User password exposed in logs'\")\n",
    "pred_a = compiled_module(issue_description=\"User password exposed in plain text logs.\")\n",
    "print(f\"Predicted: {pred_a.severity}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2b04908-2d52-459e-a9f8-eacd36cb2588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-14T05:46:40.473761]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `issue_description` (str): The raw text from the user ticket\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): Brief explanation for the classification\n",
      "2. `severity` (str): Severity level: High, Medium, or Low\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "{issue_description}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "{severity}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the severity of a software issue.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "Typo in 'Welcome' message.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Cosmetic issue, does not affect functionality.\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "Low\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "SQL injection vulnerability found.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Security vulnerability with potential for data breach and system compromise.\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "High\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "Export to PDF fails with error 404.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "A core functionality (PDF export) is failing, preventing users from completing a task.\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "Medium\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "User password exposed in plain text logs.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## severity ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "This is a critical security vulnerability as it exposes sensitive user data (passwords) in plain text, which could lead to account compromise and a significant data breach.\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "High\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check last interaction from history\n",
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2f7f6359-e76d-4992-b12e-48e7bb7aaab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Input: 'The header icon is misaligned'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 22.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Predicted: Low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Case B: A UI issue -> Should pull 'Typo' or 'Blue button' examples\n",
    "print(\">> Input: 'The header icon is misaligned'\")\n",
    "pred_b = compiled_module(issue_description=\"The header icon is misaligned by 5 pixels.\")\n",
    "print(f\"Predicted: {pred_b.severity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5042dd3a-cf90-40b1-aa34-287c10bf5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-14T05:46:58.276767]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `issue_description` (str): The raw text from the user ticket\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): Brief explanation for the classification\n",
      "2. `severity` (str): Severity level: High, Medium, or Low\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "{issue_description}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "{severity}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the severity of a software issue.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "Font size too small on settings page.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Cosmetic UI issue, does not block functionality.\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "Low\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "Blue button looks purple on mobile.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Cosmetic/UI inconsistency.\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "Low\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "Typo in 'Welcome' message.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Cosmetic/text accuracy issue. Does not affect functionality or user experience significantly.\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "Low\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## issue_description ## ]]\n",
      "The header icon is misaligned by 5 pixels.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## severity ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "Minor UI/cosmetic misalignment.\n",
      "\n",
      "[[ ## severity ## ]]\n",
      "Low\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check last interaction from history\n",
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dccd3b1-e5de-4f46-a009-d212f0454edb",
   "metadata": {},
   "source": [
    "#### <b>When to use</b>\n",
    "<b>The main advantage of [**KNNFewShot**](https://dspy.ai/api/optimizers/KNNFewShot/?h=knnfewshot) over the other optimizers is that it dynamically selects examples based on their relevance to the current input</b>. This can lead to better performance, especially when different types of inputs benefit from different types of examples. However, it <b><font color='red'>requires an additional step of computing embeddings, which adds some computational overhead</font></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512dbb4-8c10-46e5-bfa1-8451e2754c2d",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Advantages of DSPy</font></b>\n",
    "Below we will see the advantages of DSPy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f59a2-9909-4ce5-8551-c4ddd72a53c3",
   "metadata": {},
   "source": [
    "* <b><font size='3ptx'>Declarative Programming</font></b>: Allows developers to specify desired outcomes without detailing the implementation steps.\n",
    "* <b><font size='3ptx'>Modularity</font></b>: Encourages the creation of reusable components for building complex workflows.\n",
    "* <b><font size='3ptx'>Automatic Optimization</font></b>: Enhances performance by fine-tuning prompts and configurations without manual intervention.\n",
    "* <b><font size='3ptx'>Self-Improvement</font></b>: Continuously refines workflows based on feedback, leading to better results over time.\n",
    "* <b><font size='3ptx'>Scalability</font></b>: Efficiently manages workflows of varying complexity and size.\n",
    "* <b><font size='3ptx'>Easy Integration</font></b>: Seamlessly incorporates into existing systems and applications.\n",
    "* <b><font size='3ptx'>Continuous Monitoring</font></b>: Provides tools to track and maintain workflow performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2fd8a-4d40-4640-851c-b70312069401",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [ithelp - 【Day 27】- 告別提示工程：DSPy如何革新大型語言模型的應用開發](https://ithelp.ithome.com.tw/m/articles/10348919)\n",
    "* [CodeSignal - Introduction to Optimization with DSPy](https://codesignal.com/learn/courses/how-to-optimize-with-dspy/lessons/introduction-to-optimization-with-dspy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
