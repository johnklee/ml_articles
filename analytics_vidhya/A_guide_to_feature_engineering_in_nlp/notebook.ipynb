{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3d680f",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Preface</font>\n",
    "([article source](https://www.analyticsvidhya.com/blog/2021/04/a-guide-to-feature-engineering-in-nlp/)) <font size='3ptx'><b>\"If 80 percent of our work is data preparation, then ensuring data quality is the important work of a machine learning team.‚Äù - ‚Äì Andrew Ng</b> Feature engineering is one of the most important steps in machine learning. It is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Think machine learning algorithm as a learning child the more accurate information you provide the more they will be able to interpret the information well. Focusing first on our data will give us better results than focusing only on models. Feature engineering helps us to create better data which helps the model understand it well and provide reasonable results.</font>\n",
    "\n",
    "<b>NLP is a subfield of artificial intelligence where we understand human interaction with machines using natural languages</b>. To understand a natural language, you need to understand how we write a sentence, how we express our thoughts using different words, signs, special characters, etc basically we should understand the context of the sentence to interpret its meaning.\n",
    "\n",
    "<b>If we can use these contexts as features and feed them to our model then the model will be able to understand the sentence better</b>. Some of the common features that we can extract from a sentence are the number of words, number of capital words, number of punctuation, number of unique words, number of stopwords, average sentence length, etc. We can define these features based on our data set we are using. In this blog, we will use a Twitter data set so we can add some others features like the number of hashtags, number of mentions, etc. We will discuss them in detail in the coming sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ca056",
   "metadata": {},
   "source": [
    "<a id='sect0'></a>\n",
    "### <font color='darkgreen'>Table of Content</font>\n",
    "* <font size='3ptx'><b><a href='#sect1'>NLP task overview</a></b></font>\n",
    "* <font size='3ptx'><b><a href='#sect2'>List of features with code</a></b></font>\n",
    "* <font size='3ptx'><b><a href='#sect3'>Implementation</a></b></font>\n",
    "* <font size='3ptx'><b><a href='#sect4'>Results comparison with and without doing feature engineering</a></b></font>\n",
    "* <font size='3ptx'><b><a href='#sect5'>Conclusion</a></b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8840748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer, sent_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f856407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a281528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b680fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c67d9f",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "## <font color='darkblue'>NLP task overview</font>\n",
    "<font size='3ptx'><b>To understand the feature engineering task in NLP, we will be implementing it on a Twitter dataset</b>. We will be using COVID-19 Fake News Dataset. The task is to classify the tweet as Fake or Real.</font>\n",
    "\n",
    "You can download the dataset from [here](https://www.kaggle.com/datasets/arashnic/covid19-fake-news?resource=download) (or [here](https://github.com/MiHarsh/Public_stuffs)). The dataset is divided into train, validation, and test set.  Below is the distribution,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f94722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('https://raw.githubusercontent.com/MiHarsh/Public_stuffs/master/Constraint_English_Train%20-%20Sheet1.csv')\n",
    "test_df = pd.read_csv('https://raw.githubusercontent.com/MiHarsh/Public_stuffs/master/Constraint_English_Val%20-%20Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd8342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6420, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>1266</td>\n",
       "      <td>Doctors should pay particular attention to pat...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>2024</td>\n",
       "      <td>Facebook posts claims the Asian Hong Kong swin...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>2031</td>\n",
       "      <td>People are handing out masks ???doused with ch...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet label\n",
       "1265  1266  Doctors should pay particular attention to pat...  real\n",
       "2023  2024  Facebook posts claims the Asian Hong Kong swin...  fake\n",
       "2030  2031  People are handing out masks ???doused with ch...  fake"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d4fb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>681</td>\n",
       "      <td>The remedy for the corona virus may have exist...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>1815</td>\n",
       "      <td>WHO releases report claiming vegetarians haven...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1580</td>\n",
       "      <td>Video showing COVID-19 patients sitting in cor...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet label\n",
       "680    681  The remedy for the corona virus may have exist...  fake\n",
       "1814  1815  WHO releases report claiming vegetarians haven...  fake\n",
       "1579  1580  Video showing COVID-19 patients sitting in cor...  fake"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0b6a3",
   "metadata": {},
   "source": [
    "Below is the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c248038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f6e473acf40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training data\n",
    "sns.displot(train_df, x=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22653ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f6e9c6e05e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing data\n",
    "sns.displot(test_df, x=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34629a87",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "## <font color='darkblue'>List of features</font> ([back](#sect0))\n",
    "I will be listing out a total of 15 features that we can use for the above dataset, number of features totally depends upon the type of dataset you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e00b07",
   "metadata": {},
   "source": [
    "#### 1. Number of Characters\n",
    "Count the number of characters present in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7b0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_chars(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232b327f",
   "metadata": {},
   "source": [
    "#### 2. Number of words\n",
    "Count the number of words present in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2dc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bce17f",
   "metadata": {},
   "source": [
    "#### 3. Number of capital characters\n",
    "Count the number of capital characters present in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11f04164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_capital_chars(text):\n",
    "    count=0\n",
    "    for i in text:\n",
    "        if i.isupper():\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b156a4",
   "metadata": {},
   "source": [
    "#### 4. Number of capital words\n",
    "Count the number of capital words present in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20119ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_capital_words(text):\n",
    "    return sum(map(str.isupper,text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a002d7",
   "metadata": {},
   "source": [
    "#### 5. Count the number of punctuations\n",
    "In this function, we return a dictionary of 32 punctuation with the counts, which can be used as separate features, which I will discuss in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe3805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuations(text):\n",
    "    punctuations='!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "    d=dict()\n",
    "    for i in punctuations:\n",
    "        d[str(i)+' count']=text.count(i)\n",
    "    return d "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0819c",
   "metadata": {},
   "source": [
    "#### 6. Number of words in quotes\n",
    "The number of words in the single quotation and double quotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d462847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_in_quotes(text):\n",
    "    x = re.findall(\"'.'|\\\".\\\"\", text)\n",
    "    count=0\n",
    "    if x is None:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in x:\n",
    "            t=i[1:-1]\n",
    "            count+=count_words(t)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4cf36",
   "metadata": {},
   "source": [
    "#### 7. Number of sentences\n",
    "Count the number of sentences in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d49b403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sent(text):\n",
    "    return len(nltk.sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d55ce",
   "metadata": {},
   "source": [
    "#### 8. Count the number of unique words\n",
    "Count the number of unique words in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e148ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_words(text):\n",
    "    return len(set(text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918ea7c",
   "metadata": {},
   "source": [
    "#### 9. Count of hashtags\n",
    "Since we are using the Twitter dataset we can count the number of times users used the hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da43bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_htags(text):\n",
    "    x = re.findall(r'(#w[A-Za-z0-9]*)', text)\n",
    "    return len(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2084f9",
   "metadata": {},
   "source": [
    "#### 10. Count of mentions\n",
    "On Twitter, most of the time people reply or mention someone in their tweet, counting the number of mentions can also be treated as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b5661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mentions(text):\n",
    "    x = re.findall(r'(@w[A-Za-z0-9]*)', text)\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c47f74",
   "metadata": {},
   "source": [
    "#### 11. Count of stopwords\n",
    "Here we will count the number of stopwords used in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f24a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "    word_tokens = word_tokenize(text)\n",
    "    stopwords_x = [w for w in word_tokens if w in stop_words]\n",
    "    return len(stopwords_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0490b",
   "metadata": {},
   "source": [
    "#### 12. Calculating average word length\n",
    "This can be calculated by dividing the counts of characters by counts of words.\n",
    "```python\n",
    "train_df['avg_wordlength'] = train_df['char_count']/train_df['word_count']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893600f7",
   "metadata": {},
   "source": [
    "#### 13. Calculating average sentence length\n",
    "This can be calculated by dividing the counts of words by the counts of sentences.\n",
    "```python\n",
    "train_df['avg_sentlength'] = train_df['word_count']/train_df['sent_count']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb67cbe",
   "metadata": {},
   "source": [
    "#### 14. unique words vs word count feature\n",
    "This feature is basically the ratio of unique words to a total number of words.\n",
    "```python\n",
    "df['unique_vs_words'] = df['unique_word_count']/df['word_count']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c402d1",
   "metadata": {},
   "source": [
    "#### 15. Stopwords count vs words counts feature\n",
    "This feature is also the ratio of counts of stopwords to the total number of words.\n",
    "```python\n",
    "df['stopwords_vs_words'] = df['stopword_count']/df['word_count']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f539f6b9",
   "metadata": {},
   "source": [
    "<a id='sect3'></a>\n",
    "## <font color='darkblue'>Implementation</font> ([back](#sect0))\n",
    "We will focus more on feature engineering, for this we will keep the approach simple, by using TF-IDF and simple pre-processing. All the code will be available on my GitHub repository https://github.com/ahmadkhan242/Feature-Engineering-in-NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bf849",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Applying the above-defined feature extraction on train and test set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "490b281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features(df):\n",
    "    df['char_count'] = df[\"tweet\"].apply(lambda x:count_chars(x))\n",
    "    df['word_count'] = df[\"tweet\"].apply(lambda x:count_words(x))\n",
    "    df['sent_count'] = df[\"tweet\"].apply(lambda x:count_sent(x))\n",
    "    df['capital_char_count'] = df[\"tweet\"].apply(lambda x:count_capital_chars(x))\n",
    "    df['capital_word_count'] = df[\"tweet\"].apply(lambda x:count_capital_words(x))\n",
    "    df['quoted_word_count'] = df[\"tweet\"].apply(lambda x:count_words_in_quotes(x))\n",
    "    df['stopword_count'] = df[\"tweet\"].apply(lambda x:count_stopwords(x))\n",
    "    df['unique_word_count'] = df[\"tweet\"].apply(lambda x:count_unique_words(x))\n",
    "    df['htag_count'] = df[\"tweet\"].apply(lambda x:count_htags(x))\n",
    "    df['mention_count'] = df[\"tweet\"].apply(lambda x:count_mentions(x))\n",
    "    df['punct_count'] = df[\"tweet\"].apply(lambda x:count_punctuations(x))\n",
    "    df['avg_wordlength'] = df['char_count']/df['word_count']\n",
    "    df['avg_sentlength'] = df['word_count']/df['sent_count']\n",
    "    df['unique_vs_words'] = df['unique_word_count']/df['word_count']\n",
    "    df['stopwords_vs_words'] = df['stopword_count']/df['word_count']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2ad7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = gen_features(train_df)\n",
    "test_df = gen_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1d240b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>htag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>1855</td>\n",
       "      <td>Guess who is the marketing CEO of Zoom? Pelosi...</td>\n",
       "      <td>fake</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>#CoronaVirusUpdates: üìçTotal #COVID19 Cases in ...</td>\n",
       "      <td>real</td>\n",
       "      <td>280</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 2, '$ ...</td>\n",
       "      <td>9.655172</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>_A student from Pondicherry University in Indi...</td>\n",
       "      <td>fake</td>\n",
       "      <td>144</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.260870</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet label  \\\n",
       "1854  1855  Guess who is the marketing CEO of Zoom? Pelosi...  fake   \n",
       "200    201  #CoronaVirusUpdates: üìçTotal #COVID19 Cases in ...  real   \n",
       "101    102  _A student from Pondicherry University in Indi...  fake   \n",
       "\n",
       "      char_count  word_count  sent_count  capital_char_count  \\\n",
       "1854          75          11           2                   7   \n",
       "200          280          29           1                  33   \n",
       "101          144          23           1                  15   \n",
       "\n",
       "      capital_word_count  quoted_word_count  stopword_count  \\\n",
       "1854                   1                  0               6   \n",
       "200                    2                  0               3   \n",
       "101                    3                  0               9   \n",
       "\n",
       "      unique_word_count  htag_count  mention_count  \\\n",
       "1854                 11           0              0   \n",
       "200                  28           0              0   \n",
       "101                  22           0              0   \n",
       "\n",
       "                                            punct_count  avg_wordlength  \\\n",
       "1854  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.818182   \n",
       "200   {'! count': 0, '\" count': 0, '# count': 2, '$ ...        9.655172   \n",
       "101   {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.260870   \n",
       "\n",
       "      avg_sentlength  unique_vs_words  stopwords_vs_words  \n",
       "1854             5.5         1.000000            0.545455  \n",
       "200             29.0         0.965517            0.103448  \n",
       "101             23.0         0.956522            0.391304  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c0001",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Adding some extra features using punctuation count</font>\n",
    "We will create a DataFrame from the dictionary returned by the ‚Äúpunct_count‚Äù function and then merge it with the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a81b446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>! count</th>\n",
       "      <th>\" count</th>\n",
       "      <th># count</th>\n",
       "      <th>$ count</th>\n",
       "      <th>% count</th>\n",
       "      <th>&amp; count</th>\n",
       "      <th>' count</th>\n",
       "      <th>( count</th>\n",
       "      <th>) count</th>\n",
       "      <th>* count</th>\n",
       "      <th>...</th>\n",
       "      <th>[ count</th>\n",
       "      <th>\\ count</th>\n",
       "      <th>] count</th>\n",
       "      <th>^ count</th>\n",
       "      <th>_ count</th>\n",
       "      <th>` count</th>\n",
       "      <th>{ count</th>\n",
       "      <th>| count</th>\n",
       "      <th>} count</th>\n",
       "      <th>~ count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ! count  \" count  # count  $ count  % count  & count  ' count  ( count  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        2        0        0        0        0        1   \n",
       "\n",
       "   ) count  * count  ...  [ count  \\ count  ] count  ^ count  _ count  \\\n",
       "0        0        0  ...        0        0        0        0        0   \n",
       "1        0        0  ...        0        0        0        0        0   \n",
       "2        1        0  ...        0        0        0        0        0   \n",
       "\n",
       "   ` count  { count  | count  } count  ~ count  \n",
       "0        0        0        0        0        0  \n",
       "1        0        0        0        0        0  \n",
       "2        0        0        0        0        0  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_punct_df = pd.DataFrame(list(test_df.punct_count))\n",
    "train_punct_df = pd.DataFrame(list(train_df.punct_count))\n",
    "train_punct_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74b39b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>...</th>\n",
       "      <th>[ count</th>\n",
       "      <th>\\ count</th>\n",
       "      <th>] count</th>\n",
       "      <th>^ count</th>\n",
       "      <th>_ count</th>\n",
       "      <th>` count</th>\n",
       "      <th>{ count</th>\n",
       "      <th>| count</th>\n",
       "      <th>} count</th>\n",
       "      <th>~ count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>5197</td>\n",
       "      <td>Since August 12 our contact tracing team has i...</td>\n",
       "      <td>real</td>\n",
       "      <td>191</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1666</td>\n",
       "      <td>by inhaling steam from boiling sea salt and or...</td>\n",
       "      <td>fake</td>\n",
       "      <td>122</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1363</td>\n",
       "      <td>Reopening of places of worship doesn't mean th...</td>\n",
       "      <td>real</td>\n",
       "      <td>286</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet label  \\\n",
       "5196  5197  Since August 12 our contact tracing team has i...  real   \n",
       "1665  1666  by inhaling steam from boiling sea salt and or...  fake   \n",
       "1362  1363  Reopening of places of worship doesn't mean th...  real   \n",
       "\n",
       "      char_count  word_count  sent_count  capital_char_count  \\\n",
       "5196         191          33           1                   2   \n",
       "1665         122          20           1                   0   \n",
       "1362         286          44           2                  18   \n",
       "\n",
       "      capital_word_count  quoted_word_count  stopword_count  ...  [ count  \\\n",
       "5196                   0                  0              16  ...        0   \n",
       "1665                   0                  0               7  ...        0   \n",
       "1362                   1                  0              15  ...        0   \n",
       "\n",
       "      \\ count  ] count ^ count  _ count  ` count  { count  | count  } count  \\\n",
       "5196        0        0       0        0        0        0        0        0   \n",
       "1665        0        0       0        0        0        0        0        0   \n",
       "1362        0        0       0        0        0        0        0        0   \n",
       "\n",
       "      ~ count  \n",
       "5196        0  \n",
       "1665        0  \n",
       "1362        0  \n",
       "\n",
       "[3 rows x 50 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging pnctuation DataFrame with main DataFrame\n",
    "train_df = pd.merge(train_df, train_punct_df, left_index=True, right_index=True)\n",
    "test_df = pd.merge(test_df, test_punct_df, left_index=True, right_index=True)\n",
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48aa1c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet', 'label', 'char_count', 'word_count', 'sent_count',\n",
       "       'capital_char_count', 'capital_word_count', 'quoted_word_count',\n",
       "       'stopword_count', 'unique_word_count', 'htag_count', 'mention_count',\n",
       "       'avg_wordlength', 'avg_sentlength', 'unique_vs_words',\n",
       "       'stopwords_vs_words', '! count', '\" count', '# count', '$ count',\n",
       "       '% count', '& count', '' count', '( count', ') count', '* count',\n",
       "       '+ count', ', count', '- count', '. count', '/ count', ': count',\n",
       "       '; count', '< count', '= count', '> count', '? count', '@ count',\n",
       "       '[ count', '\\ count', '] count', '^ count', '_ count', '` count',\n",
       "       '{ count', '| count', '} count', '~ count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can drop \"punct_count\" column from both df and test DataFrame\n",
    "train_df.drop(columns=['punct_count'], inplace=True)\n",
    "test_df.drop(columns=['punct_count'], inplace=True)\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39493d7b",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Re-processing</font>\n",
    "We performed a simple pre-processing step, like removing links, removing user name, numbers, double space, punctuation, lower casing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4383344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'httpS+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/S+', '', tweet) # rempve bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RTs@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet\n",
    "\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\]^_`{|}~‚Ä¢@'\n",
    "    \n",
    "def preprocess(sent):\n",
    "    sent = remove_users(sent)\n",
    "    sent = remove_links(sent)\n",
    "    sent = sent.lower() # lower case\n",
    "    sent = re.sub('['+my_punctuation + ']+', ' ', sent) # strip punctuation\n",
    "    sent = re.sub('s+', ' ', sent) #remove double spacing\n",
    "    sent = re.sub('([0-9]+)', '', sent) # remove numbers\n",
    "    sent_token_list = [word for word in sent.split(' ')]\n",
    "    sent = ' '.join(sent_token_list)\n",
    "    return sent\n",
    "\n",
    "train_df['tweet']   = train_df['tweet'].apply(lambda x: preprocess(x))\n",
    "test_df['tweet'] = test_df['tweet'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d444641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet', 'label', 'char_count', 'word_count', 'sent_count',\n",
       "       'capital_char_count', 'capital_word_count', 'quoted_word_count',\n",
       "       'stopword_count', 'unique_word_count', 'htag_count', 'mention_count',\n",
       "       'avg_wordlength', 'avg_sentlength', 'unique_vs_words',\n",
       "       'stopwords_vs_words', '! count', '\" count', '# count', '$ count',\n",
       "       '% count', '& count', '' count', '( count', ') count', '* count',\n",
       "       '+ count', ', count', '- count', '. count', '/ count', ': count',\n",
       "       '; count', '< count', '= count', '> count', '? count', '@ count',\n",
       "       '[ count', '\\ count', '] count', '^ count', '_ count', '` count',\n",
       "       '{ count', '| count', '} count', '~ count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d173f34",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Encoding text</font>\n",
    "We will encode our text data using TF-IDF. We first fit transform on our train and test set‚Äôs tweet column and then merge it with all features columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d1035074",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorizer            =  TfidfVectorizer()\n",
    "train_tf_idf_features =  vectorizer.fit_transform(train_df['tweet']).toarray()\n",
    "test_tf_idf_features  =  vectorizer.transform(test_df['tweet']).toarray()\n",
    "\n",
    "# Converting above list to DataFrame\n",
    "train_tf_idf_df          = pd.DataFrame(train_tf_idf_features)\n",
    "test_tf_idf_df           = pd.DataFrame(test_tf_idf_features)\n",
    "\n",
    "# Saparating train and test labels from all features\n",
    "y_train               = train_df['label']\n",
    "y_test                = test_df['label']\n",
    "\n",
    "#Listing all features\n",
    "features = ['char_count', 'word_count', 'sent_count',\n",
    "       'capital_char_count', 'capital_word_count', 'quoted_word_count',\n",
    "       'stopword_count', 'unique_word_count', 'htag_count', 'mention_count',\n",
    "       'avg_wordlength', 'avg_sentlength', 'unique_vs_words',\n",
    "       'stopwords_vs_words', '! count', '\" count', '# count', '$ count',\n",
    "       '% count', '& count', '\\' count', '( count', ') count', '* count',\n",
    "       '+ count', ', count', '- count', '. count', '/ count', ': count',\n",
    "       '; count', '< count', '= count', '> count', '? count', '@ count',\n",
    "       '[ count', '\\ count', '] count', '^ count', '_ count', '` count',\n",
    "       '{ count', '| count', '} count', '~ count']\n",
    "\n",
    "# Finally merging all features with above TF-IDF. \n",
    "X_train = pd.merge(train_tf_idf_df, train_df[features], left_index=True, right_index=True)\n",
    "X_test  = pd.merge(test_tf_idf_df, test_df[features], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "910aa79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>[ count</th>\n",
       "      <th>\\ count</th>\n",
       "      <th>] count</th>\n",
       "      <th>^ count</th>\n",
       "      <th>_ count</th>\n",
       "      <th>` count</th>\n",
       "      <th>{ count</th>\n",
       "      <th>| count</th>\n",
       "      <th>} count</th>\n",
       "      <th>~ count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 13918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  [ count  \\ count  \\\n",
       "4802  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        0        0   \n",
       "1230  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        0        0   \n",
       "5822  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        0        0   \n",
       "\n",
       "      ] count  ^ count  _ count  ` count  { count  | count  } count  ~ count  \n",
       "4802        0        0        0        0        0        0        0        0  \n",
       "1230        0        0        0        0        0        0        0        0  \n",
       "5822        0        0        0        0        0        0        0        0  \n",
       "\n",
       "[3 rows x 13918 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6896c25",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Training</font>\n",
    "For training, we will be using the Random forest algorithm ([**RandomForestClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)) from the sci-kit learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eb41dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Github/ml_courses/env/lib/python3.8/site-packages/sklearn/utils/validation.py:1673: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 4.77 s, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=15, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_model = RandomForestClassifier(\n",
    "    n_estimators = 1000, min_samples_split = 15, random_state = RANDOM_STATE)\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "610090c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b7472cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real',\n",
       "       'fake', 'fake'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5492abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.4%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.97      0.89      0.93      1020\n",
      "        real       0.91      0.97      0.94      1120\n",
      "\n",
      "    accuracy                           0.93      2140\n",
      "   macro avg       0.94      0.93      0.93      2140\n",
      "weighted avg       0.94      0.93      0.93      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.01%}')\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e713f83c",
   "metadata": {},
   "source": [
    "<a id='sect4'></a>\n",
    "## <font color='darkblue'>Result comparison</font> ([back](#sect0))\n",
    "* <font size='3ptx'><b><a href='#sect4_1'>Without using Feature Engineering techniques</a></b></font>\n",
    "* <font size='3ptx'><b><a href='#sect4_2'>Using Feature Engineering techniques</a></b></font>\n",
    "<br/>\n",
    "\n",
    "<font size='3ptx'><b>For comparison, we first trained our model on the above dataset by using features engineering techniques and then without using feature engineering techniques</b></font>.\n",
    "\n",
    "In both approaches, we pre-processed the dataset using the same method as described above and TF-IDF was used in both approaches for encoding the text data. You can use whatever encoding techniques you want to use like word2vec, glove, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b7b8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb58a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_perf_data(y_pred, name, feature_size):\n",
    "    y_test_binary = [1 if label=='fake' else 0 for label in y_test]\n",
    "    y_pred_binary = [1 if label=='fake' else 0 for label in y_pred]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    perf_data.append((\n",
    "        name,\n",
    "        feature_size,\n",
    "        accuracy,\n",
    "        recall_score(y_test_binary, y_pred_binary),\n",
    "        precision_score(y_test_binary, y_pred_binary),\n",
    "        f1_score(y_test_binary, y_pred_binary)))\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.01%}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return perf_data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12474b58",
   "metadata": {},
   "source": [
    "<a id='sect4_1'></a>\n",
    "### <font color='darkgreen'>Without using Feature Engineering techniques</font>\n",
    "Here we only use features tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1c26e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 31s, sys: 159 ms, total: 9min 31s\n",
      "Wall time: 9min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=15, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_model = RandomForestClassifier(\n",
    "    n_estimators = 1000, min_samples_split = 15, random_state = RANDOM_STATE)\n",
    "clf_model.fit(train_tf_idf_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3ca1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(test_tf_idf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "680ca4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.2%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.87      0.90      1020\n",
      "        real       0.89      0.95      0.92      1120\n",
      "\n",
      "    accuracy                           0.91      2140\n",
      "   macro avg       0.91      0.91      0.91      2140\n",
      "weighted avg       0.91      0.91      0.91      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tf-idf',\n",
       " 13872,\n",
       " 0.9121495327102803,\n",
       " 0.8745098039215686,\n",
       " 0.9369747899159664,\n",
       " 0.9046653144016227)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_perf_data(y_pred, 'tf-idf', train_tf_idf_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f08a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data.append(\n",
    "    ('randomforest + tf-idf',\n",
    "     13872,\n",
    "     0.9121495327102803,\n",
    "     0.8745098039215686,\n",
    "     0.9369747899159664,\n",
    "     0.9046653144016227))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9726b",
   "metadata": {},
   "source": [
    "<a id='sect4_2'></a>\n",
    "### <font color='darkgreen'>Using Feature Engineering techniques</font>\n",
    "Here we used up all features we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67f300b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Github/ml_courses/env/lib/python3.8/site-packages/sklearn/utils/validation.py:1673: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 264 ms, total: 2min 2s\n",
      "Wall time: 2min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=15, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_model = RandomForestClassifier(\n",
    "    n_estimators = 1000, min_samples_split = 15, random_state = RANDOM_STATE)\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6cd1a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "470afe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.4%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.97      0.89      0.93      1020\n",
      "        real       0.91      0.97      0.94      1120\n",
      "\n",
      "    accuracy                           0.93      2140\n",
      "   macro avg       0.94      0.93      0.93      2140\n",
      "weighted avg       0.94      0.93      0.93      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tf-idf + feature engineering',\n",
       " 13918,\n",
       " 0.9336448598130841,\n",
       " 0.8911764705882353,\n",
       " 0.9670212765957447,\n",
       " 0.9275510204081633)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_perf_data(y_pred, 'tf-idf + feature engineering', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d36ade8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data.append(\n",
    "    ('randomforest + tf-idf + feature engineering',\n",
    "     13918,\n",
    "     0.9336448598130841,\n",
    "     0.8911764705882353,\n",
    "     0.9670212765957447,\n",
    "     0.9275510204081633))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbdc80",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Replace tf-idf with word-vector</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29774108",
   "metadata": {},
   "source": [
    "Here we use [**word2vec**](https://en.wikipedia.org/wiki/Word2vec) to replace tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1e9d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install gensim\n",
    "test_tf_idf_features = train_tf_idf_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "daea3c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ddda68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_feature_names = [f'w{i}' for i in range(300)]\n",
    "\n",
    "def text2w2v(df, column='tweet'):\n",
    "    \"\"\"Turns text into word2vect\"\"\"\n",
    "    model = api.load(\"word2vec-google-news-300\") \n",
    "    wv_list = []\n",
    "    for ri, row in df.iterrows():\n",
    "        vector = np.zeros(300)\n",
    "        for w in row.get(column).split():\n",
    "            try:\n",
    "                vector += model[w]\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "        wv_list.append(vector)\n",
    "        \n",
    "    w2v_df = pd.DataFrame(wv_list, columns=[f'w{i}' for i in range(300)])\n",
    "    df = pd.concat([df, w2v_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cbf1d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 s, sys: 59.4 s, total: 1min 30s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = text2w2v(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4478f180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.5 s, sys: 1.25 s, total: 53.8 s\n",
      "Wall time: 54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = text2w2v(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de464c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6420, 349)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>...</th>\n",
       "      <th>w290</th>\n",
       "      <th>w291</th>\n",
       "      <th>w292</th>\n",
       "      <th>w293</th>\n",
       "      <th>w294</th>\n",
       "      <th>w295</th>\n",
       "      <th>w296</th>\n",
       "      <th>w297</th>\n",
       "      <th>w298</th>\n",
       "      <th>w299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>3786</td>\n",
       "      <td>rt   in a  uo moto  tatement in #lok abha on #...</td>\n",
       "      <td>real</td>\n",
       "      <td>138</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143005</td>\n",
       "      <td>0.065186</td>\n",
       "      <td>-0.672852</td>\n",
       "      <td>0.352051</td>\n",
       "      <td>0.093506</td>\n",
       "      <td>-0.524475</td>\n",
       "      <td>-0.694763</td>\n",
       "      <td>0.398315</td>\n",
       "      <td>-1.125122</td>\n",
       "      <td>0.199860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>4478</td>\n",
       "      <td>new rule  banning  ocial gathering  of more th...</td>\n",
       "      <td>real</td>\n",
       "      <td>218</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.912689</td>\n",
       "      <td>1.234344</td>\n",
       "      <td>-1.290840</td>\n",
       "      <td>-0.918701</td>\n",
       "      <td>-1.965206</td>\n",
       "      <td>-1.078857</td>\n",
       "      <td>0.563293</td>\n",
       "      <td>-1.158279</td>\n",
       "      <td>1.134354</td>\n",
       "      <td>0.016987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>3860</td>\n",
       "      <td>rt   if you have recovered from #covid confirm...</td>\n",
       "      <td>real</td>\n",
       "      <td>138</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.746460</td>\n",
       "      <td>0.267296</td>\n",
       "      <td>-1.561256</td>\n",
       "      <td>0.951660</td>\n",
       "      <td>0.596375</td>\n",
       "      <td>-0.697601</td>\n",
       "      <td>-0.319214</td>\n",
       "      <td>-2.548584</td>\n",
       "      <td>-0.775101</td>\n",
       "      <td>0.031555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet label  \\\n",
       "3785  3786  rt   in a  uo moto  tatement in #lok abha on #...  real   \n",
       "4477  4478  new rule  banning  ocial gathering  of more th...  real   \n",
       "3859  3860  rt   if you have recovered from #covid confirm...  real   \n",
       "\n",
       "      char_count  word_count  sent_count  capital_char_count  \\\n",
       "3785         138          19           1                  20   \n",
       "4477         218          39           3                   5   \n",
       "3859         138          23           2                  13   \n",
       "\n",
       "      capital_word_count  quoted_word_count  stopword_count  ...      w290  \\\n",
       "3785                   3                  0               5  ... -0.143005   \n",
       "4477                   0                  0              18  ... -0.912689   \n",
       "3859                   2                  0               7  ... -0.746460   \n",
       "\n",
       "          w291      w292      w293      w294      w295      w296      w297  \\\n",
       "3785  0.065186 -0.672852  0.352051  0.093506 -0.524475 -0.694763  0.398315   \n",
       "4477  1.234344 -1.290840 -0.918701 -1.965206 -1.078857  0.563293 -1.158279   \n",
       "3859  0.267296 -1.561256  0.951660  0.596375 -0.697601 -0.319214 -2.548584   \n",
       "\n",
       "          w298      w299  \n",
       "3785 -1.125122  0.199860  \n",
       "4477  1.134354  0.016987  \n",
       "3859 -0.775101  0.031555  \n",
       "\n",
       "[3 rows x 349 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97c217ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[features + w2v_feature_names]\n",
    "X_test  = test_df[features + w2v_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c64ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 12 ms, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=15, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_model = RandomForestClassifier(\n",
    "    n_estimators = 1000, min_samples_split = 15, random_state = RANDOM_STATE)\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcc4e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48172e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.8%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.87      0.90      1020\n",
      "        real       0.89      0.94      0.91      1120\n",
      "\n",
      "    accuracy                           0.91      2140\n",
      "   macro avg       0.91      0.91      0.91      2140\n",
      "weighted avg       0.91      0.91      0.91      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('word2vec + feature engineering',\n",
       " 346,\n",
       " 0.908411214953271,\n",
       " 0.8725490196078431,\n",
       " 0.9309623430962343,\n",
       " 0.9008097165991903)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_perf_data(y_pred, 'word2vec + feature engineering', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61e90e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data.append(\n",
    "    ('randomforest + word2vec + feature engineering',\n",
    "     346,\n",
    "     0.908411214953271,\n",
    "     0.8725490196078431,\n",
    "     0.9309623430962343,\n",
    "     0.9008097165991903)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f80b47",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>SVC + word2vec + feature engineering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42716ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.8 s, sys: 36 ms, total: 4.83 s\n",
      "Wall time: 4.83 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_model = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3100720",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f9528cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.9%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.92      0.93      1020\n",
      "        real       0.93      0.94      0.93      1120\n",
      "\n",
      "    accuracy                           0.93      2140\n",
      "   macro avg       0.93      0.93      0.93      2140\n",
      "weighted avg       0.93      0.93      0.93      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('SVC + word2vec + feature engineering',\n",
       " 346,\n",
       " 0.9294392523364486,\n",
       " 0.9215686274509803,\n",
       " 0.9297725024727992,\n",
       " 0.9256523879862137)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_perf_data(y_pred, 'SVC + word2vec + feature engineering', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea693275",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data.append(\n",
    "    ('SVC + word2vec + feature engineering',\n",
    "     346,\n",
    "     0.9294392523364486,\n",
    "     0.9215686274509803,\n",
    "     0.9297725024727992,\n",
    "     0.9256523879862137)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afe37b7",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>SVC (Grid search) + word2vec + feature engineering</font>\n",
    "Please refer to [\"Searching for optimal parameters with successive halving\"](https://scikit-learn.org/stable/modules/grid_search.html#searching-for-optimal-parameters-with-successive-halving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb3fe9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  11.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  10.9s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  10.7s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  10.9s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  10.9s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  29.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  35.1s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  31.3s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  40.2s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=  33.7s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  11.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  11.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  11.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  11.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  11.4s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  34.1s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  32.2s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  34.7s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  42.6s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  33.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  11.5s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.7s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.5s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.6s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.6s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  29.9s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  31.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  34.3s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  38.6s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  28.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  10.6s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  10.7s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  10.7s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  10.6s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  10.9s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  29.2s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  35.1s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  31.1s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  40.8s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=  33.8s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  11.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  11.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  11.4s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  11.1s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  11.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  34.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  32.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  34.1s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  42.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  33.3s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  10.3s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   9.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   9.6s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   9.6s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   9.4s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  30.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  31.8s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  34.4s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  38.9s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  28.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.6s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.4s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  29.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  35.2s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  31.4s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  40.2s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=  33.9s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.7s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.7s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.9s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.6s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  38.7s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  35.2s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  34.1s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  41.7s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=  33.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  10.8s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.9s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.9s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.7s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=  10.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  29.8s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  31.7s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  34.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  38.7s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=  28.2s\n",
      "CPU times: user 34min 29s, sys: 1.91 s, total: 34min 31s\n",
      "Wall time: 34min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01],\n",
       "                         'kernel': ['rbf', 'poly']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01 ],'kernel': ['rbf', 'poly']}\n",
    "#base_estimator = SVC(gamma='scale')\n",
    "#sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "#                         factor=2, max_resources=40,\n",
    "#                         aggressive_elimination=False).fit(X_train, y_train)\n",
    "grid = GridSearchCV(\n",
    "    SVC(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train,y_train)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da5f445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa6c9e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.1%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.90      0.94      0.92      1020\n",
      "        real       0.94      0.91      0.92      1120\n",
      "\n",
      "    accuracy                           0.92      2140\n",
      "   macro avg       0.92      0.92      0.92      2140\n",
      "weighted avg       0.92      0.92      0.92      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Grid search SVC + word2vec + feature engineering',\n",
       " 346,\n",
       " 0.9205607476635514,\n",
       " 0.9362745098039216,\n",
       " 0.9009433962264151,\n",
       " 0.9182692307692307)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_perf_data(y_pred, 'Grid search SVC + word2vec + feature engineering', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25896d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data.append(\n",
    "    ('Grid search SVC + word2vec + feature engineering',\n",
    "     346,\n",
    "     0.9205607476635514,\n",
    "     0.9362745098039216,\n",
    "     0.9009433962264151,\n",
    "     0.9182692307692307)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c89629",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>SVC + tf-idf + feature engineering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90647bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally merging all features with above TF-IDF. \n",
    "X_train = pd.merge(pd.DataFrame(vectorizer.transform(train_df['tweet']).toarray()),\n",
    "                   train_df[features], left_index=True, right_index=True)\n",
    "X_test  = pd.merge(pd.DataFrame(vectorizer.transform(test_df['tweet']).toarray()),\n",
    "                   test_df[features], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e17fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6420, 13918)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>[ count</th>\n",
       "      <th>\\ count</th>\n",
       "      <th>] count</th>\n",
       "      <th>^ count</th>\n",
       "      <th>_ count</th>\n",
       "      <th>` count</th>\n",
       "      <th>{ count</th>\n",
       "      <th>| count</th>\n",
       "      <th>} count</th>\n",
       "      <th>~ count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 13918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  [ count  \\ count  \\\n",
       "1326  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        0        0   \n",
       "5090  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        0        0   \n",
       "2474  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...        0        0   \n",
       "\n",
       "      ] count  ^ count  _ count  ` count  { count  | count  } count  ~ count  \n",
       "1326        0        0        0        0        0        0        0        0  \n",
       "5090        0        0        0        0        0        0        0        0  \n",
       "2474        0        0        0        0        0        0        0        0  \n",
       "\n",
       "[3 rows x 13918 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d560e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'f-{i}' for i in range(X_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc2bfc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_test.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87dec530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 34s, sys: 4min 5s, total: 21min 40s\n",
      "Wall time: 5min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC())])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_model = make_pipeline(StandardScaler(), SVC())\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7fa3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c385fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.6%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.91      0.92      1020\n",
      "        real       0.92      0.94      0.93      1120\n",
      "\n",
      "    accuracy                           0.93      2140\n",
      "   macro avg       0.93      0.93      0.93      2140\n",
      "weighted avg       0.93      0.93      0.93      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('SVC + tf-idf + feature engineering',\n",
       " 13918,\n",
       " 0.9257009345794392,\n",
       " 0.9137254901960784,\n",
       " 0.9292123629112662,\n",
       " 0.921403855659911)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_perf_data(y_pred, 'SVC + tf-idf + feature engineering', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "996255a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data.append(\n",
    "    ('SVC + tf-idf + feature engineering',\n",
    "     13918,\n",
    "     0.9257009345794392,\n",
    "     0.9137254901960784,\n",
    "     0.9292123629112662,\n",
    "     0.921403855659911)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb28f667",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'> Grid search SVC + tf-idf + feature engineering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16919afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=14.6min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time= 8.3min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=10.4min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=11.0min\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time= 7.0min\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time= 8.9min\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time= 6.3min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=13.0min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=10.8min\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time= 7.6min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=11.6min\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time= 7.0min\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time= 7.0min\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time= 7.9min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=11.2min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=10.4min\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time= 7.3min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=12.2min\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time= 7.3min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 6.3min\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time= 7.8min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=14.4min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 9.5min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=11.1min\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time= 5.6min\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time= 6.7min\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time= 8.6min\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time= 7.1min\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time= 8.6min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=14.1min\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time= 7.4min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=12.3min\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time= 8.4min\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time= 5.4min\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time= 7.5min\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time= 6.3min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=12.9min\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time= 5.0min\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time= 6.4min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=12.7min\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time= 7.6min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 4.9min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 6.6min\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time= 5.8min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=14.5min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time= 5.4min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time= 7.2min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=12.2min\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time= 7.6min\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time= 8.5min\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time= 7.4min\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time= 7.1min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=14.7min\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time= 7.6min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=11.8min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 9.4min\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time= 8.0min\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time= 6.8min\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time= 6.4min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=13.2min\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time= 7.3min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=11.8min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 9.7min\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time= 7.5min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 6.3min\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time= 5.7min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=14.7min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time= 8.0min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time= 8.4min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=11.9min\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time= 6.4min\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time= 9.4min\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time= 8.3min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=13.4min\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time= 5.3min\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time= 6.9min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=11.6min\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time= 5.3min\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time= 7.1min\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time= 6.6min\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time= 5.1min\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time= 7.7min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=12.7min\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time= 6.5min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=11.8min\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time= 5.3min\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time= 7.0min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 6.0min\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time= 5.3min\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time= 6.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01],\n",
       "                         'kernel': ['rbf', 'poly']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01],'kernel': ['rbf', 'poly']}\n",
    "grid = GridSearchCV(\n",
    "    SVC(), param_grid, refit=True, verbose=2, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9325ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30fb31a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.3%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.95      0.94      1020\n",
      "        real       0.96      0.93      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Gridsearch SVC + tf-idf + feature engineering',\n",
       " 13918,\n",
       " 0.9425233644859813,\n",
       " 0.9519607843137254,\n",
       " 0.9291866028708134,\n",
       " 0.9404358353510895)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_perf_data(y_pred, 'Gridsearch SVC + tf-idf + feature engineering', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "614a4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data.append(\n",
    "    ('Gridsearch SVC + tf-idf + feature engineering',\n",
    "     13918,\n",
    "     0.9425233644859813,\n",
    "     0.9519607843137254,\n",
    "     0.9291866028708134,\n",
    "     0.9404358353510895)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24dbbc",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>SVC + tf-idf + feature engineering + 2gram(100)</font>\n",
    "Here we add 100 more features of 2 grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7a272730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoGramFeatures:\n",
    "    \"\"\"Class to collect 2gram features.\n",
    "    \n",
    "    Attributes:\n",
    "        top_n: Number of 2gram to collect.\n",
    "        min_doc_count: The limitation of minimum doc which 2gram should exist\n",
    "            in order to be collected.\n",
    "        text_column_name: The column name of dataframe as text to search for 2gram.\n",
    "        label_column_name: The column name of dataframe as labeling result.\n",
    "        fit_history: dict object with key as collected 2gram and value as its meta data\n",
    "            such as score and doc count.\n",
    "        fit_gram_list: The collrected 2gram list after fit.\n",
    "    \"\"\"\n",
    "    HEAD_TOKEN_PLACEHOLDER = '__HEAD_TOKEN__'\n",
    "\n",
    "    def __init__(self, text_column_name, label_column_name, top_n=100, min_doc_count=10):\n",
    "        self.top_n = top_n\n",
    "        self.min_doc_count = min_doc_count\n",
    "        self.text_column_name = text_column_name\n",
    "        self.label_column_name = label_column_name\n",
    "        self.fit_history = {}\n",
    "        self.fit_gram_list = ()\n",
    "        self._tokenizer_words = TweetTokenizer()\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TwoGramFeatures(min_doc_count={self.min_doc_count}, top_n={self.top_n}): {len(self.fit_history)} 2gram(s)'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fit_gram_list)\n",
    "        \n",
    "    def _reverse_entropy(self, prob_list):\n",
    "        \"\"\"Calculate the entropy of given probability list and take the reciprocal of it.\n",
    "        \n",
    "        For how to calculate entropy, please refer to:\n",
    "        https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
    "        \n",
    "        Below are few examples for reference:\n",
    "        ```\n",
    "        (0, 1) with reverse-entropy as 9223372036854775807\n",
    "        (1, 0) with reverse-entropy as 9223372036854775807\n",
    "        (0.99, 0.01) with reverse-entropy as 17.85665359923201\n",
    "        (0.1, 0.9) with reverse-entropy as 3.0761377305228823\n",
    "        (0.3, 0.7) with reverse-entropy as 1.6370247805217761\n",
    "        (0.5, 0.5) with reverse-entropy as 1.4426950408889634\n",
    "        (0.3, 0.3, 0.3, 0.1) with reverse-entropy as 0.7611311434594984\n",
    "        ```\n",
    "        \n",
    "        Args:\n",
    "            prob_list: Probability list with sum up to 1.\n",
    "            \n",
    "        Returns:\n",
    "            The reciprocal of entropy.\n",
    "        \"\"\"\n",
    "        entropy_val = 0\n",
    "        for prob in prob_list:\n",
    "            if prob == 0:\n",
    "                continue\n",
    "            if prob == 1:\n",
    "                break\n",
    "\n",
    "            entropy_val += -1 * math.log(prob) * prob\n",
    "\n",
    "        return 1/entropy_val if entropy_val else sys.maxsize\n",
    "        \n",
    "    def _gen_2grams(self, text_content):\n",
    "        \"\"\"Generates the 2gram counter.\"\"\"\n",
    "        token_counter = Counter()        \n",
    "        for token_list in [self._tokenizer_words.tokenize(t) for t in nltk.sent_tokenize(text_content)]:\n",
    "            first_token = token_list[0]\n",
    "            for token in token_list[1:]:\n",
    "                token_counter.update({(first_token, token): 1})\n",
    "                token = first_token\n",
    "            \n",
    "        return token_counter\n",
    "        \n",
    "    def fit(self, df):\n",
    "        \"\"\"Fits the dataframe to collect 2gram information.\"\"\"\n",
    "        self.fit_history = {}\n",
    "        self.fit_gram_list = ()\n",
    "        doc_count = df.shape[0]\n",
    "        token_doc_counter = Counter()\n",
    "        token_label_dict = {}\n",
    "        for ri, row in df.iterrows():\n",
    "            label = row.get(self.label_column_name)\n",
    "            text_content = row.get(self.text_column_name)\n",
    "            gram_counter = self._gen_2grams(text_content)\n",
    "            for gram in gram_counter.keys():\n",
    "                token_doc_counter.update({gram: 1})\n",
    "                if gram in token_label_dict:\n",
    "                    token_label_dict[gram][label] += 1\n",
    "                else:\n",
    "                    token_label_dict[gram] = defaultdict(int)\n",
    "                    token_label_dict[gram][label] += 1\n",
    "        \n",
    "        # Start calculating score and sorting the result\n",
    "        toke_score_dict = {}\n",
    "        for gram, doc_count in token_doc_counter.items():\n",
    "            gram_label_count_list = token_label_dict[gram].values()\n",
    "            selected_label = max(token_label_dict[gram].items(), key=lambda t: t[1])[0]\n",
    "            gram_label_count_sum = sum(gram_label_count_list)\n",
    "            prob_list = [count/gram_label_count_sum for count in gram_label_count_list]\n",
    "            score = self._reverse_entropy(prob_list)\n",
    "            toke_score_dict[gram] = (score, token_doc_counter[gram], selected_label)\n",
    "            \n",
    "        self.fit_history = sorted(filter(\n",
    "            lambda t: t[1][1] >= self.min_doc_count,\n",
    "            toke_score_dict.items()), key=lambda t: t[1], reverse=True)[:self.top_n]\n",
    "        self.fit_gram_list = list(map(lambda t: t[0], self.fit_history))\n",
    "        \n",
    "    def transform(self, df):\n",
    "        \"\"\"Transforms the input dataframe into 2gram feature array.\"\"\"\n",
    "        datas = []\n",
    "        for ri, row in df.iterrows():\n",
    "            data = []\n",
    "            gram_counter = self._gen_2grams(row.get(self.text_column_name))\n",
    "            for gram in self.fit_gram_list:\n",
    "                data.append(gram_counter.get(gram, 0))\n",
    "                \n",
    "            datas.append(data)\n",
    "            \n",
    "        return np.array(datas)\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        \"\"\"Fits and transforms the input dataframe into 2gram feature array.\"\"\"\n",
    "        if not self.fit_history:\n",
    "            self.fit(df)\n",
    "            \n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8b3b8fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.99 s, sys: 231 ¬µs, total: 6.99 s\n",
      "Wall time: 6.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "two_gram_feats       =  TwoGramFeatures(text_column_name='tweet', label_column_name='label', top_n=150, min_doc_count=70)\n",
    "train_2gram_features =  two_gram_feats.fit_transform(train_df)\n",
    "test_2gram_features  =  two_gram_feats.transform(test_df)\n",
    "\n",
    "# Converting above list to DataFrame\n",
    "train_2gram_df          = pd.DataFrame(train_2gram_features,\n",
    "                                       columns=[f'2gram_{i}' for i in range(train_2gram_features.shape[1])])\n",
    "test_2gram_df           = pd.DataFrame(test_2gram_features,\n",
    "                                       columns=[f'2gram_{i}' for i in range(test_2gram_features.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0d29c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoGramFeatures(min_doc_count=70, top_n=150): 146 2gram(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('the', 'in'), (1.5409374900486654, 244, 'real')),\n",
       " (('the', 'and'), (1.5321818892033032, 184, 'real')),\n",
       " (('‚Äú', '‚Äù'), (1.5211716964420314, 79, 'real')),\n",
       " (('new', 'http'), (1.5115712940524648, 216, 'real')),\n",
       " (('new', 'co'), (1.5115712940524648, 216, 'real')),\n",
       " (('new', 'in'), (1.5115712940524648, 80, 'real')),\n",
       " (('the', 'the'), (1.5069846308721047, 343, 'real')),\n",
       " (('new', 'a'), (1.5053970611059928, 92, 'real')),\n",
       " (('new', 't'), (1.4979812997754336, 222, 'real')),\n",
       " (('the', 'that'), (1.4840344036129642, 97, 'real')),\n",
       " (('the', 'ha'), (1.4829071420985505, 119, 'real')),\n",
       " (('the', 'a'), (1.4812687067121846, 227, 'real')),\n",
       " (('the', 'i'), (1.4704089646857075, 217, 'real')),\n",
       " (('a', 'india'), (1.463225517964234, 79, 'real')),\n",
       " (('a', 'of'), (1.4576721754261794, 302, 'fake')),\n",
       " (('a', 't'), (1.45434081537911, 266, 'real')),\n",
       " (('a', 'for'), (1.4470427872201101, 124, 'fake')),\n",
       " (('the', 'it'), (1.4461030778165422, 70, 'fake')),\n",
       " (('the', 'covid'), (1.4440431617274436, 139, 'real')),\n",
       " (('a', 'e'), (1.443119920716149, 198, 'fake'))]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(two_gram_feats)\n",
    "list(two_gram_feats.fit_history[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "71c55948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2gram_0</th>\n",
       "      <th>2gram_1</th>\n",
       "      <th>2gram_2</th>\n",
       "      <th>2gram_3</th>\n",
       "      <th>2gram_4</th>\n",
       "      <th>2gram_5</th>\n",
       "      <th>2gram_6</th>\n",
       "      <th>2gram_7</th>\n",
       "      <th>2gram_8</th>\n",
       "      <th>2gram_9</th>\n",
       "      <th>...</th>\n",
       "      <th>2gram_136</th>\n",
       "      <th>2gram_137</th>\n",
       "      <th>2gram_138</th>\n",
       "      <th>2gram_139</th>\n",
       "      <th>2gram_140</th>\n",
       "      <th>2gram_141</th>\n",
       "      <th>2gram_142</th>\n",
       "      <th>2gram_143</th>\n",
       "      <th>2gram_144</th>\n",
       "      <th>2gram_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      2gram_0  2gram_1  2gram_2  2gram_3  2gram_4  2gram_5  2gram_6  2gram_7  \\\n",
       "5546        0        0        0        0        0        0        0        0   \n",
       "4021        0        0        0        0        0        0        0        0   \n",
       "3126        0        0        0        0        0        0        0        0   \n",
       "\n",
       "      2gram_8  2gram_9  ...  2gram_136  2gram_137  2gram_138  2gram_139  \\\n",
       "5546        0        0  ...          0          0          0          0   \n",
       "4021        0        0  ...          0          0          0          0   \n",
       "3126        0        0  ...          0          0          0          0   \n",
       "\n",
       "      2gram_140  2gram_141  2gram_142  2gram_143  2gram_144  2gram_145  \n",
       "5546          0          0          0          0          0          0  \n",
       "4021          0          0          0          0          0          0  \n",
       "3126          0          0          0          0          0          0  \n",
       "\n",
       "[3 rows x 146 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_2gram_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aace61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally merging all features with above TF-IDF. \n",
    "X_train = pd.concat([train_df[features], train_2gram_df, train_tf_idf_df], axis=1)\n",
    "X_test  = pd.concat([test_df[features], test_2gram_df, test_tf_idf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3a433e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6420, 14064)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>htag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>...</th>\n",
       "      <th>13862</th>\n",
       "      <th>13863</th>\n",
       "      <th>13864</th>\n",
       "      <th>13865</th>\n",
       "      <th>13866</th>\n",
       "      <th>13867</th>\n",
       "      <th>13868</th>\n",
       "      <th>13869</th>\n",
       "      <th>13870</th>\n",
       "      <th>13871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>144</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>130</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 14064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      char_count  word_count  sent_count  capital_char_count  \\\n",
       "2029         144          17           2                   4   \n",
       "623           87          15           1                   7   \n",
       "6175         130          19           1                   8   \n",
       "\n",
       "      capital_word_count  quoted_word_count  stopword_count  \\\n",
       "2029                   0                  0               5   \n",
       "623                    1                  0               7   \n",
       "6175                   0                  0               7   \n",
       "\n",
       "      unique_word_count  htag_count  mention_count  ...  13862  13863  13864  \\\n",
       "2029                 17           0              0  ...    0.0    0.0    0.0   \n",
       "623                  15           0              0  ...    0.0    0.0    0.0   \n",
       "6175                 19           0              0  ...    0.0    0.0    0.0   \n",
       "\n",
       "      13865  13866  13867  13868  13869  13870  13871  \n",
       "2029    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "623     0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "6175    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 14064 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7821d835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 14064)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>htag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>...</th>\n",
       "      <th>13862</th>\n",
       "      <th>13863</th>\n",
       "      <th>13864</th>\n",
       "      <th>13865</th>\n",
       "      <th>13866</th>\n",
       "      <th>13867</th>\n",
       "      <th>13868</th>\n",
       "      <th>13869</th>\n",
       "      <th>13870</th>\n",
       "      <th>13871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>142</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>278</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>274</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 14064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      char_count  word_count  sent_count  capital_char_count  \\\n",
       "1234         142          14           2                  13   \n",
       "46           278          36           2                  22   \n",
       "423          274          42           3                   9   \n",
       "\n",
       "      capital_word_count  quoted_word_count  stopword_count  \\\n",
       "1234                   0                  0               2   \n",
       "46                     2                  0               7   \n",
       "423                    0                  0              19   \n",
       "\n",
       "      unique_word_count  htag_count  mention_count  ...  13862  13863  13864  \\\n",
       "1234                 14           0              0  ...    0.0    0.0    0.0   \n",
       "46                   25           0              0  ...    0.0    0.0    0.0   \n",
       "423                  37           0              0  ...    0.0    0.0    0.0   \n",
       "\n",
       "      13865  13866  13867  13868  13869  13870  13871  \n",
       "1234    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "46      0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "423     0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 14064 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "X_test.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "963cc3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 23s, sys: 4min 47s, total: 22min 10s\n",
      "Wall time: 5min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_model = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2518b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "959f7d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.5%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.93      0.93      1020\n",
      "        real       0.94      0.94      0.94      1120\n",
      "\n",
      "    accuracy                           0.93      2140\n",
      "   macro avg       0.93      0.93      0.93      2140\n",
      "weighted avg       0.93      0.93      0.93      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=70, top_n=150): 146 2gram(s)',\n",
       " 14064,\n",
       " 0.9345794392523364,\n",
       " 0.9284313725490196,\n",
       " 0.9339250493096647,\n",
       " 0.9311701081612587)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_perf_data(y_pred, f'SVC + tf-idf + feature engineering + {two_gram_feats}', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7b767",
   "metadata": {},
   "source": [
    "<a id='sect5'></a>\n",
    "## <font color='darkblue'>Conclusion</font> ([back](#sect0))\n",
    "Then we can evaluate and sort them according to interested metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "929c8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame(perf_data, columns=['name', 'feature size', 'accuracy', 'recall', 'precision', 'f1'])\n",
    "perf_df = perf_df.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d75f8c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gridsearch SVC + tf-idf + feature engineering</th>\n",
       "      <td>13918</td>\n",
       "      <td>0.942523</td>\n",
       "      <td>0.951961</td>\n",
       "      <td>0.929187</td>\n",
       "      <td>0.940436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=70, top_n=150): 146 2gram(s)</th>\n",
       "      <td>14064</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.928431</td>\n",
       "      <td>0.933925</td>\n",
       "      <td>0.931170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=80, top_n=150): 118 2gram(s)</th>\n",
       "      <td>14036</td>\n",
       "      <td>0.934112</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.935580</td>\n",
       "      <td>0.930508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest + tf-idf + feature engineering</th>\n",
       "      <td>13918</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.891176</td>\n",
       "      <td>0.967021</td>\n",
       "      <td>0.927551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + &lt;__main__.TwoGramFeatures object at 0x7f6e676c7430&gt;</th>\n",
       "      <td>14014</td>\n",
       "      <td>0.932243</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.928395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + 2gram(150)</th>\n",
       "      <td>13993</td>\n",
       "      <td>0.930374</td>\n",
       "      <td>0.919608</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.926420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + word2vec + feature engineering</th>\n",
       "      <td>346</td>\n",
       "      <td>0.929439</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.929773</td>\n",
       "      <td>0.925652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + 2gram(100)</th>\n",
       "      <td>14018</td>\n",
       "      <td>0.929439</td>\n",
       "      <td>0.920588</td>\n",
       "      <td>0.930624</td>\n",
       "      <td>0.925579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + 2gram(150)</th>\n",
       "      <td>14068</td>\n",
       "      <td>0.928972</td>\n",
       "      <td>0.924510</td>\n",
       "      <td>0.926326</td>\n",
       "      <td>0.925417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering</th>\n",
       "      <td>13918</td>\n",
       "      <td>0.925701</td>\n",
       "      <td>0.913725</td>\n",
       "      <td>0.929212</td>\n",
       "      <td>0.921404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grid search SVC + word2vec + feature engineering</th>\n",
       "      <td>346</td>\n",
       "      <td>0.920561</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.900943</td>\n",
       "      <td>0.918269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest + tf-idf</th>\n",
       "      <td>13872</td>\n",
       "      <td>0.912150</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.936975</td>\n",
       "      <td>0.904665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest + word2vec + feature engineering</th>\n",
       "      <td>346</td>\n",
       "      <td>0.908411</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>0.930962</td>\n",
       "      <td>0.900810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    feature size  accuracy  \\\n",
       "name                                                                         \n",
       "Gridsearch SVC + tf-idf + feature engineering              13918  0.942523   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...         14064  0.934579   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...         14036  0.934112   \n",
       "randomforest + tf-idf + feature engineering                13918  0.933645   \n",
       "SVC + tf-idf + feature engineering + <__main__....         14014  0.932243   \n",
       "SVC + tf-idf + feature engineering + 2gram(150)            13993  0.930374   \n",
       "SVC + word2vec + feature engineering                         346  0.929439   \n",
       "SVC + tf-idf + feature engineering + 2gram(100)            14018  0.929439   \n",
       "SVC + tf-idf + feature engineering + 2gram(150)            14068  0.928972   \n",
       "SVC + tf-idf + feature engineering                         13918  0.925701   \n",
       "Grid search SVC + word2vec + feature engineering             346  0.920561   \n",
       "randomforest + tf-idf                                      13872  0.912150   \n",
       "randomforest + word2vec + feature engineering                346  0.908411   \n",
       "\n",
       "                                                      recall  precision  \\\n",
       "name                                                                      \n",
       "Gridsearch SVC + tf-idf + feature engineering       0.951961   0.929187   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.928431   0.933925   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.925490   0.935580   \n",
       "randomforest + tf-idf + feature engineering         0.891176   0.967021   \n",
       "SVC + tf-idf + feature engineering + <__main__....  0.921569   0.935323   \n",
       "SVC + tf-idf + feature engineering + 2gram(150)     0.919608   0.933333   \n",
       "SVC + word2vec + feature engineering                0.921569   0.929773   \n",
       "SVC + tf-idf + feature engineering + 2gram(100)     0.920588   0.930624   \n",
       "SVC + tf-idf + feature engineering + 2gram(150)     0.924510   0.926326   \n",
       "SVC + tf-idf + feature engineering                  0.913725   0.929212   \n",
       "Grid search SVC + word2vec + feature engineering    0.936275   0.900943   \n",
       "randomforest + tf-idf                               0.874510   0.936975   \n",
       "randomforest + word2vec + feature engineering       0.872549   0.930962   \n",
       "\n",
       "                                                          f1  \n",
       "name                                                          \n",
       "Gridsearch SVC + tf-idf + feature engineering       0.940436  \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.931170  \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.930508  \n",
       "randomforest + tf-idf + feature engineering         0.927551  \n",
       "SVC + tf-idf + feature engineering + <__main__....  0.928395  \n",
       "SVC + tf-idf + feature engineering + 2gram(150)     0.926420  \n",
       "SVC + word2vec + feature engineering                0.925652  \n",
       "SVC + tf-idf + feature engineering + 2gram(100)     0.925579  \n",
       "SVC + tf-idf + feature engineering + 2gram(150)     0.925417  \n",
       "SVC + tf-idf + feature engineering                  0.921404  \n",
       "Grid search SVC + word2vec + feature engineering    0.918269  \n",
       "randomforest + tf-idf                               0.904665  \n",
       "randomforest + word2vec + feature engineering       0.900810  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by Accuracy:\n",
    "perf_df.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "df3e98fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gridsearch SVC + tf-idf + feature engineering</th>\n",
       "      <td>13918</td>\n",
       "      <td>0.942523</td>\n",
       "      <td>0.951961</td>\n",
       "      <td>0.929187</td>\n",
       "      <td>0.940436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=70, top_n=150): 146 2gram(s)</th>\n",
       "      <td>14064</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.928431</td>\n",
       "      <td>0.933925</td>\n",
       "      <td>0.931170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=80, top_n=150): 118 2gram(s)</th>\n",
       "      <td>14036</td>\n",
       "      <td>0.934112</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.935580</td>\n",
       "      <td>0.930508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + &lt;__main__.TwoGramFeatures object at 0x7f6e676c7430&gt;</th>\n",
       "      <td>14014</td>\n",
       "      <td>0.932243</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.928395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest + tf-idf + feature engineering</th>\n",
       "      <td>13918</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.891176</td>\n",
       "      <td>0.967021</td>\n",
       "      <td>0.927551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    feature size  accuracy  \\\n",
       "name                                                                         \n",
       "Gridsearch SVC + tf-idf + feature engineering              13918  0.942523   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...         14064  0.934579   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...         14036  0.934112   \n",
       "SVC + tf-idf + feature engineering + <__main__....         14014  0.932243   \n",
       "randomforest + tf-idf + feature engineering                13918  0.933645   \n",
       "\n",
       "                                                      recall  precision  \\\n",
       "name                                                                      \n",
       "Gridsearch SVC + tf-idf + feature engineering       0.951961   0.929187   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.928431   0.933925   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.925490   0.935580   \n",
       "SVC + tf-idf + feature engineering + <__main__....  0.921569   0.935323   \n",
       "randomforest + tf-idf + feature engineering         0.891176   0.967021   \n",
       "\n",
       "                                                          f1  \n",
       "name                                                          \n",
       "Gridsearch SVC + tf-idf + feature engineering       0.940436  \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.931170  \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.930508  \n",
       "SVC + tf-idf + feature engineering + <__main__....  0.928395  \n",
       "randomforest + tf-idf + feature engineering         0.927551  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by F1:\n",
    "perf_df.sort_values(by='f1', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "09770f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gridsearch SVC + tf-idf + feature engineering</th>\n",
       "      <td>13918</td>\n",
       "      <td>0.942523</td>\n",
       "      <td>0.951961</td>\n",
       "      <td>0.929187</td>\n",
       "      <td>0.940436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grid search SVC + word2vec + feature engineering</th>\n",
       "      <td>346</td>\n",
       "      <td>0.920561</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.900943</td>\n",
       "      <td>0.918269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=70, top_n=150): 146 2gram(s)</th>\n",
       "      <td>14064</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.928431</td>\n",
       "      <td>0.933925</td>\n",
       "      <td>0.931170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=80, top_n=150): 118 2gram(s)</th>\n",
       "      <td>14036</td>\n",
       "      <td>0.934112</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.935580</td>\n",
       "      <td>0.930508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + 2gram(150)</th>\n",
       "      <td>14068</td>\n",
       "      <td>0.928972</td>\n",
       "      <td>0.924510</td>\n",
       "      <td>0.926326</td>\n",
       "      <td>0.925417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    feature size  accuracy  \\\n",
       "name                                                                         \n",
       "Gridsearch SVC + tf-idf + feature engineering              13918  0.942523   \n",
       "Grid search SVC + word2vec + feature engineering             346  0.920561   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...         14064  0.934579   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...         14036  0.934112   \n",
       "SVC + tf-idf + feature engineering + 2gram(150)            14068  0.928972   \n",
       "\n",
       "                                                      recall  precision  \\\n",
       "name                                                                      \n",
       "Gridsearch SVC + tf-idf + feature engineering       0.951961   0.929187   \n",
       "Grid search SVC + word2vec + feature engineering    0.936275   0.900943   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.928431   0.933925   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.925490   0.935580   \n",
       "SVC + tf-idf + feature engineering + 2gram(150)     0.924510   0.926326   \n",
       "\n",
       "                                                          f1  \n",
       "name                                                          \n",
       "Gridsearch SVC + tf-idf + feature engineering       0.940436  \n",
       "Grid search SVC + word2vec + feature engineering    0.918269  \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.931170  \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.930508  \n",
       "SVC + tf-idf + feature engineering + 2gram(150)     0.925417  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by recall:\n",
    "perf_df.sort_values(by='recall', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a2908c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>randomforest + tf-idf + feature engineering</th>\n",
       "      <td>13918</td>\n",
       "      <td>0.933645</td>\n",
       "      <td>0.891176</td>\n",
       "      <td>0.967021</td>\n",
       "      <td>0.927551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest + tf-idf</th>\n",
       "      <td>13872</td>\n",
       "      <td>0.912150</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.936975</td>\n",
       "      <td>0.904665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=80, top_n=150): 118 2gram(s)</th>\n",
       "      <td>14036</td>\n",
       "      <td>0.934112</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.935580</td>\n",
       "      <td>0.930508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + &lt;__main__.TwoGramFeatures object at 0x7f6e676c7430&gt;</th>\n",
       "      <td>14014</td>\n",
       "      <td>0.932243</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.928395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC + tf-idf + feature engineering + TwoGramFeatures(min_doc_count=70, top_n=150): 146 2gram(s)</th>\n",
       "      <td>14064</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.928431</td>\n",
       "      <td>0.933925</td>\n",
       "      <td>0.931170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    feature size  accuracy  \\\n",
       "name                                                                         \n",
       "randomforest + tf-idf + feature engineering                13918  0.933645   \n",
       "randomforest + tf-idf                                      13872  0.912150   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...         14036  0.934112   \n",
       "SVC + tf-idf + feature engineering + <__main__....         14014  0.932243   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...         14064  0.934579   \n",
       "\n",
       "                                                      recall  precision  \\\n",
       "name                                                                      \n",
       "randomforest + tf-idf + feature engineering         0.891176   0.967021   \n",
       "randomforest + tf-idf                               0.874510   0.936975   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.925490   0.935580   \n",
       "SVC + tf-idf + feature engineering + <__main__....  0.921569   0.935323   \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.928431   0.933925   \n",
       "\n",
       "                                                          f1  \n",
       "name                                                          \n",
       "randomforest + tf-idf + feature engineering         0.927551  \n",
       "randomforest + tf-idf                               0.904665  \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.930508  \n",
       "SVC + tf-idf + feature engineering + <__main__....  0.928395  \n",
       "SVC + tf-idf + feature engineering + TwoGramFea...  0.931170  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by precision:\n",
    "perf_df.sort_values(by='precision', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe1095",
   "metadata": {},
   "source": [
    "<b>The above results show that if we do feature engineering, we can achieve greater accuracy using classical Machine learning algorithms.</b> Using a transformer-based model is a time-consuming and resource-expensive algorithms. If we do feature engineering in the right way that is after analyzing our dataset we can get comparable results.\n",
    "\n",
    "We can also do some other feature engineering like, counting the number of emojis used, type of emojis used, what frequencies of unique words, etc. <b>We can define our features by analyzing the dataset and the only limit is your imagination.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d294e6f",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Supplement</font>\n",
    "* [Medium - Grid Search VS Random Search VS Bayesian Optimization](https://github.com/johnklee/ml_articles/blob/master/medium/Grid_Search_VS_Random_Search_VS_Bayesian_Optimization/notebook.ipynb)\n",
    "* [Kaggle - Gensim Word2Vec Tutorial](https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial/notebook)\n",
    "* [Sklearn - Principal component analysis (PCA)](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "* [FAQ - ImportError: cannot import name 'HalvingGridSearchCV' from 'sklearn.model_selection'](https://stackoverflow.com/questions/70908124/importerror-cannot-import-name-halvinggridsearchcv-from-sklearn-model-select)\n",
    "* [SVM Hyperparameter Tuning using GridSearchCV](https://www.vebuso.com/2020/03/svm-hyperparameter-tuning-using-gridsearchcv/)\n",
    "* [Áî®ÁôΩË©±ÊñáË´áÊï∏Â≠∏ÂÖ¨Âºè - ÁÜµ(entropy)](https://myapollo.com.tw/zh-tw/shannon-entropy-explanation/)\n",
    "> <b>ÁÜµÔºàÈü≥ÂêåÂïÜÔºâÔºåÁ∞°ËÄåË®Ä‰πãÔºåÁî®‰ª•Ë°°Èáè‰∏ÄÁµÑË≥áÊñôÁöÑ‰∏çÁ¢∫ÂÆöÊÄß(uncertainty)„ÄÇ</b><br/><br/>\n",
    "> ÂÅáË®≠Êúâ 1 ÊûöÁ°¨Âπ£ 2 Èù¢ÈÉΩÊòØ‰∫∫È†≠ÔºåÈÇ£È∫º‰∏çÁÆ°Â¶Ç‰ΩïÊäïÊì≤ÔºåÊàëÂÄëÈÉΩËÉΩÂ§†Á¢∫ÂÆöÂÆÉÁöÑÁµêÊûúÊòØ‰∫∫È†≠ÔºåÂõ†Ê≠§ÊØ´ÁÑ°‰∏çÁ¢∫ÂÆöÊÄßÂèØË®ÄÔºåÈÇ£È∫ºÁÜµÂÄºÂ∞±ÊúÉÊòØ 0 „ÄÇ<br/>\n",
    "> ÂÅáË®≠Êúâ 1 ÊûöÁ°¨Âπ£ Ê≠£Èù¢‰∫∫È†≠ÔºåËÉåÈù¢ÁÇ∫Â≠óÔºåÈÇ£È∫ºÊàëÂÄëÊúâ 50% ÁöÑÊ©üÁéáÁåú‰∏≠ÂÖ∂ÊäïÊì≤ÁµêÊûúÔºåÂõ†Ê≠§Ë©≤ÊÉÖÊ≥Å‰∏ãÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂÖ∂ÁÜµÂÄºÁÇ∫ 1 „ÄÇ<br/>\n",
    "> ÂÅáË®≠Êúâ 2 ÊûöÁ°¨Âπ£ÔºåÈÇ£È∫ºÊàëÂÄëÁ¥ÑÊúâ 33% ÁöÑÊ©üÁéáÁåú‰∏≠ÂÖ∂ÊäïÊì≤ÁµêÊûúÔºàÊ≠£Ê≠£„ÄÅÂèçÂèç„ÄÅÊ≠£ÂèçÔºâÔºåË©≤ÊÉÖÊ≥ÅÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÁõ∏Â∞çÊñºÂè™Êúâ 1 ÊûöÁ°¨Âπ£ËÄåË®ÄÊõ¥È´òÔºåÂÖ∂ÁÜµÂÄºÁ¥ÑÁÇ∫ 1.58 „ÄÇ<br/>\n",
    "> ÂèØ‰ª•ÁúãÂà∞Èö®Ëëó<b>‰∏çÁ¢∫ÂÆöÊÄßÂ¢ûÂä†ÔºåÁÜµÂÄº‰πüÊúÉÂ¢ûÂä†</b>„ÄÇ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
