{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4668ec59-2979-41cb-b002-25d3ac05afc2",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "<font size='3ptx'><b>In the [Agent Development Kit](https://google.github.io/adk-docs/agents/) (ADK), an Agent is a self-contained execution unit designed to act autonomously to achieve specific goals.</b> Agents can perform tasks, interact with users, utilize external tools, and coordinate with other agents.</font> \n",
    "\n",
    "<b>The foundation for all agents in ADK is the <font color='blue'>BaseAgent</font> class.</b> It serves as the fundamental blueprint. To create functional agents, you typically extend <font color='blue'>**BaseAgent**</font> in one of three main ways, catering to different needs â€“ from intelligent reasoning to structured process control:\n",
    "![agent types](https://google.github.io/adk-docs/assets/agent-types.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486b9a31-ab58-4dd4-9c30-187174c685a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "def show_source_code(src_path: str):\n",
    "    source_code = !cat $src_path\n",
    "    display(Markdown(f\"\"\"\n",
    "```python\n",
    "{'\\n'.join(source_code)}\n",
    "```\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c4218-f4a4-477f-9aec-2da36490f2a6",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Core Agent Categories</font></b>\n",
    "([source](https://google.github.io/adk-docs/agents/#core-agent-categories)) ADK provides distinct agent categories to build sophisticated applications:\n",
    "1. [**LLM Agents (LlmAgent, Agent)**](https://google.github.io/adk-docs/agents/llm-agents/): These agents utilize Large Language Models (LLMs) as their core engine to understand natural language, reason, plan, generate responses, and dynamically decide how to proceed or which tools to use, making them ideal for flexible, language-centric tasks. [Learn more about LLM Agents...](https://google.github.io/adk-docs/agents/llm-agents/)\n",
    "2. [**Workflow Agents (SequentialAgent, ParallelAgent, LoopAgent)**](https://google.github.io/adk-docs/agents/workflow-agents/): These specialized agents control the execution flow of other agents in predefined, deterministic patterns (sequence, parallel, or loop) without using an LLM for the flow control itself, perfect for structured processes needing predictable execution. [Explore Workflow Agents...](https://google.github.io/adk-docs/agents/workflow-agents/)\n",
    "3. [**Custom Agents**](https://google.github.io/adk-docs/agents/custom-agents/): Created by extending <font color='blue'>**BaseAgent**</font> directly, these agents allow you to implement unique operational logic, specific control flows, or specialized integrations not covered by the standard types, catering to highly tailored application requirements. [Discover how to build Custom Agents...](https://google.github.io/adk-docs/agents/custom-agents/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbb3d2-278c-4e6a-b288-4e05a22f5ce5",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Choosing the Right Agent Type</font></b>\n",
    "<b>The following table provides a high-level comparison to help distinguish between the agent types</b>. As you explore each type in more detail in the subsequent sections, these distinctions will become clearer.\n",
    "\n",
    "| Feature           | LLM Agent (`LlmAgent`)                   | Workflow Agent                        | Custom Agent (`BaseAgent` subclass)           |\n",
    "| :---------------- | :-------------------------------------- | :------------------------------------ | :-------------------------------------------- |\n",
    "| **Primary Function** | Reasoning, Generation, Tool Use         | Controlling Agent Execution Flow      | Implementing Unique Logic/Integrations        |\n",
    "| **Core Engine** | Large Language Model (LLM)              | Predefined Logic (Sequence, Parallel, Loop) | Custom Code                                   |\n",
    "| **Determinism** | Non-deterministic (Flexible)            | Deterministic (Predictable)           | Can be either, based on implementation        |\n",
    "| **Primary Use** | Language tasks, Dynamic decisions       | Structured processes, Orchestration   | Tailored requirements, Specific workflows     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf04a00-f134-49c6-9a15-f1bb07b8d45a",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Agents Working Together: Multi-Agent Systems</font></b>\n",
    "<b><font size='3ptx'>While each agent type serves a distinct purpose, the true power often comes from combining them</font></b>. Complex applications frequently employ multi-agent architectures where:\n",
    "* **LLM Agents** handle intelligent, language-based task execution.\n",
    "* **Workflow Agents** manage the overall process flow using standard patterns.\n",
    "* **Custom Agents** provide specialized capabilities or rules needed for unique integrations.\n",
    "\n",
    "Understanding these core types is the first step toward building sophisticated, capable AI applications with ADK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffbbc30-0a88-4a46-8d7f-2afda3e73592",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>What's Next?</font></b>\n",
    "Now that you have an overview of the different agent types available in ADK, dive deeper into how they work and how to use them effectively:\n",
    "\n",
    "* [**LLM Agents**](https://google.github.io/adk-docs/agents/llm-agents/): Explore how to configure agents powered by large language models, including setting instructions, providing tools, and enabling advanced features like planning and code execution.\n",
    "* [**Workflow Agents**](https://google.github.io/adk-docs/agents/workflow-agents/): Learn how to orchestrate tasks using `SequentialAgent`, `ParallelAgent`, and `LoopAgent` for structured and predictable processes.\n",
    "* [**Custom Agents**](https://google.github.io/adk-docs/agents/custom-agents/): Discover the principles of extending `BaseAgent` to build agents with unique logic and integrations tailored to your specific needs.\n",
    "* [**Multi-Agents**](https://google.github.io/adk-docs/agents/multi-agents/): Understand how to combine different agent types to create sophisticated, collaborative systems capable of tackling complex problems.\n",
    "* [**Models**](https://google.github.io/adk-docs/agents/models/): Learn about the different LLM integrations available and how to select the right model for your agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91b102d-a399-4fee-841a-1823714754df",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>LLM Agent</font></b>\n",
    "<font size='3ptx'><b>The <font color='blue'>LlmAgent</font> (<font color='brown'>often aliased simply as `Agent`</font>) is a core component in ADK, acting as the \"thinking\" part of your application.</b> It leverages the power of a Large Language Model (LLM) for reasoning, understanding natural language, making decisions, generating responses, and interacting with tools.</font>\n",
    "\n",
    "<b>Unlike deterministic `Workflow Agents` that follow predefined execution paths, `LlmAgent` behavior is non-deterministic</b>. It uses the LLM to interpret instructions and context, deciding dynamically how to proceed, which tools to use (<font color='brown'>if any</font>), or whether to transfer control to another agent.\n",
    "\n",
    "Building an effective <font color='blue'>**LlmAgent**</font> involves defining its identity, clearly guiding its behavior through instructions, and equipping it with the necessary tools and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5dedcf-1aea-4ed3-86ad-828e21c77158",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Defining the Agent's Identity and Purpose</font></b>\n",
    "First, you need to establish what the agent is and what it's for.\n",
    "\n",
    "* **name (Required)**: Every agent needs a unique string identifier. This `name` is crucial for internal operations, especially in multi-agent systems where agents need to refer to or delegate tasks to each other. Choose a descriptive name that reflects the agent's function (<font color='brown'>e.g., `customer_support_router`, `billing_inquiry_agent`). Avoid reserved names like `user`.\n",
    "* **description (Optional, Recommended for Multi-Agent)**: Provide a concise summary of the agent's capabilities. This description is primarily used by other LLM agents to determine if they should route a task to this agent. Make it specific enough to differentiate it from peers (<font color='brown'>e.g., \"Handles inquiries about current billing statements,\" not just \"Billing agent\"</font>).\n",
    "* **model (Required)**: Specify the underlying LLM that will power this agent's reasoning. This is a string identifier like \"`gemini-2.0-flash`\". The choice of model impacts the agent's capabilities, cost, and performance. See the [Models page](https://google.github.io/adk-docs/agents/models/) for available options and considerations.\n",
    "\n",
    "```python\n",
    "# Example: Defining the basic identity\n",
    "capital_agent = LlmAgent(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    name=\"capital_agent\",\n",
    "    description=\"Answers user questions about the capital city of a given country.\"\n",
    "    # instruction and tools will be added next\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919dd92-fe75-4de7-be3a-8268dfcf5350",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Guiding the Agent: Instructions (`instruction`)</font></b>\n",
    "The `instruction` parameter is arguably the most critical for shaping an <b><font color='blue'>LlmAgent</font></b>'s behavior. It's a string (<font color='brown'>or a function returning a string</font>) that tells the agent:\n",
    "* Its core task or goal.\n",
    "* Its personality or persona (<font color='brown'>e.g., \"You are a helpful assistant,\" \"You are a witty pirate\"</font>).\n",
    "* Constraints on its behavior (<font color='brown'>e.g., \"Only answer questions about X,\" \"Never reveal Y\"</font>).\n",
    "* How and when to use its tools. You should explain the purpose of each tool and the circumstances under which it should be called, supplementing any descriptions within the tool itself.\n",
    "* The desired format for its output (<font color='brown'>e.g., \"Respond in JSON,\" \"Provide a bulleted list\"</font>).\n",
    "\n",
    "Tips for Effective Instructions:\n",
    "* **Be Clear and Specific**: Avoid ambiguity. Clearly state the desired actions and outcomes.\n",
    "* **Use Markdown**: Improve readability for complex instructions using headings, lists, etc.\n",
    "* **Provide Examples (Few-Shot)**: For complex tasks or specific output formats, include examples directly in the instruction.\n",
    "* **Guide Tool Use**: Don't just list tools; explain when and why the agent should use them.\n",
    "\n",
    "State:\n",
    "* The instruction is a string template, you can use the `{var}` syntax to insert dynamic values into the instruction.\n",
    "* `{var}` is used to insert the value of the state variable named `var`.\n",
    "* `{artifact.var}` is used to insert the text content of the `artifact` named `var`.\n",
    "* **If the state variable or artifact does not exist, the agent will raise an error**. If you want to ignore the error, you can append a `?` to the variable name as in `{var?}`.\n",
    "\n",
    "```python\n",
    "# Example: Adding instructions\n",
    "capital_agent = LlmAgent(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    name=\"capital_agent\",\n",
    "    description=\"Answers user questions about the capital city of a given country.\",\n",
    "    instruction=\"\"\"You are an agent that provides the capital city of a country.\n",
    "When a user asks for the capital of a country:\n",
    "1. Identify the country name from the user's query.\n",
    "2. Use the `get_capital_city` tool to find the capital.\n",
    "3. Respond clearly to the user, stating the capital city.\n",
    "Example Query: \"What's the capital of {country}?\"\n",
    "Example Response: \"The capital of France is Paris.\"\n",
    "\"\"\",\n",
    "    # tools will be added next\n",
    ")\n",
    "```\n",
    "\n",
    "<b><font color='darkred'>Note:</font></b> For instructions that apply to all agents in a system, consider using `global_instruction` on the root agent, detailed further in the [**Multi-Agents section**](https://google.github.io/adk-docs/agents/multi-agents/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67cb314-f3dd-4cfd-85a2-806417c664ed",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Equipping the Agent: Tools (`tools`)</font></b>\n",
    "<font size='3ptx'><b>Tools give your <font color='blue'>LlmAgent</font> capabilities beyond the LLM's built-in knowledge or reasoning</b></font>. They allow the agent to interact with the outside world, perform calculations, fetch real-time data, or execute specific actions.\n",
    "* **tools (Optional)**: Provide a list of tools the agent can use. Each item in the list can be:\n",
    "  - **A native function or method (wrapped as a `FunctionTool`)**. Python ADK automatically wraps the native function into a <font color='blue'>**FuntionTool**</font>.\n",
    "  - An instance of a class inheriting from <b><font color='blue'>BaseTool</font></b>.\n",
    "  - An instance of another agent (<font color='brown'>`AgentTool`, enabling agent-to-agent delegation - see [Multi-Agents](https://google.github.io/adk-docs/agents/multi-agents/)</font>).\n",
    "\n",
    "The LLM uses the function/tool names, descriptions (<font color='brown'>from docstrings or the `description` field</font>), and parameter schemas to decide which tool to call based on the conversation and its instructions.\n",
    "\n",
    "```python\n",
    "# Define a tool function\n",
    "def get_capital_city(country: str) -> str:\n",
    "  \"\"\"Retrieves the capital city for a given country.\"\"\"\n",
    "  # Replace with actual logic (e.g., API call, database lookup)\n",
    "  capitals = {\"france\": \"Paris\", \"japan\": \"Tokyo\", \"canada\": \"Ottawa\"}\n",
    "  return capitals.get(country.lower(), f\"Sorry, I don't know the capital of {country}.\")\n",
    "\n",
    "# Add the tool to the agent\n",
    "capital_agent = LlmAgent(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    name=\"capital_agent\",\n",
    "    description=\"Answers user questions about the capital city of a given country.\",\n",
    "    instruction=\"\"\"You are an agent that provides the capital city of a country... (previous instruction text)\"\"\",\n",
    "    tools=[get_capital_city] # Provide the function directly\n",
    ")\n",
    "```\n",
    "\n",
    "Learn more about Tools in the [**Tools section**](https://google.github.io/adk-docs/tools/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989d3e7-496b-4cca-b4e1-42aa3e23b278",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Advanced Configuration & Control</font></b>\n",
    "([source](https://google.github.io/adk-docs/agents/llm-agents/#advanced-configuration-control)) Beyond the core parameters, <font color='blue'>**LlmAgent**</font> offers several options for finer control:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9d90d-9f0d-4706-a0bb-d8eb725df40c",
   "metadata": {},
   "source": [
    "#### <b>Fine-Tuning LLM Generation (`generate_content_config`)</b>\n",
    "You can adjust how the underlying LLM generates responses using `generate_content_config`.\n",
    "* **generate_content_config (Optional)**: Pass an instance of <b><font color='blue'>google.genai.types.GenerateContentConfig</font></b> to control parameters like `temperature` (randomness), `max_output_tokens` (response length), `top_p`, `top_k`, and `safety` settings.\n",
    "\n",
    "```python\n",
    "from google.genai import types\n",
    "\n",
    "agent = LlmAgent(\n",
    "    # ... other params\n",
    "    generate_content_config=types.GenerateContentConfig(\n",
    "        temperature=0.2, # More deterministic output\n",
    "        max_output_tokens=250\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa430763-2b35-43d8-8675-5d266fd46001",
   "metadata": {},
   "source": [
    "#### <b>Structuring Data (`input_schema`, `output_schema`, `output_key`)</b>\n",
    "For scenarios requiring structured data exchange with an LLM Agent, the ADK provides mechanisms to <b>define expected input and desired output formats using `schema` definitions</b>.\n",
    "\n",
    "* **input_schema (Optional)**: Define a schema representing the expected input structure. If set, the user message content passed to this agent must be a JSON string conforming to this schema. Your instructions should guide the user or preceding agent accordingly.\n",
    "* **output_schema (Optional)**: Define a schema representing the desired output structure. If set, the agent's final response must be a JSON string conforming to this schema.\n",
    "  - **Constraint**: Using `output_schema` enables controlled generation within the LLM but **disables the agent's ability to use tools or transfer control to other agents**. Your instructions must guide the LLM to produce JSON matching the schema directly.\n",
    "* **output_key (Optional)**: Provide a string key. If set, the text content of the **agent's final response will be automatically saved to the session's state dictionary under this key**. This is useful for passing results between agents or steps in a workflow. This might look like: `session.state[output_key] = agent_response_text`.\n",
    "\n",
    "The input and output schema is typically a [**Pydantic BaseModel**](https://docs.pydantic.dev/latest/api/base_model/).\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CapitalOutput(BaseModel):\n",
    "    capital: str = Field(description=\"The capital of the country.\")\n",
    "\n",
    "structured_capital_agent = LlmAgent(\n",
    "    # ... name, model, description\n",
    "    instruction=\"\"\"You are a Capital Information Agent. Given a country, respond ONLY with a JSON object containing the capital. Format: {\"capital\": \"capital_name\"}\"\"\",\n",
    "    output_schema=CapitalOutput, # Enforce JSON output\n",
    "    output_key=\"found_capital\"  # Store result in state['found_capital']\n",
    "    # Cannot use tools=[get_capital_city] effectively here\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa772b-c567-476a-af18-9bf0e0a67dea",
   "metadata": {},
   "source": [
    "#### <b>Managing Context (`include_contents`)</font>\n",
    "Control whether the agent receives the prior conversation history.\n",
    "* **include_contents (Optional, Default: '`default`')**: Determines if the `contents` (history) are sent to the LLM.\n",
    "  - `'default'`: The agent receives the relevant conversation history.\n",
    "  - `'none'`: The agent receives no prior contents. It operates based solely on its current instruction and any input provided in the current turn (<font color='brown'>useful for stateless tasks or enforcing specific contexts</font>).\n",
    "\n",
    "```python\n",
    "stateless_agent = LlmAgent(\n",
    "    # ... other params\n",
    "    include_contents='none'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfa22d-9331-46d5-8cb0-e241c84c5746",
   "metadata": {},
   "source": [
    "#### <b>Planner</b>\n",
    "**planner (Optional):** Assign a <font color='blue'>**BasePlanner**</font> instance to enable multi-step reasoning and planning before execution. There are two main planners:\n",
    "* **BuiltInPlanner**: Leverages the model's built-in planning capabilities (<font color='brown'>e.g., Gemini's thinking feature</font>). See [Gemini Thinking](https://ai.google.dev/gemini-api/docs/thinking) for details and examples.\n",
    "\n",
    "Here, the <font color='violet'>thinking_budget</font> parameter guides the model on the number of thinking tokens to use when generating a response. The <font color='violet'>include_thoughts</font> parameter controls whether the model should include its raw thoughts and internal reasoning process in the response.\n",
    "\n",
    "```python\n",
    "from google.adk import Agent\n",
    "from google.adk.planners import BuiltInPlanner\n",
    "from google.genai import types\n",
    "\n",
    "my_agent = Agent(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    planner=BuiltInPlanner(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=True,\n",
    "            thinking_budget=1024,\n",
    "        )\n",
    "    ),\n",
    "    # ... your tools here\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f29e92-f93d-4d12-9fe2-acd6e04c8751",
   "metadata": {},
   "source": [
    "* **PlanReActPlanner:** This planner instructs the model to follow a specific structure in its output: first create a plan, then execute actions (<font color='brown'>like calling tools</font>), and provide reasoning for its steps. It's particularly useful for models that don't have a `built-in \"thinking\"` feature.\n",
    "\n",
    "```python\n",
    "from google.adk import Agent\n",
    "from google.adk.planners import PlanReActPlanner\n",
    "\n",
    "my_agent = Agent(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    planner=PlanReActPlanner(),\n",
    "    # ... your tools here\n",
    ")\n",
    "```\n",
    "\n",
    "The agent's response will follow a structured format:\n",
    "```\n",
    "[user]: ai news\n",
    "[google_search_agent]: /*PLANNING*/\n",
    "1. Perform a Google search for \"latest AI news\" to get current updates and headlines related to artificial intelligence.\n",
    "2. Synthesize the information from the search results to provide a summary of recent AI news.\n",
    "\n",
    "/*ACTION*/\n",
    "/*REASONING*/\n",
    "The search results provide a comprehensive overview of recent AI news, covering various aspects like company developments, research breakthroughs, and applications. I have enough information to answer the user's request.\n",
    "\n",
    "/*FINAL_ANSWER*/\n",
    "Here's a summary of recent AI news:\n",
    "....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539507ba-2311-4baf-8b70-a2907e4953d2",
   "metadata": {},
   "source": [
    "#### <b>Code Execution</b>\n",
    "**code_executor (Optional)**: Provide a <b><font color='blue'>BaseCodeExecutor</font></b> instance to allow the agent to execute code blocks found in the LLM's response. ([See Tools/Built-in tools](https://google.github.io/adk-docs/tools/built-in-tools/))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f118a19f-e463-4679-9c3b-d0ff5e39bc3c",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Putting It Together: Example</font></b>\n",
    "Let's check the example `agent_example1.py` as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05457b3a-504f-4607-b700-70650317efed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```python\n",
       "#!/usr/bin/env python\n",
       "# --- Full example code demonstrating LlmAgent with Tools vs. Output Schema ---\n",
       "import asyncio\n",
       "import json # Needed for pretty printing dicts\n",
       "\n",
       "from google.adk.agents import LlmAgent\n",
       "from google.adk.runners import Runner\n",
       "from google.adk.sessions import InMemorySessionService\n",
       "from google.genai import types\n",
       "from pydantic import BaseModel, Field\n",
       "\n",
       "# --- 1. Define Constants ---\n",
       "APP_NAME = \"agent_comparison_app\"\n",
       "USER_ID = \"test_user_456\"\n",
       "SESSION_ID_TOOL_AGENT = \"session_tool_agent_xyz\"\n",
       "SESSION_ID_SCHEMA_AGENT = \"session_schema_agent_xyz\"\n",
       "MODEL_NAME = \"gemini-2.0-flash\"\n",
       "\n",
       "# --- 2. Define Schemas ---\n",
       "\n",
       "# Input schema used by both agents\n",
       "class CountryInput(BaseModel):\n",
       "  country: str = Field(description=\"The country to get information about.\")\n",
       "\n",
       "# Output schema ONLY for the second agent\n",
       "class CapitalInfoOutput(BaseModel):\n",
       "  capital: str = Field(description=\"The capital city of the country.\")\n",
       "  # Note: Population is illustrative; the LLM will infer or estimate this\n",
       "  # as it cannot use tools when output_schema is set.\n",
       "  population_estimate: str = Field(\n",
       "      description=\"An estimated population of the capital city.\")\n",
       "\n",
       "# --- 3. Define the Tool (Only for the first agent) ---\n",
       "def get_capital_city(country: str) -> str:\n",
       "  \"\"\"Retrieves the capital city of a given country.\"\"\"\n",
       "  print(f\"\\n-- Tool Call: get_capital_city(country='{country}') --\")\n",
       "  country_capitals = {\n",
       "      \"united states\": \"Washington, D.C.\",\n",
       "      \"canada\": \"Ottawa\",\n",
       "      \"france\": \"Paris\",\n",
       "      \"japan\": \"Tokyo\",\n",
       "      \"taiwan\": \"Taipei\",\n",
       "  }\n",
       "  result = country_capitals.get(\n",
       "      country.lower(), f\"Sorry, I couldn't find the capital for {country}.\")\n",
       "  print(f\"-- Tool Result: '{result}' --\")\n",
       "  return result\n",
       "\n",
       "# --- 4. Configure Agents ---\n",
       "\n",
       "# Agent 1: Uses a tool and output_key\n",
       "capital_agent_with_tool = LlmAgent(\n",
       "    model=MODEL_NAME,\n",
       "    name=\"capital_agent_tool\",\n",
       "    description=\"Retrieves the capital city using a specific tool.\",\n",
       "    instruction=\"\"\"\n",
       "You are a helpful agent to provide the capital city of a country using a tool.\n",
       "The user will provide the country name in a JSON format like {\"country\": \"country_name\"}.\n",
       "\n",
       "1. Extract the country name.\n",
       "2. Use the `get_capital_city` tool to find the capital.\n",
       "3. Respond clearly to the user, stating the capital city found by the tool.\n",
       "\"\"\",\n",
       "    tools=[get_capital_city],\n",
       "    input_schema=CountryInput,\n",
       "    output_key=\"capital_tool_result\", # Store final text response\n",
       ")\n",
       "\n",
       "# Agent 2: Uses output_schema (NO tools possible)\n",
       "structured_info_agent_schema = LlmAgent(\n",
       "    model=MODEL_NAME,\n",
       "    name=\"structured_info_agent_schema\",\n",
       "    description=(\n",
       "        \"Provides capital and estimated population in a specific JSON format.\"),\n",
       "    instruction=f\"\"\"\n",
       "You are an agent that provides country information.\n",
       "The user will provide the country name in a JSON format like\n",
       "{{\"country\": \"country_name\"}}.\n",
       "\n",
       "Respond ONLY with a JSON object matching this exact schema:\n",
       "{json.dumps(CapitalInfoOutput.model_json_schema(), indent=2)}\n",
       "Use your knowledge to determine the capital and estimate the population.\n",
       "\n",
       "Do not use any tools.\n",
       "\"\"\",\n",
       "    # *** NO tools parameter here - using output_schema prevents tool use ***\n",
       "    input_schema=CountryInput,\n",
       "    output_schema=CapitalInfoOutput, # Enforce JSON output structure\n",
       "    output_key=\"structured_info_result\", # Store final JSON response\n",
       ")\n",
       "\n",
       "\n",
       "# --- 6. Define Agent Interaction Logic ---\n",
       "async def call_agent_and_print(\n",
       "    runner_instance: Runner,\n",
       "    agent_instance: LlmAgent,\n",
       "    session_service: InMemorySessionService,\n",
       "    session_id: str,\n",
       "    query_json: str,\n",
       "):\n",
       "  \"\"\"Sends a query to the specified agent/runner and prints results.\"\"\"\n",
       "  print(f\"\\n>>> Calling Agent: '{agent_instance.name}' | Query: {query_json}\")\n",
       "\n",
       "  user_content = types.Content(\n",
       "      role='user', parts=[types.Part(text=query_json)])\n",
       "\n",
       "  final_response_content = \"No final response received.\"\n",
       "  async for event in runner_instance.run_async(\n",
       "      user_id=USER_ID,\n",
       "      session_id=session_id,\n",
       "      new_message=user_content):\n",
       "    # print(f\"Event: {event.type}, Author: {event.author}\") # Uncomment for detailed logging\n",
       "    if event.is_final_response() and event.content and event.content.parts:\n",
       "      # For output_schema, the content is the JSON string itself\n",
       "      final_response_content = event.content.parts[0].text\n",
       "\n",
       "  print(f\"<<< Agent '{agent_instance.name}' Response: {final_response_content}\")\n",
       "\n",
       "  current_session = await session_service.get_session(\n",
       "      app_name=APP_NAME,\n",
       "      user_id=USER_ID,\n",
       "      session_id=session_id)\n",
       "\n",
       "  stored_output = current_session.state.get(agent_instance.output_key)\n",
       "\n",
       "  # Pretty print if the stored output looks like JSON (likely from output_schema)\n",
       "  print(f\"--- Session State ['{agent_instance.output_key}']: \", end=\"\")\n",
       "  try:\n",
       "    # Attempt to parse and pretty print if it's JSON\n",
       "    parsed_output = json.loads(stored_output)\n",
       "    print(json.dumps(parsed_output, indent=2))\n",
       "  except (json.JSONDecodeError, TypeError):\n",
       "    # Otherwise, print as string\n",
       "    print(stored_output)\n",
       "  print(\"-\" * 30)\n",
       "\n",
       "\n",
       "# --- 7. Run Interactions ---\n",
       "async def main(capital_runner, structured_runner, session_service):\n",
       "  print(\"--- Testing Agent with Tool ---\")\n",
       "  await call_agent_and_print(\n",
       "      capital_runner,\n",
       "      capital_agent_with_tool,\n",
       "      session_service,\n",
       "      SESSION_ID_TOOL_AGENT,\n",
       "      '{\"country\": \"Taiwan\"}')\n",
       "\n",
       "  await call_agent_and_print(\n",
       "      capital_runner,\n",
       "      capital_agent_with_tool,\n",
       "      session_service,\n",
       "      SESSION_ID_TOOL_AGENT,\n",
       "      '{\"country\": \"Canada\"}')\n",
       "\n",
       "  print(\"\\n\\n--- Testing Agent with Output Schema (No Tool Use) ---\")\n",
       "  await call_agent_and_print(\n",
       "      structured_runner,\n",
       "      structured_info_agent_schema,\n",
       "      session_service,\n",
       "      SESSION_ID_SCHEMA_AGENT,\n",
       "      '{\"country\": \"France\"}')\n",
       "  await call_agent_and_print(\n",
       "      structured_runner,\n",
       "      structured_info_agent_schema,\n",
       "      session_service,\n",
       "      SESSION_ID_SCHEMA_AGENT,\n",
       "      '{\"country\": \"Japan\"}')\n",
       "\n",
       "\n",
       "def create_runners():\n",
       "  # --- 5. Set up Session Management and Runners ---\n",
       "  session_service = InMemorySessionService()\n",
       "  print(f'session_service: {session_service.__class__}')\n",
       "\n",
       "  # Create separate sessions for clarity, though not strictly necessary if context is managed\n",
       "  asyncio.run(session_service.create_session(\n",
       "      app_name=APP_NAME,\n",
       "      user_id=USER_ID,\n",
       "      session_id=SESSION_ID_TOOL_AGENT))\n",
       "\n",
       "  asyncio.run(session_service.create_session(\n",
       "      app_name=APP_NAME,\n",
       "      user_id=USER_ID,\n",
       "      session_id=SESSION_ID_SCHEMA_AGENT))\n",
       "\n",
       "  # Create a runner for EACH agent\n",
       "  capital_runner = Runner(\n",
       "      agent=capital_agent_with_tool,\n",
       "      app_name=APP_NAME,\n",
       "      session_service=session_service\n",
       "  )\n",
       "  structured_runner = Runner(\n",
       "      agent=structured_info_agent_schema,\n",
       "      app_name=APP_NAME,\n",
       "      session_service=session_service\n",
       "  )\n",
       "  return capital_runner, structured_runner, session_service\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "  capital_runner, structured_runner, session_service = create_runners()\n",
       "  asyncio.run(main(capital_runner, structured_runner, session_service))\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_source_code('agent_example1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c515dfbc-61b4-4e25-ab5b-48a04a370a5e",
   "metadata": {},
   "source": [
    "Let's testing the agent examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03cca3fb-0224-4bb5-ad8c-ba9a6c9a8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent_example1\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "# --- 1. Define Constants ---\n",
    "APP_NAME = \"agent_comparison_app\"\n",
    "USER_ID = \"test_user_456\"\n",
    "SESSION_ID=\"1234\"\n",
    "\n",
    "# --- 2. Define used class and instances\n",
    "InMemorySessionService = agent_example1.InMemorySessionService\n",
    "capital_agent_with_tool = agent_example1.capital_agent_with_tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7233dc07-ef28-439f-90db-5f4acd3a0365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlmAgent(name='capital_agent_tool', description='Retrieves the capital city using a specific tool.', parent_agent=None, sub_agents=[], before_agent_callback=None, after_agent_callback=None, model='gemini-2.0-flash', instruction='\\nYou are a helpful agent to provide the capital city of a country using a tool.\\nThe user will provide the country name in a JSON format like {\"country\": \"country_name\"}.\\n\\n1. Extract the country name.\\n2. Use the `get_capital_city` tool to find the capital.\\n3. Respond clearly to the user, stating the capital city found by the tool.\\n', global_instruction='', tools=[<function get_capital_city at 0x7f69eedbfa60>], generate_content_config=None, disallow_transfer_to_parent=False, disallow_transfer_to_peers=False, include_contents='default', input_schema=<class 'agent_example1.CountryInput'>, output_schema=None, output_key='capital_tool_result', planner=None, code_executor=None, before_model_callback=None, after_model_callback=None, before_tool_callback=None, after_tool_callback=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capital_agent_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25010e6b-5745-4801-9a4d-fc2cdacaebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = InMemorySessionService()\n",
    "session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
    "runner = Runner(agent=capital_agent_with_tool, app_name=APP_NAME, session_service=session_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2036fd1f-f4dd-4069-958c-37ed1fddb588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the agent\n",
    "query = '{\"country\": \"Taiwan\"}'\n",
    "content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "events = runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "571cd9e3-ba58-4628-b89c-9b309a239784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Tool Call: get_capital_city(country='Taiwan') --\n",
      "-- Tool Result: 'Taipei' --\n",
      "Agent Response:  The capital city of Taiwan is Taipei.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for event in events:\n",
    "    if event.is_final_response():\n",
    "        final_response = event.content.parts[0].text\n",
    "        print(\"Agent Response: \", final_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc1dc9-abca-4cdd-86e6-80b5b23e421f",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Related Concepts (Deferred Topics)</font></b>\n",
    "While this page covers the core configuration of `LlmAgent`, several related concepts provide more advanced control and are detailed elsewhere:\n",
    "* **Callbacks: Intercepting execution points** (<font color='brown'>before/after model calls, before/after tool calls</font>) using `before_model_callback`, `after_model_callback`, etc. See [**Callbacks**](https://google.github.io/adk-docs/callbacks/types-of-callbacks/).\n",
    "* **Multi-Agent Control:** Advanced strategies for agent interaction, including planning (planner), controlling agent transfer (`disallow_transfer_to_parent`, `disallow_transfer_to_peers`), and system-wide instructions (`global_instruction`). See [**Multi-Agents**](https://google.github.io/adk-docs/agents/multi-agents/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
