{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c985d81e-3653-40ff-8514-5c27c8208dc0",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Gemini API: List models</font></b>\n",
    "<b><font size='3ptx'>([source](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb)) This notebook demonstrates how to list the models that are available for you to use in the Gemini API, and how to find details about a model.</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56de81cc-a8aa-43fa-ab0d-16971c6646ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-generativeai==0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep 'google-generativeai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8eafb0a-a20d-4c32-8894-762ff39186a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_genai\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a93d873-13fb-4f42-829d-af4ec7d108dd",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>List models</font></b>\n",
    "Use `list_models()` to see what models are available. These models support `generateContent`, the main method used for prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc897d1c-83ab-42d7-be56-dda97fa5f6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001-tuning\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcea51e2-6724-4631-a1bc-b8e07addeb4e",
   "metadata": {},
   "source": [
    "These models support `embedContent`, used for embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba1eb14-4eb2-4a51-a878-f6de2f1f5e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if \"embedContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423001a6-8a00-417a-ade6-1d2caee2a48f",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Find details about a model</font></b>\n",
    "You can see more details about a model, including the `input_token_limit` and `output_token_limit` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d402511d-8bb2-4819-aba8-e2502ebaf854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/gemini-1.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if m.name == \"models/gemini-1.5-flash\":\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cb4e7-3bbe-45e2-9c08-2a5b27710cbf",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Get model</font></b>\n",
    "<b><font size='3ptx'>Use `get_model()` to retrieve the specific details of a model.</font></b>\n",
    "\n",
    "You can iterate over all available models using `list_models()`, but if you already know the model name you can retrieve it directly with `get_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e352531-1da3-4713-95da-92790852f5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "source": [
    "model_info = genai.get_model(\"models/aqa\")\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a5ec5-fcbf-448a-b22b-92ccbca4668a",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* To learn how use a model for prompting, see the [**Prompting quickstart**](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb).\n",
    "* To learn how use a model for embedding, see the [**Embedding quickstart**](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb).\n",
    "* For more information on models, visit the [**Gemini models documentation**](https://ai.google.dev/models/gemini)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
