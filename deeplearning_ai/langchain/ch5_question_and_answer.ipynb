{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2741f10c-5ae2-43d8-a114-6001f6257de8",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([source](https://learn.deeplearning.ai/courses/langchain/lesson/5/question-and-answer)) <b><font size='3ptx'>In the age of information overload, extracting precise answers from vast amounts of text is a critical challenge</font></b>.\n",
    "\n",
    "<b>LangChain's Question Answering over Documents framework addresses this head-on, providing a powerful solution that leverages cutting-edge language models to streamline knowledge retrieval</b>. Whether you're a researcher, analyst, or developer, this technology has the potential to revolutionize your workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e886cd8-3ec7-43b6-b359-7509300ebd57",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Outline</font></b>\n",
    "LangChain: Question Answering Over Documents – Key Concepts:\n",
    "* **Document Retrieval Methods:** Leverage Large Language Models (LLMs) to answer questions extracted from PDFs, web pages, or internal documents, expanding the scope of LLM applications. This includes demonstrating simple indexing and utilizing RetrievalQA for querying. The latter is an abstraction of [Retrieval-Augmented Generation](https://en.wikipedia.org/wiki/Prompt_engineering#Retrieval-augmented_generation) (RAG), enhancing retrieval capabilities.\n",
    "* **Data and Model Integration:** Combine LLMs with unstructured data using LangChain components like embedding models and vector stores, increasing model flexibility and adaptability.\n",
    "* **Document Processing Techniques**: Utilize \"[**CSVLoader**](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html)\" and \"[**DocArrayInMemorySearch**](https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.docarray.in_memory.DocArrayInMemorySearch.html)\" vector stores for document loading and indexing. Employ embedding techniques to convert text into numerical representations for efficient processing.\n",
    "\n",
    "Additionally, four post-retrieval processing methods are briefly touched:\n",
    "* **Stuff**: Combine all retrieved documents into a single input for the LLM.\n",
    "* **Map_reduce**: Process each document individually and then aggregate the results.\n",
    "* **Refine**: Iteratively refine the query based on previous responses.\n",
    "* **Map_rerank**: Rerank documents based on their relevance to the refined query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29c13436-25d8-4d59-9e8a-b1a52eee96f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==0.2.1\n",
      "langchain-anthropic==0.1.15\n",
      "langchain-community==0.0.38\n",
      "langchain-core==0.2.3\n",
      "langchain-google-genai==1.0.6\n",
      "langchain-groq==0.1.3\n",
      "langchain-openai==0.1.9\n",
      "langchain-text-splitters==0.2.0\n",
      "langchainhub==0.1.14\n",
      "openai==1.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep -P '(openai|langchain)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26877caa-4f88-440b-97a9-ee9712254487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "TEST_DATA = pd.DataFrame({'index': ['row1', 'row2'], 'review': ['review1', 'review2']})\n",
    "\n",
    "a = load_dotenv(find_dotenv(os.path.expanduser('~/.env'))) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694f5021-dd96-4dc2-8077-ac581e4954b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73e97c-7463-4391-bdda-b1faa7a2fb25",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>[CSVLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html): Load a CSV file into a list of Documents.</font></b>\n",
    "<b><font size='3ptx'>Load csv data with a single row per document.</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cbe4bc2-f760-4176-855b-6286a673b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores.docarray.in_memory import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "TEST_CSV_FILE_PATH = 'test_data/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "340ce76a-f86e-4ace-a7f8-27a8faded2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(TEST_CSV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbeee9c2-7c76-4227-9473-6625ba3d1fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 0\n",
      "name: Women's Campside Oxfords\n",
      "description: This ultracomfortable lace-to-toe Oxford boasts a su\n"
     ]
    }
   ],
   "source": [
    "print(loader.load()[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ace013a8-d1e4-426c-8b2b-d67b98b9449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\" # Selecting a sentence embedding model\n",
    "#model_kwargs = {'device': 'cuda'}\n",
    "#encode_kwargs = {'normalize_embeddings': False}\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9764fd6e-7a2d-4726-9d4b-80c7fd165565",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=hf_embeddings,\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9bc027a-692e-4ec5-830e-2b5fec049d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"Please recommend me product of car.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "006fabf0-23ec-4cf0-8f74-9426fccd6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_replacement_model = OpenAI(temperature=0, \n",
    "                               model='gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25d33ff4-63b0-4a35-81d1-113c14750126",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query, \n",
    "                       llm = llm_replacement_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f3c03ae-e5fd-464a-8743-f09371439c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " I'm sorry, I cannot recommend products as I am a text-based AI and do not have the ability to browse or access information about specific products. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6aa56-c6b4-4ac9-adfd-9f8163535a35",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Step By Step</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4851d2a2-fb79-4ee3-ab2e-c64056a98e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=': 0\\nname: car\\ndescription: Experience the pinnacle of automotive craftsmanship with the \"Luxury and Elegance\". Immerse yourself in a world of refined luxury, where every detail – from the hand-stitched leather seats to the precision-engineered engine – exudes sophistication and performance. The \"Luxury and Elegance\" isn\\'t just a car, it\\'s a statement.', metadata={'source': 'test_data/test_data.csv', 'row': 0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=TEST_CSV_FILE_PATH)\n",
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db8c058d-47d5-4bc3-ba66-0224d9a460a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hf_embeddings.embed_query(\"Hi my name is Harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3285fc3e-224c-4b6f-bbbc-f943a3660586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21f3cd19-b711-4dd8-9b86-2c16cca31472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12968699634075165, -0.09362716227769852, -0.0035989920143038034, 0.015314917080104351, 0.19877466559410095]\n"
     ]
    }
   ],
   "source": [
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6a47416-68a1-44e4-8d9b-6172ecae6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    hf_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc1b6c7f-9eb9-4265-ba28-3fcfb4d370e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_car =\"Please recommend me product of car.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4396c946-9b92-46f9-a86f-0d469eea9c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(query_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bc9ee0f-4c67-4cb4-9254-70975ec077f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360d14d-354e-4581-8560-0cdc51aad980",
   "metadata": {},
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74a4e749-8da1-4ac3-a939-943cddf0be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_phone =\"Please recommend me the product of phone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6f59217-d424-41b5-a175-29dee263299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(query_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "429bc60f-260d-434b-b99c-ebc9681c8065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 4\n",
      "name: phone\n",
      "description: Experience the future in your hands with the \"Cutting-Edge Technology\". This revolutionary device redefines what a smartphone can do. Its [Unique Feature 1] pushes boundaries, while [Unique Feature 2] transforms how you interact with your world. The \"Cutting-Edge Technology\" isn't just a phone; it's a portal to endless possibilities.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e924ce8-29a5-4078-9756-9d78e1297dac",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>DB as retriever</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50c3cd24-1031-4490-bd08-87717203564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f963d8f-df33-4985-a337-9a672ce4c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7775b506-8eb2-4f72-8aaa-a1eb70a97f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d195793-10ea-4bb9-a11e-f82bfe73839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 0\n",
      "name: car\n",
      "description: Experience the pinnacle of automotive craftsmanship with the \"Luxury and Elegance\". Immerse yourself in a world of refined luxury, where every detail – from the hand-stitched leather seats to the precision-engineered engine – exudes sophistication and performance. The \"Luxury and Elegance\" isn't just a car, it's a statement.: 1\n",
      "name: car\n",
      "description: Unleash your inner explorer with the \"Adventure and Thrills\". Designed to conquer any terrain, this rugged and capable v\n"
     ]
    }
   ],
   "source": [
    "print(qdocs[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c83271ac-c533-4187-b687-d73229153ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(f\"{qdocs} Question: Please list all your products as car in a table in markdown and summarize each one.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3694c96-3576-4712-8539-62007405f2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Name              | Summary                                                                                                      |\n",
       "|-------------------|--------------------------------------------------------------------------------------------------------------|\n",
       "| Luxury and Elegance | A pinnacle of automotive craftsmanship with refined luxury and sophistication.                                |\n",
       "| Adventure and Thrills | A rugged and capable vehicle designed for exploration and unforgettable journeys.                            |\n",
       "| Spark 3            | A futuristic driving experience with cutting-edge technology and advanced features.                           |\n",
       "| Family and Practicality | A family-friendly vehicle with spacious seating, versatile cargo options, and a focus on safety.             |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee074fb9-9d16-4544-920f-46c2fa8c3354",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>RetrievalQA</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3e221c76-32b2-41e7-8bf0-5303a83c5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2dccdf93-d1ca-4d72-a23e-8060490f2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"Please list all your phone products in a table in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e279928a-0581-44ec-a167-e97b2d1614fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = qa_stuff.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e1de41e-0c08-4c4e-b5c3-3f959bf96170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Name | Description |\n",
       "|------|-------------|\n",
       "| Cutting-Edge Technology | Experience the future in your hands with this revolutionary device that redefines what a smartphone can do. Its unique features push boundaries and transform how you interact with the world. It's a portal to endless possibilities. |\n",
       "| Husky | Capture life's moments in stunning detail with the \"Husky\". Its advanced camera system empowers you to unleash your inner photographer, delivering professional-grade results for portraits, landscapes, and videos. |\n",
       "| Ak3 | Make a statement with the \"Ak3\", a masterpiece of design and engineering. Its sleek lines and premium materials turn heads, while its unique design feature sets it apart as a fashion accessory that elevates your style. |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d1434-213e-40a4-8d0c-7f931617b76d",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>RetrievalQA Chain Type</font></b>\n",
    "<b><font size='3ptx'>Chain Types: Strategies for Answering</font></b>\n",
    "\n",
    "![chain type](images/ch5_qa_chain_type.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac29aa-5ca3-46b4-a044-2fc775a78c28",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>stuff</font></b>\n",
    "This is the simplest approach. All retrieved documents are \"stuffed\" into the LLM's prompt at once. The LLM then crafts an answer based on everything it sees.\n",
    "* **Pros:** Easy to set up.\n",
    "* **Cons:** Can struggle with longer documents or many documents, as LLMs have limited context windows.\n",
    "\n",
    "![stuff](images/ch5_qa_chain_type_stuff.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1e9bb-bf68-4b8e-81b8-80282adfb11c",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Map_reduce</font></b>\n",
    "This is a more sophisticated strategy:\n",
    "* **Map:** The LLM processes each retrieved document separately, creating an initial answer for each.\n",
    "* **Reduce:** The LLM combines these initial answers into a final, consolidated response.\n",
    "\n",
    "It has below pros & cons:\n",
    "* **Pros:** Handles longer documents and larger sets of documents more effectively.\n",
    "* **Cons:** Slightly more complex to implement.\n",
    "\n",
    "![map_reduce](images/ch5_qa_chain_type_map_reduce.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2fe25e-8631-49a1-809c-5624e18e1ec0",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Refine</font></b>\n",
    "This is similar to `map_reduce` but takes an iterative approach:\n",
    "1. The LLM answers the question based on the first document.\n",
    "2. It refines this initial answer using the second document.\n",
    "3. This process continues until all documents are used.\n",
    "\n",
    "It has below pros and cons:\n",
    "* **Pros:** Can lead to more nuanced answers.\n",
    "* **Cons:** Might be slower for large numbers of documents.\n",
    "\n",
    "![refine](images/ch5_qa_chain_type_refine.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7686fd-7469-41da-8576-6320c0fcce0a",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Map_rerank</font></b>\n",
    "Similar to `map_reduce`, but it also re-ranks the documents based on how relevant they are to the initial answers.\n",
    "\n",
    "* **Pros**: Utilizes a scoring mechanism to select the best answer, making it suitable for scenarios where the optimal choice needs to be made from multiple possible answers.\n",
    "* **Cons**: Relies on the accuracy of the scoring mechanism, which might not be suitable for all types of documents or queries. The scoring model requires additional training, and the scoring metric itself involves strong subjective judgment, making it difficult to standardize.\n",
    "\n",
    "![rerank](images/ch5_qa_chain_type_map_rerank.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ea55b-66eb-4ce3-a414-9e4d5a3220a4",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [Deeplearning.ai - Langchain Ch2: Model, prompt and parser](https://github.com/johnklee/ml_articles/blob/master/deeplearning_ai/langchain/ch2_model_prompt_and_parser.ipynb)\n",
    "* [Deeplearning.ai - Langchain Ch3: Memory](https://github.com/johnklee/ml_articles/blob/master/deeplearning_ai/langchain/ch3_memory.ipynb)\n",
    "* [Deeplearning.ai - Langchain Ch4: Chain](https://github.com/johnklee/ml_articles/blob/master/deeplearning_ai/langchain/ch4_chains.ipynb)\n",
    "* [Deeplearning.ai - Langchain Ch5: Question and answer](https://github.com/johnklee/ml_articles/blob/master/deeplearning_ai/langchain/ch5_question_and_answer.ipynb)\n",
    "* [Deeplearning.ai - Langchain Ch6: Evaluation](https://github.com/johnklee/ml_articles/blob/master/deeplearning_ai/langchain/ch6_evaluation.ipynb)\n",
    "* [Deeplearning.ai - Langchain Ch7: Agents](https://github.com/johnklee/ml_articles/blob/master/deeplearning_ai/langchain/ch7_agents.ipynb)\n",
    "* [Medium - 4 Ways to Do Question Answering in LangChain](https://towardsdatascience.com/4-ways-of-question-answering-in-langchain-188c6707cc5a)\n",
    "> LangChain makes it easy for you to do question answering with your documents. But do you know that there are at least 4 ways to do question answering in LangChain? In this blog post, we are going to explore four different ways to do question-answering and the various options you could consider for your use cases.\n",
    "\n",
    "* [課程筆記: LangChain - Question and Answer over Documents](https://hackmd.io/@YungHuiHsu/BJ10qunzp)\n",
    "* [LangChain-for-LLM-Application-Development/OutdoorClothingCatalog_1000.csv](https://github.com/Ryota-Kawamura/LangChain-for-LLM-Application-Development/blob/main/OutdoorClothingCatalog_1000.csv)\n",
    "* [Pinecone Docs - Build a RAG chatbot](https://docs.pinecone.io/guides/get-started/build-a-rag-chatbot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
