{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1c40cf-7f58-46ca-8348-4fa8b4be1ddf",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([course source](https://learn.deeplearning.ai/courses/functions-tools-agents-langchain/lesson/3/langchain-expression-language-(lcel))) <b><font size='3ptx'>LCEL (LangChain Expression Language)</font></b>\n",
    "\n",
    "LCEL is a declarative language within LangChain for easily composing chains of components. It offers a simpler way to define and execute complex workflows involving LLMs, data loading, and other processing steps.\n",
    "\n",
    "If you're building applications with LangChain, LCEL can be a valuable tool for streamlining your development process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbc61ed-daa7-46cb-805e-2ae50a47ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==0.2.6\n",
      "langchain-anthropic==0.1.15\n",
      "langchain-community==0.2.6\n",
      "langchain-core==0.2.10\n",
      "langchain-experimental==0.0.62\n",
      "langchain-google-genai==1.0.6\n",
      "langchain-groq==0.1.3\n",
      "langchain-openai==0.1.9\n",
      "langchain-text-splitters==0.2.0\n",
      "langchainhub==0.1.14\n",
      "openai==1.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep -P '(openai|langchain)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486aa268-5522-4579-8fab-55624b5feb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "a = load_dotenv(find_dotenv(os.path.expanduser('~/.env'))) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8d2e7-1f32-4acd-9c5e-1ebbb00a47b9",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Simple Chain</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb40a3f-1d33-454b-95e0-e037a7a9572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f06d78-d41b-424a-bee0-216bf1a6fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a318b06-b8c8-4f0c-8679-bf290bf64628",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51782626-4bcd-4d61-bcef-ebc1fbd544fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the bear break up with his girlfriend?\\nBecause he couldn't bear the relationship anymore!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc6042-5df9-40c1-b2f3-88a85c7193aa",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>More complex chain</font></b>\n",
    "And Runnable Map to supply user-provided inputs to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eeab3a4-3036-4702-bdbb-f4f717263ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88c0f62-c69a-44ca-a7c7-20596de7d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123d1748-36d8-44ed-a206-46e7cbd12e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='harrison worked at kensho'),\n",
       " Document(page_content='bears like to eat honey')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1144a03-c1f5-42a4-ad3b-a89e2afc1c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='bears like to eat honey'),\n",
       " Document(page_content='harrison worked at kensho')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58279204-b5a4-4bae-9f44-26f6a2bf7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ddd209-63a1-47fe-85e7-c66c2bdf5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c7bbdd6-62b2-4dce-aca6-71d560ae2c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a887917-802e-4fdc-820e-0ce9e4741c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ca3422a-43d1-43d0-8817-2942da8fc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad9160a4-7c84-4c8d-bd22-a591af052202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='harrison worked at kensho'),\n",
       "  Document(page_content='bears like to eat honey')],\n",
       " 'question': 'where did harrison work?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f6a67-c849-44a4-8cfd-4dcaa678f157",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Bind</font></b>\n",
    "Sometimes we want to invoke a Runnable within a Runnable sequence with constant arguments that are not part of the output of the preceding Runnable in the sequence, and which are not part of the user input. We can use Runnable.bind() to pass these arguments in. ([more](https://python.langchain.com/v0.1/docs/expression_language/primitives/binding/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62e6a0d6-7771-42e3-bc17-b42fd6664466",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd92c988-8fef-4b81-8c9f-6d150f09c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56614491-56c3-47d2-8efc-448af4a77ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab8decde-f4aa-4c11-aff2-52a878af156f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'weather_search'}}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 64, 'total_tokens': 80}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-e0724e52-3506-4f16-808b-70a91e7100ad-0', usage_metadata={'input_tokens': 64, 'output_tokens': 16, 'total_tokens': 80})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b23d9cc-45ed-4dc7-9c5d-c78862270141",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }, {\n",
    "      \"name\": \"sports_search\",\n",
    "      \"description\": \"Search for news of recent sport events\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"team_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The sports team to search for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"team_name\"]\n",
    "      }\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3929f118-3c1b-4f77-8a96-b9e6b075f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b335fa85-e4e8-41de-a0bf-93366d11cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcdae6ec-c5a2-423f-8f40-4c14282cab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52b087b9-8e65-44c6-82a9-b9748a3e9566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"patriots\"}', 'name': 'sports_search'}}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 99, 'total_tokens': 117}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-0bafb4a6-53a0-4e52-be72-2cf0070d2e62-0', usage_metadata={'input_tokens': 99, 'output_tokens': 18, 'total_tokens': 117})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640b124-4969-4d3a-91be-f8552be12cb5",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Fallbacks</font></b>\n",
    "Due to the deprecation of OpenAI's model text-davinci-001 on 4 January 2024, you'll be using OpenAI's recommended replacement model gpt-3.5-turbo-instruct instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "069e0cdd-d638-46c7-ba2f-0e061c7ec880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a8ed5dc-0f14-47e4-91b6-4a28c4c7e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/johnkclee/Github/ml_articles/env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "simple_model = OpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=1000, \n",
    "    model=\"gpt-3.5-turbo-instruct\"\n",
    ")\n",
    "simple_chain = simple_model | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ff9a94e-0795-429c-85bd-9a7cbfe66fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "692df069-cf53-468f-932e-b541858b59cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n{\\n    \"title\": \"Autumn Leaves\",\\n    \"author\": \"Emily Dickinson\",\\n    \"first_line\": \"The leaves are falling, one by one\"\\n}\\n\\n{\\n    \"title\": \"The Ocean\\'s Song\",\\n    \"author\": \"Pablo Neruda\",\\n    \"first_line\": \"I hear the ocean\\'s song, a symphony of waves\"\\n}\\n\\n{\\n    \"title\": \"A Winter\\'s Night\",\\n    \"author\": \"Robert Frost\",\\n    \"first_line\": \"The snow falls softly, covering the ground\"\\n}'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82347b4-cbd6-4421-9140-4bc533adbfad",
   "metadata": {},
   "source": [
    "The next line is expected to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffc2e8fc-74d3-4eed-9c1d-22e15792cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSONDecodeError: Extra data: line 9 column 1 (char 125)\n",
    "# simple_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e45be615-17df-4ede-9a69-6a254b33bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "chain = model | StrOutputParser() | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1d127cd-db1c-4435-a805-d711024ffa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Night Sky',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'The night is starry and the stars are blue.'},\n",
       " 'poem2': {'title': 'Autumn Leaves',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': \"My sorrow, when she's here with me, thinks these dark days of autumn rain are beautiful as days can be.\"},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul.'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b079b17b-8d47-4946-bfd8-9d70985dfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = simple_chain.with_fallbacks([chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84c40795-27d8-4193-ac3b-d6b886e136f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Night Sky',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'The night is starry and the stars are blue.'},\n",
       " 'poem2': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers'},\n",
       " 'poem3': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood,'}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbfa6a-9060-4dff-9580-6c1060c59548",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Interface</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcc8429d-d5f6-4d37-a709-895fd48a5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "746c4286-e586-41d9-9869-757f143c57f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the bear bring a flashlight to the party? \\nBecause he wanted to be the \"light\" of the party!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b7596f9-5c2f-4b8b-bb9c-919e28c537ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why did the bear dissolve in water?\\n\\nBecause it was polar!',\n",
       " 'Why are frogs so happy?\\n\\nBecause they eat whatever bugs them!']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9117b6fa-72e2-4dca-bcf5-261911d5235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " don\n",
      "'t\n",
      " bears\n",
      " wear\n",
      " shoes\n",
      "?\n",
      " \n",
      "\n",
      "\n",
      "Because\n",
      " they\n",
      " have\n",
      " bear\n",
      " feet\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a91723a4-0556-4296-9094-347b64869975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't bears like fast food? Because they can't catch it!\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25505683-384d-4af2-9135-2f95113f4bd7",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [Deeplearning.ai - Functions, Tools and Agents with LangChain Ch4: OpenAI Function Calling In LangChain](https://learn.deeplearning.ai/courses/functions-tools-agents-langchain/lesson/4/openai-function-calling-in-langchain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
