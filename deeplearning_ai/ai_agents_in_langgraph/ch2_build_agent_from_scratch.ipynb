{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c544121-4e77-47d4-b924-11c44ddc5b37",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([course source](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/2/build-an-agent-from-scratch))\n",
    "\n",
    "![react-idea](images/ch2_1.PNG)\n",
    "([diagram source](https://react-lm.github.io/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4825f83-a2fe-4d76-a89e-8878f8e8338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://til.simonwillison.net/llms/python-react-pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d2f0ef-a0ec-4224-b21a-1b39976d9bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==0.2.6\n",
      "langchain-anthropic==0.1.15\n",
      "langchain-community==0.2.6\n",
      "langchain-core==0.2.10\n",
      "langchain-experimental==0.0.62\n",
      "langchain-google-genai==1.0.6\n",
      "langchain-groq==0.1.3\n",
      "langchain-openai==0.1.9\n",
      "langchain-text-splitters==0.2.0\n",
      "langchainhub==0.1.14\n",
      "openai==1.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep -P '(openai|langchain)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1489e82-2e08-4f60-b173-c6040e076957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "a = load_dotenv(find_dotenv(os.path.expanduser('~/.env'))) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c552d94-acfc-4552-8c20-fc10cc66eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3872573-a5e9-42ee-a208-c526f5d8f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2491455-0d12-45d9-a839-6a5297b2ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1906e7b8-fc76-44d2-92ad-f84d1c28e961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How are you today?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=llm_model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c38f9e-bc2c-468a-a9e7-ce0cc75f93a6",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Agent v0</font></b>\n",
    "<b><font size='3ptx'>Our first agent can remember the execution or chat history. However, it still doesn't not be able to execute the tools/functions by itself yet.</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdac11-028f-4821-a0a8-ae0ab5c29c20",
   "metadata": {},
   "source": [
    "Let's try the execution follow of a client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd367f3-53fd-4ef4-945f-d788c5a6304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'You are a chatbot. When you finish answer the question, you always append the message \"Thanks for asking!\"'\n",
    "messages = [{\"role\": \"system\", \"content\": prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "700f7169-c6f4-46eb-8ae5-e232c08e7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare first message:\n",
    "message = 'Nice to meet you. I am John.'\n",
    "messages.append({\"role\": \"user\", \"content\": message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc39710e-70aa-44b0-9dc4-5f40e1b56383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Post the message to LLM\n",
    "resp = client.chat.completions.create(\n",
    "    model=llm_model, \n",
    "    temperature=0,\n",
    "    messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb27d315-ed89-4a4e-9fb4-b49af1fe0707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9fltsnfKpCUQkDb4sV15UijTAxPWj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you too, John! How can I assist you today? Thanks for asking!', role='assistant', function_call=None, tool_calls=None))], created=1719742604, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=43, total_tokens=62))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f1af50a-6028-4506-80e7-7557e9172cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you too, John! How can I assist you today? Thanks for asking!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Retrieve the responded message from LLM\n",
    "resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "275797a4-547a-4c4d-9072-7246739b835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add the obtained message back to `messages` list\n",
    "messages.append({\"role\": \"assistant\", \"content\": resp.choices[0].message.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8bd5458-33d3-4c63-a614-010890f6f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Post the next message and because of the history of messages, LLM could know who you are\n",
    "message = 'Do you know who I am?'\n",
    "messages.append({\"role\": \"user\", \"content\": message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b35c9bae-9841-441c-bdf1-8c60a224e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you mentioned your name is John. How can I help you, John? Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "# 6. Get the response and print the obtained message:\n",
    "resp = client.chat.completions.create(\n",
    "    model=llm_model, \n",
    "    temperature=0,\n",
    "    messages=messages)\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c323cf-b33b-437d-887f-8fe36bdfd6bf",
   "metadata": {},
   "source": [
    "Now, let's create our first agent from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb5afa7d-bb21-4559-a2fb-9a5aed72e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system: str=\"\", llm_model: str=\"gpt-4o\"):\n",
    "        self.system = system\n",
    "        self.llm_model = llm_model\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=self.llm_model, \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac3ec6-3a09-4b47-bb6a-190390ab8a5a",
   "metadata": {},
   "source": [
    "Then below is the prompt used by our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b00ec52d-a137-41a8-9138-b9846ad1791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "average_dog_weight:\n",
    "e.g. average_dog_weight: Collie\n",
    "returns average weight of a dog when given the breed\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: How much does a Bulldog weigh?\n",
    "Thought: I should look the dogs weight using average_dog_weight\n",
    "Action: average_dog_weight: Bulldog\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: A Bulldog weights 51 lbs\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: A bulldog weights 51 lbs\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88858f5-db81-4c7d-8565-c44e9236f364",
   "metadata": {},
   "source": [
    "Below are supported/known functions for LLM to leverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0789b8c1-c577-45b1-9fad-e51998f31b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(what):\n",
    "    return eval(what)\n",
    "\n",
    "def average_dog_weight(name):\n",
    "    if name in \"Scottish Terrier\": \n",
    "        return(\"Scottish Terriers average 20 lbs\")\n",
    "    elif name in \"Border Collie\":\n",
    "        return(\"a Border Collies average weight is 37 lbs\")\n",
    "    elif name in \"Toy Poodle\":\n",
    "        return(\"a toy poodles average weight is 7 lbs\")\n",
    "    else:\n",
    "        return(\"An average dog weights 50 lbs\")\n",
    "\n",
    "known_actions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_dog_weight\": average_dog_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e58f0-3d9d-414c-8dc8-1a2f44168de7",
   "metadata": {},
   "source": [
    "Alright, let's test our first agent to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "213f4c9f-6d4d-412d-a9be-4cd88c0253b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bc25b06-3900-46d7-886a-2e7297fdd872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up the average weight of a toy poodle using the average_dog_weight action.\n",
      "Action: average_dog_weight: Toy Poodle\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = abot(\"How much does a toy poodle weigh?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd6cbe-9e30-40b2-a01f-c11c28cff03f",
   "metadata": {},
   "source": [
    "As requested from the `prompt`, LLM knows in order to get the weight of toy poodle, it needs to execute the function `average_dog_weight` and feed in the argument `Toy Poodle`! For now, let's execute the function on behavior of the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b90b863-61c3-4751-930f-787e0ec3ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = average_dog_weight(\"Toy Poodle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1d1747b-754b-42aa-94e6-16790408232b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a toy poodles average weight is 7 lbs'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3efb1-4672-4a62-9f2c-e91b662d716d",
   "metadata": {},
   "source": [
    "Next, let's compose the response as `\"Observataion\"` and feed back into our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f924eb6-c97c-4551-8cb2-bbd3b9b8c4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observation: a toy poodles average weight is 7 lbs'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "082ef12b-e830-44a0-8402-662d1dc87639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: A toy poodle weighs an average of 7 lbs.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659afe8e-9803-4113-b76e-1333ad5052b3",
   "metadata": {},
   "source": [
    "As expected, we got the message with prefix `Answer:` which means the message is the final answer to our question.\n",
    "\n",
    "Let's check all the messages accumulated so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "366a5495-4c0d-4633-bd5f-9199c649c048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\naverage_dog_weight:\\ne.g. average_dog_weight: Collie\\nreturns average weight of a dog when given the breed\\n\\nExample session:\\n\\nQuestion: How much does a Bulldog weigh?\\nThought: I should look the dogs weight using average_dog_weight\\nAction: average_dog_weight: Bulldog\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: A Bulldog weights 51 lbs\\n\\nYou then output:\\n\\nAnswer: A bulldog weights 51 lbs'},\n",
       " {'role': 'user', 'content': 'How much does a toy poodle weigh?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: I should look up the average weight of a toy poodle using the average_dog_weight action.\\nAction: average_dog_weight: Toy Poodle\\nPAUSE'},\n",
       " {'role': 'user',\n",
       "  'content': 'Observation: a toy poodles average weight is 7 lbs'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Answer: A toy poodle weighs an average of 7 lbs.'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98bf067-8cc7-466d-9eed-c3cb588e85a2",
   "metadata": {},
   "source": [
    "Let's do one more time but with a more complex question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b05d9b57-80c7-4d56-9e7d-338ab5e45b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098029b4-9b37-4647-a664-59ec3b8a9cbf",
   "metadata": {},
   "source": [
    "Ask the question which requires more than one actions in order to get the final answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31dd22e7-875f-4d4d-bc09-1c47592c49b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thought: I need to find the average weight of both a Border Collie and a Scottish Terrier, then sum these weights to get the combined weight of the two dogs.\\nAction: average_dog_weight: Border Collie\\nPAUSE'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "abot(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61417fe-e039-4dfa-b4ec-c7d2f2e20c31",
   "metadata": {},
   "source": [
    "Let's call the help function `average_dog_weight` on behavior of LLM to get the weight of `Border Collie`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bfc84068-305c-442b-b21e-9d64075d25ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: a Border Collies average weight is 37 lbs\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Border Collie\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654ebf0-c3e0-4a22-a14a-c975f10e7831",
   "metadata": {},
   "source": [
    "Next, let's feed the obtained observation back to LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd8b9a9a-9c61-46cf-9303-f7bf4de3450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thought: Now I need to find the average weight of a Scottish Terrier.\\nAction: average_dog_weight: Scottish Terrier\\nPAUSE'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a7b59-5727-4290-929e-3045d5b9b168",
   "metadata": {},
   "source": [
    "Again, let's call the function `average_dog_weight` on behavior of LLM to get the weight of `Scottish Terrier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3cd213d2-be98-4338-a498-278135a3c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: Scottish Terriers average 20 lbs\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Scottish Terrier\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f0e83-e551-4694-830b-c6bc7141c1a0",
   "metadata": {},
   "source": [
    "and feed in the obtained observation back to LLM too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a0901d0-ac6e-42fd-b116-34bca81b5d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thought: I now have the average weights of both dogs. I need to sum these weights to get the combined weight.\\nAction: calculate: 37 + 20\\nPAUSE'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0236a-5c46-4a17-ad1d-49390850fd64",
   "metadata": {},
   "source": [
    "This time, the execution of function `calculate` is required to sum up the weights. Let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcf9cf7b-8127-43e2-b3e4-40968d7d13bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 57\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(eval(\"37 + 20\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314bcf6d-f45c-42a7-b089-e49c732df07e",
   "metadata": {},
   "source": [
    "As usual, let's feed in the observation back to LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b1cf8b2-4457-4152-8214-26453c3db25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: The combined weight of a Border Collie and a Scottish Terrier is 57 lbs.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e5182-b212-48b7-be73-1043c2bb95ff",
   "metadata": {},
   "source": [
    "No surprise, we got the correct answer `57 lbs` back. Cool! isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd69cb-d8ec-4c70-b011-06a335ffd0ee",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Agent v1</font></b>\n",
    "<b><font size='3ptx'>We are going to enable the agent to be capable of executing the tools/functions now.</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f0e38-f082-4aac-af73-0b8d7c130512",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>RE to extract the function name and corresponding arguments for execution</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74461e14-a6f4-4741-ae73-2f2c4ce9d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python regular expression to selection action\n",
    "action_re = re.compile('^Action: (\\w+): (.*)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f155d59-dfa7-4ec4-a288-55b3418de400",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Query function</font></b>\n",
    "Let's put all the things we have done together and wrap them up as a function `query`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae6c1dc2-ae6c-40ff-b28b-821815afad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question: str, max_turns: int=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a) \n",
    "            for a in result.split('\\n') \n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            # There is an action to run\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe3f34-b81a-4501-b958-6053a63638e2",
   "metadata": {},
   "source": [
    "Let's test it with the question we just asked before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99f1fce8-4368-4538-bd1c-0c4a55c9e447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the average weight of both a Border Collie and a Scottish Terrier, then add them together to get the combined weight.\n",
      "Action: average_dog_weight: Border Collie\n",
      "PAUSE\n",
      " -- running average_dog_weight Border Collie\n",
      "Observation: a Border Collies average weight is 37 lbs\n",
      "Thought: Now I need to find the average weight of a Scottish Terrier.\n",
      "Action: average_dog_weight: Scottish Terrier\n",
      "PAUSE\n",
      " -- running average_dog_weight Scottish Terrier\n",
      "Observation: Scottish Terriers average 20 lbs\n",
      "Thought: I now have the average weights of both dogs. I will add them together to find their combined weight.\n",
      "Action: calculate: 37 + 20\n",
      "PAUSE\n",
      " -- running calculate 37 + 20\n",
      "Observation: 57\n",
      "Answer: The combined weight of a Border Collie and a Scottish Terrier is 57 lbs.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90add3a2-e500-43e0-b6dc-bd2fce00d71d",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [Deeplearn.ai - AI Agents in LangGraph - Ch3: LangGraph Components](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/3/langgraph-components)\n",
    "* [Paper - ReAct: Synergizing Reasoning and Acting in Language Models](https://react-lm.github.io/)\n",
    "> Language models are getting better at reasoning (e.g. chain-of-thought prompting) and acting (e.g. WebGPT, SayCan, ACT-1), but these two directions have remained separate. ReAct asks, what if these two fundamental capabilities are combined?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
