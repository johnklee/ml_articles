{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a450761-2857-493a-b0fc-79227a692035",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Preface</font></b>\n",
    "([course source](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/5/persistence-and-streaming))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a5b1a4-80b3-4bad-a9fa-95338575b540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==0.2.6\n",
      "langchain-anthropic==0.1.15\n",
      "langchain-community==0.2.6\n",
      "langchain-core==0.2.10\n",
      "langchain-experimental==0.0.62\n",
      "langchain-google-genai==1.0.6\n",
      "langchain-groq==0.1.3\n",
      "langchain-openai==0.1.9\n",
      "langchain-text-splitters==0.2.0\n",
      "langchainhub==0.1.14\n",
      "langgraph==0.1.4\n",
      "openai==1.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep -P '(openai|langchain|langgraph)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5594f9c4-b818-4049-9b75-3527d6623cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from tavily import TavilyClient\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "a = load_dotenv(find_dotenv(os.path.expanduser('~/.env'))) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "# connect\n",
    "client = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d493b63-0cc2-4fa7-b55b-06c37f735b28",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Persistence</font></b>\n",
    "Here we are going to demonstrate the persistence of agent. So it could use chat history to answer question which hidden information which it should refer to the previous chat question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79581af5-f44f-47e2-9f20-9dc12a1dee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.tool import ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411e9306-f0b4-4f1e-bd1a-4544b9b55464",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1405472-4dbc-486d-884b-cc522efe3534",
   "metadata": {},
   "source": [
    "Let's prepare the state of graph which will keep the generated message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959d6a77-7ba6-481b-90b8-b0ffcb4e0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fed123-84fb-46af-92c5-3a6dcdd9d2aa",
   "metadata": {},
   "source": [
    "Then we use [**SqliteSaver**](SqliteSaver) DB to save the chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8b80857-6975-4017-836d-a47538265c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54fe9d-8dbf-4b98-b3ef-1baeed0be028",
   "metadata": {},
   "source": [
    "Then, below is the implementation of our agent. Here we compile the LangGraph workflow with a [`CheckPointer`](https://langchain-ai.github.io/langgraph/reference/checkpoints/?h=sqlite+saver#checkpoints) to give the agent \"memory\" by persisting its state. This permits things like:\n",
    "* Remembering things across multiple interactions\n",
    "* Interrupting to wait for user input\n",
    "* Resilience for long-running, error-prone agents\n",
    "* Time travel retry and branch from a previous checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a0bde74-1009-4222-a3fa-3361397f56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6df50-fcb9-45b2-8d1d-e2e095b091e0",
   "metadata": {},
   "source": [
    "Then we could prepare an agent for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a824ce3-3719-4371-8277-d6b1dafba2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da03d47-ce2f-482f-a5f6-c7ddbae76fda",
   "metadata": {},
   "source": [
    "### <b><font color='darkgreen'>Question: `What is the weather in Taiwan?`</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cea141f-be97-4a30-aff7-dc87c8cd15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content='What is the weather in Taiwan?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3ed5dbf-994c-4c4d-bd97-a16b649ebcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24eec5-1aa1-4d5b-bd9a-e4fbdade8a48",
   "metadata": {},
   "source": [
    "We then call [graph.stream](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream) with argument `config` to keep the `thread_id` information for futher back tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f055de2-7798-42ad-84e0-cccf40fcd296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_U6KCkVEkwnuQp4AkwAGwuepY', 'function': {'arguments': '{\\n  \"query\": \"current weather in Taiwan\"\\n}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_ce0793330f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-83f0b598-6c0c-42bb-90fe-d71bea685e2d-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Taiwan'}, 'id': 'call_U6KCkVEkwnuQp4AkwAGwuepY'}], usage_metadata={'input_tokens': 151, 'output_tokens': 22, 'total_tokens': 173})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Taiwan'}, 'id': 'call_U6KCkVEkwnuQp4AkwAGwuepY'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.timeanddate.com/weather/taiwan/taipei/ext\\', \\'content\\': \\'Taipei 14 Day Extended Forecast. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 84 °F. Sprinkles. Partly sunny. (Weather station: Sungshan / Taipei, Taiwan). See more current weather.\\'}, {\\'url\\': \\'https://www.ventusky.com/taipei\\', \\'content\\': \"台北市 (Taipei) ☀ Weather forecast for 10 days, information from meteorological stations, webcams, sunrise and sunset, wind and precipitation maps for this place ... Taiwan / Lat.: 25°2\\'N / Lon.: 121°33\\'E / Altitude: 17 m Timezone: Asia/Taipei (UTC+8) / Current time: 09:09 2024/06/29 . Current Weather ; Forecast ; Sun and Moon ; 33 °C ...\"}]', name='tavily_search_results_json', tool_call_id='call_U6KCkVEkwnuQp4AkwAGwuepY')]\n",
      "[AIMessage(content='The current weather in Taipei, Taiwan is partly sunny with sprinkles, and the temperature is around 84°F (approximately 29°C). For more detailed and extended forecasts, you can visit:\\n\\n- [Time and Date - Taipei Weather](https://www.timeanddate.com/weather/taiwan/taipei/ext)\\n- [Ventusky - Taipei Weather](https://www.ventusky.com/taipei)', response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 390, 'total_tokens': 476}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d576307f90', 'finish_reason': 'stop', 'logprobs': None}, id='run-ed63484b-a930-4a30-8252-a9095c8a9605-0', usage_metadata={'input_tokens': 390, 'output_tokens': 86, 'total_tokens': 476})]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb8007-d2b3-4152-9e28-51892007be1f",
   "metadata": {},
   "source": [
    "Because we store the chatting history in memory, so we could know below question is referring to the weather of Tokyo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "661a9fc2-b1f7-44ad-8252-df99c5cf0fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Kldot0N18wuhgs82yzo1fQJE', 'function': {'arguments': '{\"query\":\"current weather in Tokyo\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1165, 'total_tokens': 1186}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d576307f90', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aad4b30d-d5aa-40c4-9bde-35015dcbe0c1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Tokyo'}, 'id': 'call_Kldot0N18wuhgs82yzo1fQJE'}], usage_metadata={'input_tokens': 1165, 'output_tokens': 21, 'total_tokens': 1186})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Tokyo'}, 'id': 'call_Kldot0N18wuhgs82yzo1fQJE'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.accuweather.com/en/jp/tokyo/226396/january-weather/226396\\', \\'content\\': \\'Get the monthly weather forecast for Tokyo, Tokyo, Japan, including daily high/low, historical averages, to help you plan ahead.\\'}, {\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Tokyo\\', \\'region\\': \\'Tokyo\\', \\'country\\': \\'Japan\\', \\'lat\\': 35.69, \\'lon\\': 139.69, \\'tz_id\\': \\'Asia/Tokyo\\', \\'localtime_epoch\\': 1719823496, \\'localtime\\': \\'2024-07-01 17:44\\'}, \\'current\\': {\\'last_updated_epoch\\': 1719822600, \\'last_updated\\': \\'2024-07-01 17:30\\', \\'temp_c\\': 27.3, \\'temp_f\\': 81.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Light rain\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/296.png\\', \\'code\\': 1183}, \\'wind_mph\\': 8.1, \\'wind_kph\\': 13.0, \\'wind_degree\\': 180, \\'wind_dir\\': \\'S\\', \\'pressure_mb\\': 1001.0, \\'pressure_in\\': 29.56, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 84, \\'cloud\\': 75, \\'feelslike_c\\': 29.0, \\'feelslike_f\\': 84.2, \\'windchill_c\\': 29.3, \\'windchill_f\\': 84.7, \\'heatindex_c\\': 32.2, \\'heatindex_f\\': 90.0, \\'dewpoint_c\\': 21.5, \\'dewpoint_f\\': 70.7, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 7.0, \\'gust_mph\\': 15.5, \\'gust_kph\\': 24.9}}\"}]', name='tavily_search_results_json', tool_call_id='call_Kldot0N18wuhgs82yzo1fQJE')]}\n",
      "{'messages': [AIMessage(content='The current weather in Tokyo, Japan is as follows:\\n\\n- **Temperature:** 27.3°C (81.1°F)\\n- **Condition:** Light rain\\n- **Wind:** 8.1 mph (13.0 kph) from the south\\n- **Humidity:** 84%\\n- **Cloud Cover:** 75%\\n- **Feels Like:** 29.0°C (84.2°F)\\n- **Visibility:** 10 km (6 miles)\\n\\nFor more detailed and up-to-date information, you can visit:\\n- [AccuWeather - Tokyo Weather](https://www.accuweather.com/en/jp/tokyo/226396/january-weather/226396)\\n\\nOr check other sources such as Weather API or similar weather services.', response_metadata={'token_usage': {'completion_tokens': 154, 'prompt_tokens': 1656, 'total_tokens': 1810}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-a58b1859-d62b-486b-99c8-0244cbd5f5ce-0', usage_metadata={'input_tokens': 1656, 'output_tokens': 154, 'total_tokens': 1810})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in Tokyo?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "last_event = None\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        last_event = v\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6218162d-fc38-40d1-8ff9-9ac3e2ed176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Tokyo, Japan is as follows:\n",
      "\n",
      "- **Temperature:** 27.3°C (81.1°F)\n",
      "- **Condition:** Light rain\n",
      "- **Wind:** 8.1 mph (13.0 kph) from the south\n",
      "- **Humidity:** 84%\n",
      "- **Cloud Cover:** 75%\n",
      "- **Feels Like:** 29.0°C (84.2°F)\n",
      "- **Visibility:** 10 km (6 miles)\n",
      "\n",
      "For more detailed and up-to-date information, you can visit:\n",
      "- [AccuWeather - Tokyo Weather](https://www.accuweather.com/en/jp/tokyo/226396/january-weather/226396)\n",
      "\n",
      "Or check other sources such as Weather API or similar weather services.\n"
     ]
    }
   ],
   "source": [
    "print(last_event['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ec5d1-2430-4c60-8ecb-817da2f8810a",
   "metadata": {},
   "source": [
    "Now we know both the weather in Taipei and Tokyo. With chatting history, agent should be able to answer below question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea88183d-1945-4ffe-8ccd-b89881499b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Based on the current weather information:\\n\\n- **Taipei, Taiwan:** 84°F (approximately 29°C)\\n- **Tokyo, Japan:** 27.3°C (81.1°F)\\n\\nTaipei is currently slightly warmer than Tokyo.', response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 1822, 'total_tokens': 1872}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-680d63f3-fc4f-4909-b8bc-ffaf8ace11bf-0', usage_metadata={'input_tokens': 1822, 'output_tokens': 50, 'total_tokens': 1872})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "last_event = None\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "        last_event = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c665e9ee-839c-44bc-84c5-d56304a3a738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the current weather information:\n",
      "\n",
      "- **Taipei, Taiwan:** 84°F (approximately 29°C)\n",
      "- **Tokyo, Japan:** 27.3°C (81.1°F)\n",
      "\n",
      "Taipei is currently slightly warmer than Tokyo.\n"
     ]
    }
   ],
   "source": [
    "print(last_event['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9a2ae-c0d6-4dac-b7c6-24323ef8ba53",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Streaming tokens</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5fca87c7-cdcf-4cca-ac6c-98e47bb91853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a50b9c3-cf28-42d9-b360-fddcc84586a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/johnkclee/Github/ml_articles/env/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany| is| a| country|,| so| the| weather| can| vary| widely| depending| on| the| region|.| Could| you| please| specify| a| particular| city| or| region| in| Germany| for| which| you| would| like| to| know| the| weather|?|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in German?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a95b5-e7d2-4695-b55d-56b157f25009",
   "metadata": {},
   "source": [
    "## <b><font color='darkblue'>Supplement</font></b>\n",
    "* [Deeplearn.ai - AI Agents in LangGraph - Ch2: Build an Agent from Scratch](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/2/build-an-agent-from-scratch)\n",
    "* [Deeplearn.ai - AI Agents in LangGraph - Ch3: LangGraph components](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/3/langgraph-components)\n",
    "* [Deeplearn.ai - AI Agents in LangGraph - Ch4: Agentic search tools](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/4/agentic-search-tools)\n",
    "* [Deeplearn.ai - AI Agents in LangGraph - Ch5: Persistence and streaming](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/5/persistence-and-streaming)\n",
    "* [Deeplearn.ai - AI Agents in LangGraph - Ch6: Human in the loop](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/6/human-in-the-loop)\n",
    "* [Langchain doc - How to add chat history](https://python.langchain.com/v0.2/docs/how_to/qa_chat_history_how_to/)\n",
    "* [YWC 科技筆記 - LangGraph: LangChain Agent 的殺手鐧 (進階)](https://ywctech.net/ml-ai/langchain-langgraph-agent-part2/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
