{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>POS Tagging - An Overview</font>\n",
    "([article source](https://www.kaggle.com/tanyadayanand/pos-tagging-using-rnn)) <font size='3ptx'>**The process of classifying words into their [parts of speech](https://en.wikipedia.org/wiki/Part_of_speech) and labeling them accordingly is known as part-of-speech tagging, or simply POS-tagging.**</font>\n",
    "\n",
    "The [**NLTK library**](https://www.nltk.org/) has a number of corpora which contains word and its POS tag. The following table provide information about each tag:\n",
    "![1.png](images/1.PNG)\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Notebook layout</font>\n",
    "1. <font size='3ptx'>[**Preprocess data**](#sect1)</font>\n",
    "2. <font size='3ptx'>[**Vanilla RNN**](#sect2)</font>\n",
    "3. <font size='3ptx'>[**LSTM**](#sect3)</font>\n",
    "5. GRU\n",
    "6. Bidirectional LSTM\n",
    "7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#!pip install seaborn\n",
    "#!pip install gensim\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0)\n",
      "/usr/local/google/home/johnkclee/Github/ml_articles/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# subprocess = subprocess.Popen(\"pip freeze\", shell=True, stdout=subprocess.PIPE)\n",
    "# print(subprocess.stdout.read().decode('utf8'))\n",
    "print(sys.version_info)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "from nltk.tokenize import word_tokenize as nltk_word_tokenize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect1'></a>\n",
    "## <font color='darkblue'>1. Preprocess data</font>\n",
    "Here we will going to load in datas and explore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Load data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /usr/local/google/home/johnkclee/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /usr/local/google/home/johnkclee/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /usr/local/google/home/johnkclee/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /usr/local/google/home/johnkclee/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "nltk.download('brown')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('universal_tagset')\n",
    "  \n",
    "# load POS tagged corpora from NLTK\n",
    "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
    "brown_corpus = brown.tagged_sents(tagset='universal')\n",
    "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
    "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DET'),\n",
       " ('Lorillard', 'NOUN'),\n",
       " ('spokewoman', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " (',', '.'),\n",
       " ('``', '.'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('old', 'ADJ'),\n",
       " ('story', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Divide data in words (X) and tags (y)</font>\n",
    "We have to preprocess the raw data into `X` (features) and `y` (labels) for ML training. Since this is a many-to-many problem, each data point will be a different sentence of the corpora.\n",
    "* Each data point will have multiple words in the input sequence. This is what we will refer to as `X`.\n",
    "* Each word will have its correpsonding tag in the output sequence. This what we will refer to as `y`.\n",
    "\n",
    "Sample dataset:\n",
    "\n",
    "| X | y |\n",
    "| --- | --- |\n",
    "|Mr. Vinken is chairman of Elsevier | NOUN NOUN VERB NOUN ADP NOUN |\n",
    "|We have no useful information | PRON VERB DET ADJ NOUN |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # store input sequence\n",
    "y = [] # store output sequence\n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    X_sentence = []\n",
    "    y_sentence = []\n",
    "    for entity in sentence:         \n",
    "        X_sentence.append(entity[0])  # entity[0] contains the word\n",
    "        y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
    "        \n",
    "    X.append(X_sentence)\n",
    "    y.append(y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
    "num_tags   = len(set([word.lower() for sentence in y for word in sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tagged sentences: 72202\n",
      "Vocabulary size: 59448\n",
      "Total number of tags: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
    "print(\"Vocabulary size: {}\".format(num_words))\n",
    "print(\"Total number of tags: {}\".format(num_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
      "\n",
      "sample Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at first data point\n",
    "# this is one data point that will be fed to the RNN\n",
    "print('sample X: ', X[0], '\\n')\n",
    "print('sample Y: ', y[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first input sequence  : 18\n",
      "Length of first output sequence : 18\n"
     ]
    }
   ],
   "source": [
    "# In this many-to-many problem, the length of each input and output sequence must be the same.\n",
    "# Since each word is tagged, it's important to make sure that the length of input sequence equals the output sequence\n",
    "print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
    "print(\"Length of first output sequence : {}\".format(len(y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Vectorise X and y</font>\n",
    "\n",
    "#### Encode X and Y to integer values\n",
    "We'll use the <font color='blue'>Tokenizer()</font> function from Keras library ([Keras Text Preprocess](https://keras.io/api/preprocessing/text/)) to encode text sequence to integer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode X\n",
    "word_tokenizer = Tokenizer()                      # instantiate tokeniser\n",
    "word_tokenizer.fit_on_texts(X)                    # fit tokeniser on data\n",
    "X_encoded = word_tokenizer.texts_to_sequences(X)  # use the tokeniser to encode input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Y\n",
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(y)\n",
    "y_encoded = tag_tokenizer.texts_to_sequences(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Raw data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
      "\n",
      "Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
      "\n",
      "\n",
      "** Encoded data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  [6423, 24231, 2, 7652, 102, 170, 2, 47, 1898, 1, 269, 17, 7, 13230, 619, 1711, 2761, 3] \n",
      "\n",
      "Y:  [1, 1, 3, 11, 1, 6, 3, 2, 2, 5, 1, 4, 5, 6, 1, 1, 11, 3] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at first encoded data point\n",
    "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X[0], '\\n')\n",
    "print('Y: ', y[0], '\\n')\n",
    "print()\n",
    "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X_encoded[0], '\\n')\n",
    "print('Y: ', y_encoded[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Pad sequences</font>\n",
    "The next step after encoding the data is to **define the sequence lengths**. As of now, the sentences present in the data are of various lengths. We need to either pad short sentences or truncate long sentences to a fixed length. This fixed length, however, is a **hyperparameter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest sentence: 271\n"
     ]
    }
   ],
   "source": [
    "# check length of longest sentence\n",
    "lengths = [len(seq) for seq in X_encoded]\n",
    "print(\"Length of longest sentence: {}\".format(max(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad each sequence to MAX_SEQ_LENGTH using KERAS' pad_sequences() function. \n",
    "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
    "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
    "\n",
    "# Truncation and padding can either be 'pre' or 'post'. \n",
    "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
    "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
    "\n",
    "MAX_SEQ_LENGTH = 100  # sequences greater than 100 in length will be truncated\n",
    "\n",
    "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "y_padded = pad_sequences(y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0  6423 24231\n",
      "     2  7652   102   170     2    47  1898     1   269    17     7 13230\n",
      "   619  1711  2761     3] \n",
      "\n",
      "\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  1  1  3 11  1  6  3  2  2  5  1  4  5  6\n",
      "  1  1 11  3]\n"
     ]
    }
   ],
   "source": [
    "# print the first sequence\n",
    "print(X_padded[0], \"\\n\"*3)\n",
    "print(y_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN will learn the zero to zero mapping while training. So we don't need to worry about the padded zeroes. Please note that zero is not reserved for any word or tag, it's only reserved for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign padded sequences to X and Y\n",
    "X, y = X_padded, y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vector(sentence):\n",
    "    # Sentence to token list\n",
    "    tokens = nltk_word_tokenize(sentence)\n",
    "    \n",
    "    # Encode token list\n",
    "    X_encoded = word_tokenizer.texts_to_sequences([tokens])\n",
    "    \n",
    "    # Pad the sequence\n",
    "    X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "    \n",
    "    return X_padded, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,   26,   11,   34, 1602, 3586,\n",
       "           3]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How we translate a sentence into feature vector (X)\n",
    "X_padded, tokens = sentence2vector(\"This is an interesting sentence.\")\n",
    "X_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Word embeddings</font>\n",
    "Currently, each word and each tag is encoded as an integer.\n",
    "\n",
    "We'll use a more sophisticated technique to represent the input words (`X`) using what's known as [**word embeddings**](https://en.wikipedia.org/wiki/Word_embedding).\n",
    "\n",
    "However, to represent each tag in y, we'll simply use [**one-hot encoding**](https://en.wikipedia.org/wiki/One-hot) scheme since there are only 13 tags in the dataset and the [**LSTM**](https://en.wikipedia.org/wiki/Long_short-term_memory) will have no problems in learning its own representation of these tags.\n",
    "\n",
    "To use word embeddings, you can go for either of the following models:\n",
    "* **word2vec model:** https://code.google.com/archive/p/word2vec/\n",
    "* **GloVe model:** https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "**We're using the word2vec model for no particular reason.** Both of these are very efficient in representing words. You can try both and see which one works better. Dimensions of a word embedding is: `(VOCABULARY_SIZE, EMBEDDING_DIMENSION)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Use word embeddings for input sequences (`X`)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Queen', 0.4929387867450714),\n",
       " ('Tupou_V.', 0.45174285769462585),\n",
       " ('Oprah_BFF_Gayle', 0.4422132968902588),\n",
       " ('Jackson', 0.440250426530838),\n",
       " ('NECN_Alison', 0.4331282675266266),\n",
       " ('Whitfield', 0.42834725975990295),\n",
       " ('Ida_Vandross', 0.42084527015686035),\n",
       " ('prosecutor_Dan_Satterberg', 0.420758992433548),\n",
       " ('martin_Luther_King', 0.42059651017189026),\n",
       " ('Coretta_King', 0.4202733635902405)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec effectiveness\n",
    "word2vec.most_similar(positive = [\"King\", \"Woman\"], negative = [\"Man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign word vectors from word2vec model\n",
    "EMBEDDING_SIZE  = 300  # each word in word2vec model is represented using a 300 dimensional vector\n",
    "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "# create an empty embedding matix\n",
    "embedding_weights = np.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))\n",
    "\n",
    "# create a word to index dictionary mapping\n",
    "word2id = word_tokenizer.word_index\n",
    "\n",
    "# copy vectors from word2vec model to the words present in corpus\n",
    "for word, index in word2id.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = word2vec[word]\n",
    "    except KeyError:\n",
    "        # Keep unknown word to use vector with all valueas as 0\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (59449, 300)\n"
     ]
    }
   ],
   "source": [
    "# check embedding dimension\n",
    "print(\"Embeddings shape: {}\".format(embedding_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4453125 , -0.20019531,  0.20019531, -0.03149414,  0.078125  ,\n",
       "       -0.390625  ,  0.13671875, -0.13867188,  0.05395508,  0.10546875,\n",
       "       -0.05029297, -0.23730469,  0.19921875,  0.12597656, -0.12695312,\n",
       "        0.34179688,  0.06347656,  0.26757812, -0.07324219, -0.29101562,\n",
       "        0.10498047,  0.11914062,  0.23730469,  0.00640869,  0.12451172,\n",
       "       -0.00939941, -0.02770996,  0.03076172,  0.07421875, -0.22851562,\n",
       "       -0.08056641, -0.05273438,  0.16894531,  0.19824219, -0.15625   ,\n",
       "       -0.08740234,  0.10742188, -0.07177734,  0.05200195,  0.25976562,\n",
       "        0.171875  , -0.13574219,  0.06738281,  0.00531006,  0.15527344,\n",
       "       -0.03515625,  0.08789062,  0.3359375 , -0.12890625,  0.17578125,\n",
       "       -0.08642578,  0.32421875, -0.09033203,  0.35351562,  0.24316406,\n",
       "       -0.07470703, -0.06640625, -0.17578125,  0.06689453, -0.03833008,\n",
       "        0.0100708 , -0.21484375, -0.03686523,  0.04394531,  0.02209473,\n",
       "        0.00219727, -0.22460938,  0.03015137, -0.21582031,  0.16015625,\n",
       "        0.23339844, -0.16699219, -0.09228516,  0.10644531,  0.19335938,\n",
       "       -0.26757812,  0.15722656, -0.08691406,  0.11181641,  0.14941406,\n",
       "       -0.20507812,  0.04882812, -0.07519531, -0.21582031, -0.10107422,\n",
       "       -0.13378906, -0.06103516,  0.05444336,  0.07470703,  0.09521484,\n",
       "       -0.0144043 ,  0.27929688, -0.25585938, -0.05273438, -0.22460938,\n",
       "        0.10253906, -0.15136719,  0.21289062, -0.04711914, -0.12109375,\n",
       "        0.04663086,  0.25976562,  0.13574219,  0.00799561,  0.02001953,\n",
       "        0.1796875 ,  0.30664062,  0.06152344,  0.13574219, -0.09619141,\n",
       "       -0.07421875,  0.38671875,  0.20800781,  0.12695312,  0.05200195,\n",
       "        0.17675781, -0.16796875, -0.19335938, -0.06152344, -0.07568359,\n",
       "       -0.18457031,  0.06030273, -0.15136719, -0.1953125 , -0.23339844,\n",
       "        0.00738525, -0.02478027, -0.09765625, -0.06054688,  0.20214844,\n",
       "       -0.2734375 ,  0.00595093, -0.34570312, -0.12988281,  0.00418091,\n",
       "        0.09960938,  0.0246582 ,  0.15917969, -0.02038574,  0.30273438,\n",
       "       -0.20800781, -0.20214844, -0.03930664, -0.06494141,  0.00436401,\n",
       "       -0.02270508, -0.171875  ,  0.30273438, -0.16113281, -0.49414062,\n",
       "        0.3515625 ,  0.39257812,  0.09814453,  0.41796875,  0.05371094,\n",
       "        0.02392578, -0.03710938, -0.08251953, -0.38671875, -0.40625   ,\n",
       "       -0.05664062,  0.203125  , -0.01782227,  0.3359375 ,  0.19140625,\n",
       "       -0.44335938,  0.00927734,  0.24804688, -0.05102539,  0.19726562,\n",
       "        0.03881836,  0.03442383, -0.40039062, -0.09912109, -0.07128906,\n",
       "        0.21484375, -0.01422119,  0.04907227, -0.07421875, -0.21582031,\n",
       "       -0.41992188,  0.02172852,  0.11083984, -0.33398438, -0.2734375 ,\n",
       "       -0.05322266, -0.16601562, -0.28515625, -0.12207031,  0.04882812,\n",
       "       -0.0625    , -0.04077148, -0.16503906,  0.0480957 , -0.21191406,\n",
       "        0.20019531, -0.2109375 ,  0.10839844, -0.14648438, -0.07958984,\n",
       "       -0.05151367, -0.16601562, -0.24902344, -0.375     ,  0.05664062,\n",
       "       -0.13671875, -0.2578125 ,  0.28515625, -0.04736328,  0.13574219,\n",
       "       -0.14550781,  0.19433594, -0.21972656,  0.08447266, -0.10791016,\n",
       "       -0.11816406, -0.16015625,  0.12060547, -0.10888672,  0.04345703,\n",
       "        0.11474609, -0.08447266, -0.00720215,  0.03662109, -0.38671875,\n",
       "       -0.03881836, -0.03198242,  0.00344849,  0.22558594, -0.06787109,\n",
       "       -0.16699219,  0.2421875 ,  0.05712891,  0.27539062, -0.0456543 ,\n",
       "       -0.19042969, -0.17285156,  0.00836182, -0.03271484,  0.16992188,\n",
       "       -0.18554688, -0.0703125 , -0.32617188, -0.00668335, -0.02770996,\n",
       "        0.3359375 ,  0.125     , -0.2109375 ,  0.06005859, -0.07080078,\n",
       "        0.11132812,  0.125     ,  0.25390625,  0.29296875, -0.03125   ,\n",
       "        0.09033203, -0.20507812, -0.07861328,  0.02062988, -0.0546875 ,\n",
       "       -0.23339844,  0.00096893, -0.04516602,  0.16894531, -0.22167969,\n",
       "        0.08105469,  0.33398438,  0.09619141,  0.00866699, -0.03271484,\n",
       "        0.05493164,  0.12109375,  0.16210938, -0.10302734,  0.27148438,\n",
       "       -0.03344727, -0.30273438,  0.04223633,  0.08496094, -0.15527344,\n",
       "        0.10107422, -0.11474609, -0.13085938,  0.22949219,  0.12988281,\n",
       "        0.09863281, -0.03588867,  0.10693359, -0.24902344,  0.19238281,\n",
       "       -0.05322266, -0.09033203, -0.31640625, -0.5703125 , -0.15917969,\n",
       "        0.0291748 , -0.0246582 , -0.07714844, -0.04663086, -0.17578125])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at an embedding of a word\n",
    "embedding_weights[word_tokenizer.word_index['joy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use one-hot encoding for output sequences (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras' to_categorical function to one-hot encode Y\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72202, 100, 13)\n"
     ]
    }
   ],
   "source": [
    "# print Y of the first output sequqnce\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Split data in training, validation and tesing sets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split entire data into training and testing sets\n",
    "TEST_SIZE = 0.15\n",
    "RANDOM_STATE = 4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation sets\n",
    "VALID_SIZE = 0.15\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=VALID_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Shape of input sequences: (52165, 100)\n",
      "Shape of output sequences: (52165, 100, 13)\n",
      "--------------------------------------------------\n",
      "VALIDATION DATA\n",
      "Shape of input sequences: (9206, 100)\n",
      "Shape of output sequences: (9206, 100, 13)\n",
      "--------------------------------------------------\n",
      "TESTING DATA\n",
      "Shape of input sequences: (10831, 100)\n",
      "Shape of output sequences: (10831, 100, 13)\n"
     ]
    }
   ],
   "source": [
    "# print number of samples in each set\n",
    "print(\"TRAINING DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_train.shape))\n",
    "print('Shape of output sequences: {}'.format(y_train.shape))\n",
    "print(\"-\"*50)\n",
    "print(\"VALIDATION DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_validation.shape))\n",
    "print('Shape of output sequences: {}'.format(y_validation.shape))\n",
    "print(\"-\"*50)\n",
    "print(\"TESTING DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_test.shape))\n",
    "print('Shape of output sequences: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using [**RNN**](https://en.wikipedia.org/wiki/Recurrent_neural_network), we must make sure the dimensions of the data are what an [**RNN**](https://en.wikipedia.org/wiki/Recurrent_neural_network) expects. In general, an [**RNN**](https://en.wikipedia.org/wiki/Recurrent_neural_network) expects the following shape:\n",
    "* **Shape of X**: (#samples, #timesteps, #features)\n",
    "* **Shape of Y**: (#samples, #timesteps, #features)\n",
    "\n",
    "Now, there can be various variations in the shape that you use to feed an [**RNN**](https://en.wikipedia.org/wiki/Recurrent_neural_network) depending on the type of architecture. Since the problem we're working on has a many-to-many architecture, the input and the output both include number of timesteps which is nothing but the sequence length. But notice that the tensor `X` doesn't have the third dimension, that is, number of features. That's because we're going to use word embeddings before feeding in the data to an [**RNN**](https://en.wikipedia.org/wiki/Recurrent_neural_network), and hence there is no need to explicitly mention the third dimension. That's because when you use the [Embedding()](https://keras.io/api/layers/core_layers/embedding/) layer in Keras, you the training data will automatically be converted to `(#samples, #timesteps, #features)` where `#features` will be the embedding dimention (<font color='brown'>and note that the [**Embedding layer**](https://keras.io/api/layers/core_layers/embedding/) is always the very first layer of an [**RNN**](https://en.wikipedia.org/wiki/Recurrent_neural_network)</font>). While using the embedding layer we only need to reshape the data to `(#samples, #timesteps)` which is what we have done. However, note that you'll need to shape it to `(#samples, #timesteps, #features)` in case you don't use the [Embedding()](https://keras.io/api/layers/core_layers/embedding/) layer in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2'></a>\n",
    "## <font color='darkblue'>2. Vanilla RNN</font>\n",
    "* <font size='3ptx'>[**Uninitialised fixed embeddings**](#sect2_1)</font>\n",
    "* <font size='3ptx'>[**Compile model**](#sect2_2)</font>\n",
    "* <font size='3ptx'>[**Fix model**](#sect2_3)</font>\n",
    "* <font size='3ptx'>[**Evaluate RNN Model (embedding not trainable)**](#sect2_4)</font>\n",
    "* <font size='3ptx'>[**Uninitialised trainable embeddings**](#sect2_5)</font>\n",
    "* <font size='3ptx'>[**Compile model**](#sect2_6)</font>\n",
    "* <font size='3ptx'>[**Fix model**](#sect2_7)</font>\n",
    "* <font size='3ptx'>[**Using pre-trained embedding weights**](#sect2_8)</font>\n",
    "* <font size='3ptx'>[**Compile model**](#sect2_9)</font>\n",
    "* <font size='3ptx'>[**Fix model**](#sect2_10)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_1'></a>\n",
    "### <font color='darkgreen'>Uninitialised fixed embeddings</font>\n",
    "First let's try running a vanilla RNN. For this RNN we won't use the pre-trained word embeddings. We'll use randomly inititalised embeddings. Moreover, we won't update the embeddings weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of tags\n",
    "NUM_CLASSES = y.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        trainable     =  False                    # False - don't update the embeddings\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          17834700  \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 100, 64)           23360     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 100, 13)           845       \n",
      "=================================================================\n",
      "Total params: 17,858,905\n",
      "Trainable params: 24,205\n",
      "Non-trainable params: 17,834,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_2'></a>\n",
    "### <font color='darkgreen'>Compile model</font>\n",
    "Here we trained the model by:\n",
    "* Loss function: [Categorical Cross Entropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class)\n",
    "* Optimizer: [Adam](https://keras.io/api/optimizers/adam/)\n",
    "* Metrics: [Accuracy](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          17834700  \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 100, 64)           23360     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 100, 13)           845       \n",
      "=================================================================\n",
      "Total params: 17,858,905\n",
      "Trainable params: 24,205\n",
      "Non-trainable params: 17,834,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check summary of the model\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_3'></a>\n",
    "### <font color='darkgreen'>Fit Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x7f56fc2360d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpkmlnjlfe.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x7f56fc2360d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpkmlnjlfe.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "408/408 [==============================] - 21s 25ms/step - loss: 0.7341 - acc: 0.8088 - val_loss: 0.3260 - val_acc: 0.9018\n",
      "Epoch 2/10\n",
      "408/408 [==============================] - 9s 23ms/step - loss: 0.2962 - acc: 0.9103 - val_loss: 0.2263 - val_acc: 0.9313\n",
      "Epoch 3/10\n",
      "408/408 [==============================] - 9s 23ms/step - loss: 0.2149 - acc: 0.9340 - val_loss: 0.1837 - val_acc: 0.9420\n",
      "Epoch 4/10\n",
      "408/408 [==============================] - 10s 24ms/step - loss: 0.1785 - acc: 0.9431 - val_loss: 0.1597 - val_acc: 0.9483\n",
      "Epoch 5/10\n",
      "408/408 [==============================] - 10s 23ms/step - loss: 0.1565 - acc: 0.9492 - val_loss: 0.1445 - val_acc: 0.9530\n",
      "Epoch 6/10\n",
      "408/408 [==============================] - 10s 23ms/step - loss: 0.1429 - acc: 0.9533 - val_loss: 0.1356 - val_acc: 0.9551\n",
      "Epoch 7/10\n",
      "408/408 [==============================] - 9s 23ms/step - loss: 0.1343 - acc: 0.9556 - val_loss: 0.1294 - val_acc: 0.9569\n",
      "Epoch 8/10\n",
      "408/408 [==============================] - 10s 24ms/step - loss: 0.1287 - acc: 0.9569 - val_loss: 0.1254 - val_acc: 0.9579\n",
      "Epoch 9/10\n",
      "408/408 [==============================] - 10s 23ms/step - loss: 0.1251 - acc: 0.9578 - val_loss: 0.1221 - val_acc: 0.9586\n",
      "Epoch 10/10\n",
      "408/408 [==============================] - 9s 23ms/step - loss: 0.1220 - acc: 0.9586 - val_loss: 0.1198 - val_acc: 0.9591\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "rnn_training = rnn_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise training history\n",
    "plt.plot(rnn_training.history['acc'])\n",
    "plt.plot(rnn_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_4'></a>\n",
    "### <font color='darkgreen'>Evaluate RNN Model (embedding not trainable)</font>\n",
    "Here will demonstrate how to make prediction based on given sentence from trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translate sentence into feature fectors\n",
    "X_feats, tokens = sentence2vector(\"This is an interesting sentence.\")\n",
    "X_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 13)\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred_tmp = rnn_model.predict(X_feats)\n",
    "print(y_pred_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 5, 6, 2, 3]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle padding issue\n",
    "y_pred = []\n",
    "for i in range(1, len(tokens)+1):\n",
    "    y_pred.append(np.argmax(y_pred_tmp[0][-i]))\n",
    "    \n",
    "y_pred = y_pred[::-1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This/det\n",
      "is/verb\n",
      "an/det\n",
      "interesting/adj\n",
      "sentence/verb\n",
      "./.\n"
     ]
    }
   ],
   "source": [
    "# Output result\n",
    "for _y, t in zip(y_pred, tokens):\n",
    "    print(f\"{t}/{tag_tokenizer.index_word[_y]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know above process, let's wrap this process in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_of_sentence(sentence, model):\n",
    "    # 1) Sentence to feature vector\n",
    "    _X_test, tokens = sentence2vector(sentence)\n",
    "    # 2) Prediction\n",
    "    y_pred_tmp = model.predict(_X_test)\n",
    "    # 3) Handle padding issue\n",
    "    y_pred = []\n",
    "    for i in range(1, len(tokens)+1):\n",
    "        y_pred.append(np.argmax(y_pred_tmp[0][-i]))\n",
    "    \n",
    "    y_pred = list(map(lambda e: tag_tokenizer.index_word[e], y_pred[::-1]))\n",
    "    \n",
    "    # Output result\n",
    "    return tokens, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun/adp\n",
      "thing/noun\n",
      "is/verb\n",
      "that/adp\n",
      "I/pron\n",
      "do/verb\n",
      "n't/adv\n",
      "know/verb\n",
      "where/adv\n",
      "the/det\n",
      "rest/noun\n",
      "room/verb\n",
      "is/verb\n",
      "./.\n"
     ]
    }
   ],
   "source": [
    "tokens, y_pred = get_pos_of_sentence(\n",
    "    \"Fun thing is that I don't know where the rest room is.\", \n",
    "    rnn_model\n",
    ")\n",
    "for t, pos in zip(tokens, y_pred):\n",
    "    print(f\"{t}/{pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_5'></a>\n",
    "### <font color='darkgreen'>Uninitialised trainable embeddings</font>\n",
    "This time, we use RNN with embedding layer as trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        trainable     =  True                     # True - update the embeddings while training\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_6'></a>\n",
    "### <font color='darkgreen'>Compile Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          17834700  \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 100, 64)           23360     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 13)           845       \n",
      "=================================================================\n",
      "Total params: 17,858,905\n",
      "Trainable params: 17,858,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check summary of the model\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_7'></a>\n",
    "### <font color='darkgreen'>Fit Model</font> ([back](#sect2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "408/408 [==============================] - 36s 87ms/step - loss: 0.4997 - acc: 0.8867 - val_loss: 0.0410 - val_acc: 0.9878\n",
      "Epoch 2/10\n",
      "143/408 [=========>....................] - ETA: 22s - loss: 0.0340 - acc: 0.9899"
     ]
    }
   ],
   "source": [
    "rnn_training = rnn_model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=(X_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(rnn_training.history['acc'])\n",
    "plt.plot(rnn_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_8'></a>\n",
    "### <font color='darkgreen'>Using pre-trained embedding weights</font> ([back](#sect2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        weights       = [embedding_weights],      # word embedding matrix\n",
    "                        trainable     =  True                     # True - update the embeddings while training\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_9'></a>\n",
    "### <font color='darkgreen'>Compile model</font> ([back](#sect2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary of the model\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect2_10'></a>\n",
    "### <font color='darkgreen'>Fix Model</font> ([back](#sect2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_training = rnn_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=(X_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(rnn_training.history['acc'])\n",
    "plt.plot(rnn_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3'></a>\n",
    "## <font color='darkblue'>3. LSTM</font>\n",
    "We'll use pre-trained word embeddings in following models and allow them to be updated as well.\n",
    "1. <font size='3ptx'>[**Create model architecture**](#sect3_1)</font>\n",
    "2. <font size='3ptx'>[**Compile Model**](#sect3_2)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3_1'></a>\n",
    "### <font color='darkgreen'>Create model architecture</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim     = VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                         output_dim    = EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                         input_length  = MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                         weights       = [embedding_weights],     # word embedding matrix\n",
    "                         trainable     = True                     # True - update embeddings_weight matrix\n",
    "))\n",
    "\n",
    "lstm_model.add(LSTM(64, return_sequences=True))\n",
    "lstm_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect3_2'></a>\n",
    "### <font color='darkgreen'>Compile Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer =  'adam',\n",
    "    metrics   =  ['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Fit Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_training = lstm_model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=(X_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(lstm_training.history['acc'])\n",
    "plt.plot(lstm_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, y_pred = get_pos_of_sentence(\n",
    "    \"Fun thing is that I don't know where the rest room is.\", \n",
    "    lstm_model\n",
    ")\n",
    "for t, pos in zip(tokens, y_pred):\n",
    "    print(f\"{t}/{pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>4. GRU</font>\n",
    "[**Gated recurrent units**](https://en.wikipedia.org/wiki/Gated_recurrent_unit) (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014 by Kyunghyun Cho et al. The GRU is like a long short-term memory (LSTM) with a forget gate, but has fewer parameters than LSTM, as it lacks an output gate.\n",
    "* <font size='3ptx'>[**Create model architecture**](#sect4_1)</font>\n",
    "* <font size='3ptx'>[**Compile model**](#sect4_2)</font>\n",
    "* <font size='3ptx'>[**Fit model**](#sect4_3)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect4_1'></a>\n",
    "### <font color='darkgreen'>Create model architecture</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(input_dim     = VOCABULARY_SIZE,\n",
    "                        output_dim    = EMBEDDING_SIZE,\n",
    "                        input_length  = MAX_SEQ_LENGTH,\n",
    "                        weights       = [embedding_weights],\n",
    "                        trainable     = True\n",
    "))\n",
    "gru_model.add(GRU(64, return_sequences=True))\n",
    "gru_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect4_2'></a>\n",
    "### <font color='darkgreen'>Compile model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary of model\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect4_3'></a>\n",
    "### <font color='darkgreen'>Fit model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_training = gru_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(gru_training.history['acc'])\n",
    "plt.plot(gru_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>5. Bidirectional LSTM</font>\n",
    "Bidirectional LSTMs are an extension of traditional LSTMs that can improve model performance on sequence classification problems.\n",
    "* <font size='3ptx'>[**Create model architecture**](#sect5_1)</font>\n",
    "* <font size='3ptx'>[**Compile model**](#sect5_2)</font>\n",
    "* <font size='3ptx'>[**Fit model**](#sect5_3)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect5_1'></a>\n",
    "### <font color='darkgreen'>Create model architecture</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "bidirect_model = Sequential()\n",
    "bidirect_model.add(Embedding(input_dim     = VOCABULARY_SIZE,\n",
    "                             output_dim    = EMBEDDING_SIZE,\n",
    "                             input_length  = MAX_SEQ_LENGTH,\n",
    "                             weights       = [embedding_weights],\n",
    "                             trainable     = True\n",
    "))\n",
    "bidirect_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "bidirect_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect5_2'></a>\n",
    "### <font color=\"darkgreen\">Compile Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirect_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary of model\n",
    "bidirect_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sect5_3'></a>\n",
    "### <font color='darkgreen'>Fit Model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirect_training = bidirect_model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(bidirect_training.history['acc'])\n",
    "plt.plot(bidirect_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>6. Model evaluation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>RNN model performance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(\"Loss: {0},\\nAccuracy: {1}\".format(rnn_loss, rnn_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>LSTM model performance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(\"Loss: {0},\\nAccuracy: {1}\".format(lstm_loss, lstm_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>Bidirectional LSTM model performance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = bidirect_model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Supplement</font>\n",
    "* [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn)\n",
    "* [Kaggle - Using keras models with scikit-learn pipelines](https://www.kaggle.com/residentmario/using-keras-models-with-scikit-learn-pipelines)\n",
    "* [How to Develop a Bidirectional LSTM For Sequence Classification in Python with Keras](https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
